{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061edd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### 生成磁通密度曲线 ##############################\n",
    "############# 以材料1为例，其余材料做类似处理\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 指定engine为openpyxl\n",
    "material_1_data = pd.read_excel('train_data.xlsx', engine='openpyxl', sheet_name='材料1')\n",
    "material_1_magnetic_flux = material_1_data.iloc[:, 4:]\n",
    "\n",
    "wave_shape_name = list(material_1_data.iloc[:, 3])\n",
    "max_value = float(np.array(material_1_magnetic_flux).max())\n",
    "min_value = float(np.array(material_1_magnetic_flux).min())\n",
    "time_point = np.arange(1024)\n",
    "for wave_index in range(material_1_magnetic_flux.shape[0]):\n",
    "    if wave_shape_name[wave_index] == '正弦波':\n",
    "        wave_graph_name = 'wave_graph/matrrial_1_train/0/' + str(wave_index) + '.png'\n",
    "    elif wave_shape_name[wave_index] == '三角波':\n",
    "        wave_graph_name = 'wave_graph/matrrial_1_train/1/' + str(wave_index) + '.png'\n",
    "    elif wave_shape_name[wave_index] == '梯形波':\n",
    "        wave_graph_name = 'wave_graph/matrrial_1_train/2/' + str(wave_index) + '.png'\n",
    "    else:\n",
    "        print('################# error !')\n",
    "\n",
    "    magnetic_flux_data = list(material_1_magnetic_flux.iloc[wave_index, :])\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(time_point, magnetic_flux_data, color='k', \n",
    "                marker='o', linewidths=20)\n",
    "    plt.ylim((min_value, max_value))\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(wave_graph_name)  # 保存当前批次的图像\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "    \n",
    "# 指定engine为openpyxl\n",
    "material_test_data = pd.read_excel('test_data.xlsx')\n",
    "material_1_test_magnetic_flux = material_test_data.iloc[:20, 4:]\n",
    "for wave_index in range(material_1_test_magnetic_flux.shape[0]):\n",
    "    wave_graph_name = 'wave_graph/matrrial_1_test/0/' + str(10+wave_index) + '.png'\n",
    "    magnetic_flux_data = list(material_1_test_magnetic_flux.iloc[wave_index, :])\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(time_point, magnetic_flux_data, color='k', \n",
    "                marker='o', linewidths=20)\n",
    "    plt.ylim((min_value, max_value))\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(wave_graph_name)  # 保存当前批次的图像\n",
    "    plt.close()\n",
    "    \n",
    "############################## 使用VGG模型对磁通密度曲线进行分类 ##########\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16,64,kernel_size=3,stride=1,padding=1)\n",
    "        self.fc1 = nn.Linear(64*7*7,128)#两个池化，所以是7*7而不是14*14\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64,3)\n",
    "        self.dp = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(-1, 64 * 7* 7)#将数据平整为一维的 \n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x = self.fc3(x)\n",
    "#         self.dp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "#         x = F.log_softmax(x,dim=1) NLLLoss()才需要，交叉熵不需要\n",
    "        return x\n",
    "\n",
    "def output_embedding(embeddings):\n",
    "    final_embeddings = np.array(embeddings[0].cpu())\n",
    "    for i in range(1, len(embeddings)):\n",
    "        batch_embedding = np.array(embeddings[i].cpu())\n",
    "        final_embeddings = np.vstack((final_embeddings, batch_embedding))\n",
    "    return final_embeddings\n",
    "\n",
    "def output_labels(input_labels):\n",
    "    final_labels = np.array(input_labels[0].cpu())\n",
    "    for i in range(1, len(input_labels)):\n",
    "        batch_labels = np.array(input_labels[i].cpu())\n",
    "        final_labels = np.append(final_labels, batch_labels)\n",
    "    return final_labels\n",
    "\n",
    "def train():\n",
    "        # 定义转换流程，将RGB图像转换为灰度图像并调整大小到28x28，归一化到[0, 1]范围\n",
    "    transform_to_mnist = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # 转换为单通道灰度图像\n",
    "        transforms.Resize((28, 28)),                  # 调整图像大小为28x28\n",
    "        transforms.ToTensor(),                        # 转换为Tensor并归一化到[0, 1]范          \n",
    "        transforms.Lambda(lambda x: 1 - x)            # 反转颜色，将白底变为黑底\n",
    "    ])\n",
    "\n",
    "    # 使用ImageFolder读取文件夹中的图片\n",
    "    train_data = datasets.ImageFolder(root='wave_graph/matrrial_4_train/',\n",
    "                                      transform=transform_to_mnist)\n",
    "\n",
    "    # 加载数据\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "    # 查看数据集中的类别\n",
    "    print(train_data.classes)\n",
    "\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    total_batchs = len(train_loader)\n",
    "\n",
    "    net = CNN()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    train_accs = []\n",
    "    train_loss = []\n",
    "    test_accs = []\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = net.to(device)\n",
    "\n",
    "    ALL_EMBEDDINGS = []\n",
    "    ALL_LABELS = []\n",
    "\n",
    "    for epoch in range(35):\n",
    "        running_loss = 0.0\n",
    "        for i,data in enumerate(train_loader, 0):#0是下标起始位置默认为0\n",
    "            # data 的格式[[inputs, labels]]       \n",
    "    #         inputs,labels = data\n",
    "            inputs,labels = data[0].to(device), data[1].to(device)\n",
    "            #初始为0，清除上个batch的梯度信息\n",
    "            optimizer.zero_grad()\n",
    "            #前向+后向+优化     \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch == 34:\n",
    "                ALL_EMBEDDINGS.append(outputs.detach())\n",
    "                ALL_LABELS.append(labels.detach())\n",
    "\n",
    "            # loss 的输出，每个一百个batch输出，平均的loss\n",
    "            running_loss += loss.item()\n",
    "            if i == total_batchs-1:\n",
    "                print('[%d,%5d] loss :%.3f' %\n",
    "                     (epoch+1,i+1,running_loss/total_batchs))\n",
    "                running_loss = 0.0\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # 训练曲线的绘制 一个batch中的准确率\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = labels.size(0)# labels 的长度\n",
    "            correct = (predicted == labels).sum().item() # 预测正确的数目\n",
    "            train_accs.append(100*correct/total)\n",
    "            print('预测准确率： ', 100*correct/total)\n",
    "\n",
    "    print('Finished Training')\n",
    "    PATH = './mnist_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    #return train_acc\n",
    "\n",
    "    test_net = CNN()\n",
    "    test_net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    # 使用ImageFolder读取文件夹中的图片\n",
    "    test_data = datasets.ImageFolder(root='wave_graph/matrrial_4_test/',\n",
    "                                     transform=transform_to_mnist)\n",
    "\n",
    "    # 加载数据\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():# 进行评测的时候网络不更新梯度\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = test_net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "    print('################# 预测的标签： ')\n",
    "    print(predicted)\n",
    "    \n",
    "    pd.DataFrame(train_accs).to_csv('train_accs_material_4.txt', header=None, index=False)\n",
    "    pd.DataFrame(train_loss).to_csv('train_loss_material_4.txt', header=None, index=False)\n",
    "    \n",
    "    FINAL_EMB = output_embedding(ALL_EMBEDDINGS)\n",
    "    pd.DataFrame(FINAL_EMB).to_csv('FINAL_EMB_material_4.txt', header=None, index=False)\n",
    "    \n",
    "    FINAL_LABELS = output_labels(ALL_LABELS)\n",
    "    pd.DataFrame(FINAL_LABELS).to_csv('FINAL_LABELS_material_4.txt', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ce6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### 第二题\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 指定engine为openpyxl\n",
    "material_1_data = pd.read_excel('train_data.xlsx', engine='openpyxl', sheet_name='材料1')\n",
    "\n",
    "material_1_data = material_1_data[material_1_data.iloc[:, 3] == '正弦波']\n",
    "\n",
    "all_tem_list = np.array(material_1_data.iloc[:, 0])\n",
    "tem_25_index = np.argwhere(all_tem_list==25).flatten()[:10]\n",
    "tem_50_index = np.argwhere(all_tem_list==50).flatten()[:10]\n",
    "tem_70_index = np.argwhere(all_tem_list==70).flatten()[:10]\n",
    "tem_90_index = np.argwhere(all_tem_list==90).flatten()[:10]\n",
    "\n",
    "example_index = np.append(tem_25_index, tem_50_index)\n",
    "example_index = np.append(example_index, tem_70_index)\n",
    "example_index = np.append(example_index, tem_90_index)\n",
    "\n",
    "###################### 全部训练（温度不log）#######################\n",
    "all_tem_data = np.array(material_1_data.iloc[:, 0])\n",
    "tem_max_val = np.max(all_tem_data)\n",
    "all_tem_data = all_tem_data / tem_max_val\n",
    "\n",
    "all_true_P = np.array(material_1_data.iloc[:, 2])\n",
    "all_true_P_max_val = np.max(all_true_P)\n",
    "all_normalized_true_P = all_true_P/all_true_P_max_val\n",
    "all_true_P = np.log(all_normalized_true_P)\n",
    "\n",
    "all_used_f = np.array(material_1_data.iloc[:, 1])\n",
    "all_used_f_max_val = np.max(all_used_f)\n",
    "all_normalized_used_f = all_used_f/all_used_f_max_val\n",
    "all_used_f = np.log(all_normalized_used_f)\n",
    "\n",
    "all_ALL_DENSITY = material_1_data.iloc[:, 4:]\n",
    "all_used_B_M = all_ALL_DENSITY.max(axis=1)\n",
    "all_used_B_M_max_val = np.max(all_used_B_M)\n",
    "all_normalized_used_B_M = all_used_B_M/all_used_B_M_max_val\n",
    "all_used_B_M = np.log(all_normalized_used_B_M)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "x_tensor = torch.Tensor(all_used_B_M)\n",
    "z_tensor = torch.Tensor(all_used_f)\n",
    "t_tensor = torch.Tensor(all_tem_data)\n",
    "y_tensor = torch.Tensor(all_true_P)\n",
    "\n",
    "x_tensor = x_tensor.unsqueeze(1)\n",
    "y_tensor = y_tensor.unsqueeze(1)\n",
    "t_tensor = t_tensor.unsqueeze(1)\n",
    "z_tensor = z_tensor.unsqueeze(1)\n",
    "\n",
    "# 将x和z合并为输入\n",
    "inputs = torch.cat([x_tensor, z_tensor, t_tensor], dim=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, y_tensor, test_size=0.1, random_state=42)\n",
    "\n",
    "# 定义简单的线性神经网络\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # 初始化一个全连接层，输入两个特征，输出一个值\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "        \n",
    "        # 强制初始化参数a和b的范围在[1, 3]和[2, 3]之间\n",
    "        with torch.no_grad():\n",
    "            self.linear.weight[:, 0].uniform_(1, 3)  # 限制a的范围\n",
    "            self.linear.weight[:, 1].uniform_(2, 3)  # 限制b的范围\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 初始化模型\n",
    "model = LinearModel()\n",
    "\n",
    "# 损失函数: 均方误差\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 优化器: 随机梯度下降\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 1200\n",
    "for epoch in range(epochs):\n",
    "    # 前向传播\n",
    "    outputs = model(x_train)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 打印损失值\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 评估模型在测试集上的表现\n",
    "model.eval()  # 切换到评估模式，禁用dropout等\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(x_test)  # 使用测试集进行预测\n",
    "    test_loss = criterion(test_outputs, y_test)  # 计算测试集上的均方误差\n",
    "print(f\"测试集上的损失（均方误差）: {test_loss.item():.4f}\")\n",
    "\n",
    "pre_y = np.array(test_outputs.flatten())\n",
    "tru_y = np.array(y_test.flatten())\n",
    "r2_index = r2_score(tru_y, pre_y)\n",
    "mae_index = mean_absolute_error(tru_y, pre_y)\n",
    "print(f\"测试集上的决定系数: {r2_index.item():.4f}\")\n",
    "print(f\"测试集上的mae: {mae_index.item():.4f}\")\n",
    "\n",
    "\n",
    "example_inputs = inputs[example_index]\n",
    "# 评估模型在测试集上的表现\n",
    "model.eval()  # 切换到评估模式，禁用dropout等\n",
    "with torch.no_grad():\n",
    "    example_outputs = model(example_inputs)  # 使用测试集进行预测\n",
    "    print('##################### 预测值：')\n",
    "    print(np.exp(np.array(example_outputs.flatten()))*all_true_P_max_val) \n",
    "\n",
    "# 打印模型拟合的参数\n",
    "with torch.no_grad():\n",
    "    print(\"Learned parameters (BETA_PREDICTED, ALPHA_PREDICTED, K_PREDICTED):\")\n",
    "    BETA_PREDICTED, ALPHA_PREDICTED, T_PREDICTED = model.linear.weight[0].numpy()\n",
    "    K_PREDICTED = model.linear.bias.item()\n",
    "    print(f\"beta = {BETA_PREDICTED}, alpha = {ALPHA_PREDICTED}, t = {T_PREDICTED}, k = {K_PREDICTED}\")\n",
    "    \n",
    "    \n",
    "    ############################### 全部训练（不用温度）####################\n",
    "# 将x和z合并为输入\n",
    "inputs = torch.cat([x_tensor, z_tensor], dim=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, y_tensor, test_size=0.1, random_state=42)\n",
    "\n",
    "# 定义简单的线性神经网络\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # 初始化一个全连接层，输入两个特征，输出一个值\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        \n",
    "        # 强制初始化参数a和b的范围在[1, 3]和[2, 3]之间\n",
    "        with torch.no_grad():\n",
    "            self.linear.weight[:, 0].uniform_(1, 3)  # 限制a的范围\n",
    "            self.linear.weight[:, 1].uniform_(2, 3)  # 限制b的范围\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 初始化模型\n",
    "model = LinearModel()\n",
    "\n",
    "# 损失函数: 均方误差\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 优化器: 随机梯度下降\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    # 前向传播\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 打印损失值\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 评估模型在测试集上的表现\n",
    "model.eval()  # 切换到评估模式，禁用dropout等\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(x_test)  # 使用测试集进行预测\n",
    "    test_loss = criterion(test_outputs, y_test)  # 计算测试集上的均方误差\n",
    "print(f\"测试集上的损失（均方误差）: {test_loss.item():.4f}\")\n",
    "\n",
    "pre_y = np.array(test_outputs.flatten())\n",
    "tru_y = np.array(y_test.flatten())\n",
    "r2_index = r2_score(tru_y, pre_y)\n",
    "mae_index = mean_absolute_error(tru_y, pre_y)\n",
    "print(f\"测试集上的决定系数: {r2_index.item():.4f}\")\n",
    "print(f\"测试集上的mae: {mae_index.item():.4f}\")\n",
    "\n",
    "\n",
    "example_inputs = inputs[example_index]\n",
    "# 评估模型在测试集上的表现\n",
    "model.eval()  # 切换到评估模式，禁用dropout等\n",
    "with torch.no_grad():\n",
    "    example_outputs = model(example_inputs)  # 使用测试集进行预测\n",
    "    print('##################### 预测值：')\n",
    "    print(np.exp(np.array(example_outputs.flatten()))*all_true_P_max_val) \n",
    "        \n",
    "# 打印模型拟合的参数\n",
    "with torch.no_grad():\n",
    "    print(\"Learned parameters (BETA_PREDICTED, ALPHA_PREDICTED, K_PREDICTED):\")\n",
    "    BETA_PREDICTED, ALPHA_PREDICTED = model.linear.weight[0].numpy()\n",
    "    K_PREDICTED = model.linear.bias.item()\n",
    "    print(f\"beta = {BETA_PREDICTED}, alpha = {ALPHA_PREDICTED}, k = {K_PREDICTED}\")\n",
    "    \n",
    "###################### 全部训练（温度log）#######################\n",
    "all_tem_data = np.array(material_1_data.iloc[:, 0])\n",
    "tem_max_val = np.max(all_tem_data)\n",
    "all_tem_data = all_tem_data / tem_max_val\n",
    "all_tem_data = np.log(all_tem_data)\n",
    "\n",
    "all_true_P = np.array(material_1_data.iloc[:, 2])\n",
    "all_true_P_max_val = np.max(all_true_P)\n",
    "all_normalized_true_P = all_true_P/all_true_P_max_val\n",
    "all_true_P = np.log(all_normalized_true_P)\n",
    "\n",
    "all_used_f = np.array(material_1_data.iloc[:, 1])\n",
    "all_used_f_max_val = np.max(all_used_f)\n",
    "all_normalized_used_f = all_used_f/all_used_f_max_val\n",
    "all_used_f = np.log(all_normalized_used_f)\n",
    "\n",
    "all_ALL_DENSITY = material_1_data.iloc[:, 4:]\n",
    "all_used_B_M = all_ALL_DENSITY.max(axis=1)\n",
    "all_used_B_M_max_val = np.max(all_used_B_M)\n",
    "all_normalized_used_B_M = all_used_B_M/all_used_B_M_max_val\n",
    "all_used_B_M = np.log(all_normalized_used_B_M)\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "x_tensor = torch.Tensor(all_used_B_M)\n",
    "z_tensor = torch.Tensor(all_used_f)\n",
    "t_tensor = torch.Tensor(all_tem_data)\n",
    "y_tensor = torch.Tensor(all_true_P)\n",
    "\n",
    "x_tensor = x_tensor.unsqueeze(1)\n",
    "y_tensor = y_tensor.unsqueeze(1)\n",
    "t_tensor = t_tensor.unsqueeze(1)\n",
    "z_tensor = z_tensor.unsqueeze(1)\n",
    "\n",
    "# 将x和z合并为输入\n",
    "inputs = torch.cat([x_tensor, z_tensor, t_tensor], dim=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, y_tensor, test_size=0.01, random_state=42)\n",
    "\n",
    "# 定义简单的线性神经网络\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # 初始化一个全连接层，输入两个特征，输出一个值\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "        \n",
    "        # 强制初始化参数a和b的范围在[1, 3]和[2, 3]之间\n",
    "        with torch.no_grad():\n",
    "            self.linear.weight[:, 0].uniform_(1, 3)  # 限制a的范围\n",
    "            self.linear.weight[:, 1].uniform_(2, 3)  # 限制b的范围\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 初始化模型\n",
    "model = LinearModel()\n",
    "\n",
    "# 损失函数: 均方误差\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 优化器: 随机梯度下降\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 1500\n",
    "for epoch in range(epochs):\n",
    "    # 前向传播\n",
    "    outputs = model(x_train)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 打印损失值\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 评估模型在测试集上的表现\n",
    "model.eval()  # 切换到评估模式，禁用dropout等\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(x_test)  # 使用测试集进行预测\n",
    "    test_loss = criterion(test_outputs, y_test)  # 计算测试集上的均方误差\n",
    "print(f\"测试集上的损失（均方误差）: {test_loss.item():.4f}\")\n",
    "\n",
    "pre_y = np.array(test_outputs.flatten())\n",
    "tru_y = np.array(y_test.flatten())\n",
    "r2_index = r2_score(tru_y, pre_y)\n",
    "mae_index = mean_absolute_error(tru_y, pre_y)\n",
    "print(f\"测试集上的决定系数: {r2_index.item():.4f}\")\n",
    "print(f\"测试集上的mae: {mae_index.item():.4f}\")\n",
    "\n",
    "\n",
    "example_inputs = inputs[example_index]\n",
    "# 评估模型在测试集上的表现\n",
    "model.eval()  # 切换到评估模式，禁用dropout等\n",
    "with torch.no_grad():\n",
    "    example_outputs = model(example_inputs)  # 使用测试集进行预测\n",
    "    print('##################### 预测值：')\n",
    "    print(np.exp(np.array(example_outputs.flatten()))*all_true_P_max_val) \n",
    "\n",
    "# 打印模型拟合的参数\n",
    "with torch.no_grad():\n",
    "    print(\"Learned parameters (BETA_PREDICTED, ALPHA_PREDICTED, K_PREDICTED):\")\n",
    "    BETA_PREDICTED, ALPHA_PREDICTED, T_PREDICTED = model.linear.weight[0].numpy()\n",
    "    K_PREDICTED = model.linear.bias.item()\n",
    "    print(f\"beta = {BETA_PREDICTED}, alpha = {ALPHA_PREDICTED}, t = {T_PREDICTED}, k = {K_PREDICTED}\")\n",
    "\n",
    "\n",
    "########################## 按温度拟合 #############################\n",
    "material_1_tem_25_data = material_1_data[material_1_data.iloc[:, 0] == 25]\n",
    "material_1_tem_50_data = material_1_data[material_1_data.iloc[:, 0] == 50]\n",
    "material_1_tem_70_data = material_1_data[material_1_data.iloc[:, 0] == 70]\n",
    "material_1_tem_90_data = material_1_data[material_1_data.iloc[:, 0] == 90]\n",
    "\n",
    "true_P_25 = np.array(material_1_tem_25_data.iloc[:, 2])\n",
    "true_P_max_val_25 = np.max(true_P_25)\n",
    "normalized_true_P_25 = true_P_25/true_P_max_val_25\n",
    "true_P_25 = np.log(normalized_true_P_25)\n",
    "\n",
    "used_f_25 = np.array(material_1_tem_25_data.iloc[:, 1])\n",
    "used_f_max_val_25 = np.max(used_f_25)\n",
    "normalized_used_f_25 = used_f_25/used_f_max_val_25\n",
    "used_f_25 = np.log(normalized_used_f_25)\n",
    "\n",
    "ALL_DENSITY_25 = material_1_tem_25_data.iloc[:, 4:]\n",
    "used_B_M_25 = ALL_DENSITY_25.max(axis=1)\n",
    "used_B_M_max_val_25 = np.max(used_B_M_25)\n",
    "normalized_used_B_M_25 = used_B_M_25/used_B_M_max_val_25\n",
    "used_B_M_25 = np.log(normalized_used_B_M_25)\n",
    "used_B_M_25 = np.array(used_B_M_25)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "x_tensor_25 = torch.Tensor(used_B_M_25)\n",
    "z_tensor_25 = torch.Tensor(used_f_25)\n",
    "y_tensor_25 = torch.Tensor(true_P_25)\n",
    "\n",
    "x_tensor_25 = x_tensor_25.unsqueeze(1)\n",
    "y_tensor_25 = y_tensor_25.unsqueeze(1)\n",
    "z_tensor_25 = z_tensor_25.unsqueeze(1)\n",
    "\n",
    "# 将x和z合并为输入\n",
    "inputs_25 = torch.cat([x_tensor_25, z_tensor_25], dim=1)\n",
    "\n",
    "x_train_25, x_test_25, y_train_25, y_test_25 = train_test_split(inputs_25, y_tensor_25, test_size=0.1, random_state=42)\n",
    "    \n",
    "true_P_50 = np.array(material_1_tem_50_data.iloc[:, 2])\n",
    "true_P_max_val_50 = np.max(true_P_50)\n",
    "normalized_true_P_50 = true_P_50/true_P_max_val_50\n",
    "true_P_50 = np.log(normalized_true_P_50)\n",
    "\n",
    "used_f_50 = np.array(material_1_tem_50_data.iloc[:, 1])\n",
    "used_f_max_val_50 = np.max(used_f_50)\n",
    "normalized_used_f_50 = used_f_50/used_f_max_val_50\n",
    "used_f_50 = np.log(normalized_used_f_50)\n",
    "\n",
    "ALL_DENSITY_50 = material_1_tem_50_data.iloc[:, 4:]\n",
    "used_B_M_50 = ALL_DENSITY_50.max(axis=1)\n",
    "used_B_M_max_val_50 = np.max(used_B_M_50)\n",
    "normalized_used_B_M_50 = used_B_M_50/used_B_M_max_val_50\n",
    "used_B_M_50 = np.log(normalized_used_B_M_50)\n",
    "used_B_M_50 = np.array(used_B_M_50)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "x_tensor_50 = torch.Tensor(used_B_M_50)\n",
    "z_tensor_50 = torch.Tensor(used_f_50)\n",
    "y_tensor_50 = torch.Tensor(true_P_50)\n",
    "\n",
    "x_tensor_50 = x_tensor_50.unsqueeze(1)\n",
    "y_tensor_50 = y_tensor_50.unsqueeze(1)\n",
    "z_tensor_50 = z_tensor_50.unsqueeze(1)\n",
    "\n",
    "# 将x和z合并为输入\n",
    "inputs_50 = torch.cat([x_tensor_50, z_tensor_50], dim=1)\n",
    "\n",
    "x_train_50, x_test_50, y_train_50, y_test_50 = train_test_split(inputs_50, y_tensor_50, test_size=0.1, random_state=42)\n",
    "\n",
    "true_P_70 = np.array(material_1_tem_70_data.iloc[:, 2])\n",
    "true_P_max_val_70 = np.max(true_P_70)\n",
    "normalized_true_P_70 = true_P_70/true_P_max_val_70\n",
    "true_P_70 = np.log(normalized_true_P_70)\n",
    "\n",
    "used_f_70 = np.array(material_1_tem_70_data.iloc[:, 1])\n",
    "used_f_max_val_70 = np.max(used_f_70)\n",
    "normalized_used_f_70 = used_f_70/used_f_max_val_70\n",
    "used_f_70 = np.log(normalized_used_f_70)\n",
    "\n",
    "ALL_DENSITY_70 = material_1_tem_70_data.iloc[:, 4:]\n",
    "used_B_M_70 = ALL_DENSITY_70.max(axis=1)\n",
    "used_B_M_max_val_70 = np.max(used_B_M_70)\n",
    "normalized_used_B_M_70 = used_B_M_70/used_B_M_max_val_70\n",
    "used_B_M_70 = np.log(normalized_used_B_M_70)\n",
    "used_B_M_70 = np.array(used_B_M_70)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "x_tensor_70 = torch.Tensor(used_B_M_70)\n",
    "z_tensor_70 = torch.Tensor(used_f_70)\n",
    "y_tensor_70 = torch.Tensor(true_P_70)\n",
    "\n",
    "x_tensor_70 = x_tensor_70.unsqueeze(1)\n",
    "y_tensor_70 = y_tensor_70.unsqueeze(1)\n",
    "z_tensor_70 = z_tensor_70.unsqueeze(1)\n",
    "\n",
    "# 将x和z合并为输入\n",
    "inputs_70 = torch.cat([x_tensor_70, z_tensor_70], dim=1)\n",
    "\n",
    "x_train_70, x_test_70, y_train_70, y_test_70 = train_test_split(inputs_70, y_tensor_70, test_size=0.1, random_state=42)\n",
    "\n",
    "true_P_90 = np.array(material_1_tem_90_data.iloc[:, 2])\n",
    "true_P_max_val_90 = np.max(true_P_90)\n",
    "normalized_true_P_90 = true_P_90/true_P_max_val_90\n",
    "true_P_90 = np.log(normalized_true_P_90)\n",
    "\n",
    "used_f_90 = np.array(material_1_tem_90_data.iloc[:, 1])\n",
    "used_f_max_val_90 = np.max(used_f_90)\n",
    "normalized_used_f_90 = used_f_90/used_f_max_val_90\n",
    "used_f_90 = np.log(normalized_used_f_90)\n",
    "\n",
    "ALL_DENSITY_90 = material_1_tem_90_data.iloc[:, 4:]\n",
    "used_B_M_90 = ALL_DENSITY_90.max(axis=1)\n",
    "used_B_M_max_val_90 = np.max(used_B_M_90)\n",
    "normalized_used_B_M_90 = used_B_M_90/used_B_M_max_val_90\n",
    "used_B_M_90 = np.log(normalized_used_B_M_90)\n",
    "used_B_M_90 = np.array(used_B_M_90)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "x_tensor_90 = torch.Tensor(used_B_M_90)\n",
    "z_tensor_90 = torch.Tensor(used_f_90)\n",
    "y_tensor_90 = torch.Tensor(true_P_90)\n",
    "\n",
    "x_tensor_90 = x_tensor_90.unsqueeze(1)\n",
    "y_tensor_90 = y_tensor_90.unsqueeze(1)\n",
    "z_tensor_90 = z_tensor_90.unsqueeze(1)\n",
    "\n",
    "# 将x和z合并为输入\n",
    "inputs_90 = torch.cat([x_tensor_90, z_tensor_90], dim=1)\n",
    "\n",
    "x_train_90, x_test_90, y_train_90, y_test_90 = train_test_split(inputs_90, y_tensor_90, test_size=0.1, random_state=42)\n",
    "\n",
    "# 定义简单的线性神经网络\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # 初始化一个全连接层，输入两个特征，输出一个值\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        \n",
    "        # 强制初始化参数a和b的范围在[1, 3]和[2, 3]之间\n",
    "        with torch.no_grad():\n",
    "            self.linear.weight[:, 0].uniform_(1, 3)  # 限制a的范围\n",
    "            self.linear.weight[:, 1].uniform_(2, 3)  # 限制b的范围\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def train_and_test(X_TRAIN, Y_TRAIN, \n",
    "                   X_TEST, Y_TEST, \n",
    "                   INPUT_1, OUTPUT_1, \n",
    "                   INPUT_2, OUTPUT_2, \n",
    "                   INPUT_3, OUTPUT_3):\n",
    "    # 初始化模型\n",
    "    model = LinearModel()\n",
    "\n",
    "    # 损失函数: 均方误差\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 优化器: 随机梯度下降\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    # 训练模型\n",
    "    epochs = 1000\n",
    "    for epoch in range(epochs):\n",
    "        # 前向传播\n",
    "        outputs = model(X_TRAIN)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, Y_TRAIN)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印损失值\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # 评估模型在测试集上的表现\n",
    "    model.eval()  # 切换到评估模式，禁用dropout等\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_TEST)  # 使用测试集进行预测\n",
    "        test_loss = criterion(test_outputs, Y_TEST)  # 计算测试集上的均方误差\n",
    "    print(f\"测试集上的损失（均方误差）: {test_loss.item():.4f}\")\n",
    "    \n",
    "    \n",
    "    # 评估模型在测试集上的表现\n",
    "    model.eval()  # 切换到评估模式，禁用dropout等\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(INPUT_1)  # 使用测试集进行预测\n",
    "        test_loss = criterion(test_outputs, OUTPUT_1)  # 计算测试集上的均方误差\n",
    "    print(f\"测试集上的损失（均方误差）: {test_loss.item():.4f}\")\n",
    "    \n",
    "    # 评估模型在测试集上的表现\n",
    "    model.eval()  # 切换到评估模式，禁用dropout等\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(INPUT_2)  # 使用测试集进行预测\n",
    "        test_loss = criterion(test_outputs, OUTPUT_2)  # 计算测试集上的均方误差\n",
    "    print(f\"测试集上的损失（均方误差）: {test_loss.item():.4f}\")\n",
    "    \n",
    "    # 评估模型在测试集上的表现\n",
    "    model.eval()  # 切换到评估模式，禁用dropout等\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(INPUT_3)  # 使用测试集进行预测\n",
    "        test_loss = criterion(test_outputs, OUTPUT_3)  # 计算测试集上的均方误差\n",
    "    print(f\"测试集上的损失（均方误差）: {test_loss.item():.4f}\")\n",
    "\n",
    "    # 打印模型拟合的参数\n",
    "    with torch.no_grad():\n",
    "        print(\"Learned parameters (BETA_PREDICTED, ALPHA_PREDICTED, K_PREDICTED):\")\n",
    "        BETA_PREDICTED, ALPHA_PREDICTED = model.linear.weight[0].numpy()\n",
    "        K_PREDICTED = model.linear.bias.item()\n",
    "        print(f\"beta = {BETA_PREDICTED}, alpha = {ALPHA_PREDICTED}, k = {K_PREDICTED}\")\n",
    "        \n",
    "    train_and_test(x_train_25, y_train_25, \n",
    "               x_test_25, y_test_25, \n",
    "               inputs_50, y_tensor_50, \n",
    "               inputs_70, y_tensor_70, \n",
    "               inputs_90, y_tensor_90)\n",
    "    \n",
    "    train_and_test(x_train_50, y_train_50, \n",
    "               x_test_50, y_test_50,\n",
    "               inputs_25, y_tensor_25, \n",
    "               inputs_70, y_tensor_70, \n",
    "               inputs_90, y_tensor_90)\n",
    "    \n",
    "    train_and_test(x_train_70, y_train_70, \n",
    "               x_test_70, y_test_70, \n",
    "               inputs_25, y_tensor_25, \n",
    "               inputs_50, y_tensor_50, \n",
    "               inputs_90, y_tensor_90)\n",
    "    \n",
    "    train_and_test(x_train_90, y_train_90, \n",
    "               x_test_90, y_test_90, \n",
    "               inputs_25, y_tensor_25, \n",
    "               inputs_50, y_tensor_50,\n",
    "               inputs_70, y_tensor_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cdce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### 第四题 #####################################\n",
    "###################### 不进行特征提取\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "material_1_data = pd.read_excel('train_data.xlsx', engine='openpyxl', sheet_name='材料1')\n",
    "material_2_data = pd.read_excel('train_data.xlsx', engine='openpyxl', sheet_name='材料2')\n",
    "material_3_data = pd.read_excel('train_data.xlsx', engine='openpyxl', sheet_name='材料3')、\n",
    "material_4_data = pd.read_excel('train_data.xlsx', engine='openpyxl', sheet_name='材料4')\n",
    "\n",
    "material_1_feature = material_1_data.iloc[:, :2]\n",
    "material_1_DENSITY = np.array(material_1_data.iloc[:, 4:])\n",
    "material_1_DENSITY_MAX = material_1_DENSITY.max(axis=1)\n",
    "material_1_DENSITY_MIN = material_1_DENSITY.min(axis=1)\n",
    "\n",
    "# material_1_DENSITY_feature = np.column_stack((material_1_DENSITY_MAX, material_1_DENSITY_MIN))\n",
    "\n",
    "material_1_feature = np.array(material_1_feature)\n",
    "wave_shape = list(np.array(material_1_data.iloc[:, 3]))\n",
    "wave_ont_hot_encode = []\n",
    "for i in range(len(wave_shape)):\n",
    "    if wave_shape[i] == '正弦波':\n",
    "        wave_ont_hot_encode.append([0, 0, 1])\n",
    "    elif wave_shape[i] == '三角波':\n",
    "        wave_ont_hot_encode.append([0, 1, 0])\n",
    "    elif wave_shape[i] == '梯形波':\n",
    "        wave_ont_hot_encode.append([1, 0, 0])\n",
    "    else:\n",
    "        print('############# error !')\n",
    "        \n",
    "wave_ont_hot_encode = np.array(wave_ont_hot_encode)\n",
    "material_1_feature = np.hstack((material_1_feature, wave_ont_hot_encode))\n",
    "# material_1_feature = np.hstack((material_1_feature, material_1_DENSITY_feature))\n",
    "material_1_feature = np.hstack((material_1_feature, material_1_DENSITY))\n",
    "material_1_type_feature = np.tile([1, 0, 0, 0], (material_1_feature.shape[0], 1))\n",
    "material_1_input_feature = np.hstack((material_1_type_feature, material_1_feature))\n",
    "\n",
    "material_1_output = np.array(material_1_data.iloc[:, 2])\n",
    "material_1_input_data = np.column_stack((material_1_input_feature, material_1_output))\n",
    "\n",
    "material_2_feature = material_2_data.iloc[:, :2]\n",
    "material_2_DENSITY = np.array(material_2_data.iloc[:, 4:])\n",
    "material_2_DENSITY_MAX = material_2_DENSITY.max(axis=1)\n",
    "material_2_DENSITY_MIN = material_2_DENSITY.min(axis=1)\n",
    "\n",
    "# material_2_DENSITY_feature = np.column_stack((material_2_DENSITY_MAX, material_2_DENSITY_MIN))\n",
    "\n",
    "material_2_feature = np.array(material_2_feature)\n",
    "wave_shape = list(np.array(material_2_data.iloc[:, 3]))\n",
    "wave_ont_hot_encode = []\n",
    "for i in range(len(wave_shape)):\n",
    "    if wave_shape[i] == '正弦波':\n",
    "        wave_ont_hot_encode.append([0, 0, 1])\n",
    "    elif wave_shape[i] == '三角波':\n",
    "        wave_ont_hot_encode.append([0, 1, 0])\n",
    "    elif wave_shape[i] == '梯形波':\n",
    "        wave_ont_hot_encode.append([1, 0, 0])\n",
    "    else:\n",
    "        print('############# error !')\n",
    "        \n",
    "wave_ont_hot_encode = np.array(wave_ont_hot_encode)\n",
    "material_2_feature = np.hstack((material_2_feature, wave_ont_hot_encode))\n",
    "# material_2_feature = np.hstack((material_2_feature, material_2_DENSITY_feature))\n",
    "material_2_feature = np.hstack((material_2_feature, material_2_DENSITY))\n",
    "material_2_type_feature = np.tile([0, 1, 0, 0], (material_2_feature.shape[0], 1))\n",
    "material_2_input_feature = np.hstack((material_2_type_feature, material_2_feature))\n",
    "\n",
    "material_2_output = np.array(material_2_data.iloc[:, 2])\n",
    "material_2_input_data = np.column_stack((material_2_input_feature, material_2_output))\n",
    "\n",
    "material_3_feature = material_3_data.iloc[:, :2]\n",
    "material_3_DENSITY = np.array(material_3_data.iloc[:, 4:])\n",
    "material_3_DENSITY_MAX = material_3_DENSITY.max(axis=1)\n",
    "material_3_DENSITY_MIN = material_3_DENSITY.min(axis=1)\n",
    "\n",
    "# material_3_DENSITY_feature = np.column_stack((material_3_DENSITY_MAX, material_3_DENSITY_MIN))\n",
    "\n",
    "material_3_feature = np.array(material_3_feature)\n",
    "wave_shape = list(np.array(material_3_data.iloc[:, 3]))\n",
    "wave_ont_hot_encode = []\n",
    "for i in range(len(wave_shape)):\n",
    "    if wave_shape[i] == '正弦波':\n",
    "        wave_ont_hot_encode.append([0, 0, 1])\n",
    "    elif wave_shape[i] == '三角波':\n",
    "        wave_ont_hot_encode.append([0, 1, 0])\n",
    "    elif wave_shape[i] == '梯形波':\n",
    "        wave_ont_hot_encode.append([1, 0, 0])\n",
    "    else:\n",
    "        print('############# error !')\n",
    "        \n",
    "wave_ont_hot_encode = np.array(wave_ont_hot_encode)\n",
    "material_3_feature = np.hstack((material_3_feature, wave_ont_hot_encode))\n",
    "# material_3_feature = np.hstack((material_3_feature, material_3_DENSITY_feature))\n",
    "material_3_feature = np.hstack((material_3_feature, material_3_DENSITY))\n",
    "material_3_type_feature = np.tile([0, 0, 1, 0], (material_3_feature.shape[0], 1))\n",
    "material_3_input_feature = np.hstack((material_3_type_feature, material_3_feature))\n",
    "\n",
    "material_3_output = np.array(material_3_data.iloc[:, 2])\n",
    "material_3_input_data = np.column_stack((material_3_input_feature, material_3_output))\n",
    "\n",
    "material_4_feature = material_4_data.iloc[:, :2]\n",
    "material_4_DENSITY = np.array(material_4_data.iloc[:, 4:])\n",
    "material_4_DENSITY_MAX = material_4_DENSITY.max(axis=1)\n",
    "material_4_DENSITY_MIN = material_4_DENSITY.min(axis=1)\n",
    "\n",
    "# material_4_DENSITY_feature = np.column_stack((material_4_DENSITY_MAX, material_4_DENSITY_MIN))\n",
    "\n",
    "material_4_feature = np.array(material_4_feature)\n",
    "wave_shape = list(np.array(material_4_data.iloc[:, 3]))\n",
    "wave_ont_hot_encode = []\n",
    "for i in range(len(wave_shape)):\n",
    "    if wave_shape[i] == '正弦波':\n",
    "        wave_ont_hot_encode.append([0, 0, 1])\n",
    "    elif wave_shape[i] == '三角波':\n",
    "        wave_ont_hot_encode.append([0, 1, 0])\n",
    "    elif wave_shape[i] == '梯形波':\n",
    "        wave_ont_hot_encode.append([1, 0, 0])\n",
    "    else:\n",
    "        print('############# error !')\n",
    "        \n",
    "wave_ont_hot_encode = np.array(wave_ont_hot_encode)\n",
    "material_4_feature = np.hstack((material_4_feature, wave_ont_hot_encode))\n",
    "# material_4_feature = np.hstack((material_4_feature, material_4_DENSITY_feature))\n",
    "material_4_feature = np.hstack((material_4_feature, material_4_DENSITY))\n",
    "\n",
    "material_4_type_feature = np.tile([0, 0, 0, 1], (material_4_feature.shape[0], 1))\n",
    "material_4_input_feature = np.hstack((material_4_type_feature, material_4_feature))\n",
    "\n",
    "material_4_output = np.array(material_4_data.iloc[:, 2])\n",
    "material_4_input_data = np.column_stack((material_4_input_feature, material_4_output))\n",
    "\n",
    "all_input_data = np.vstack((material_1_input_data, material_2_input_data, material_3_input_data, material_4_input_data))\n",
    "pd.DataFrame(all_input_data).to_csv('wave_data_all.txt', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762848da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel('test_3.xlsx', engine='openpyxl')\n",
    "material_type = np.array(test_data.iloc[:, 3])\n",
    "wave_type = np.array(test_data.iloc[:, 4])\n",
    "\n",
    "wave_type_ont_hot = []\n",
    "for i in range(wave_type.shape[0]):\n",
    "    if wave_type[i] == '正弦波':\n",
    "        wave_type_ont_hot.append([0, 0, 1])\n",
    "    elif wave_type[i] == '三角波':\n",
    "        wave_type_ont_hot.append([0, 1, 0])\n",
    "    elif wave_type[i] == '梯形波':\n",
    "        wave_type_ont_hot.append([1, 0, 0])\n",
    "    else:\n",
    "        print('############ error!')\n",
    "        \n",
    "material_type_ont_hot = []\n",
    "for i in range(material_type.shape[0]):\n",
    "    if material_type[i] == '材料1':\n",
    "        material_type_ont_hot.append([1, 0, 0, 0])\n",
    "    elif material_type[i] == '材料2':\n",
    "        material_type_ont_hot.append([0, 1, 0, 0])\n",
    "    elif material_type[i] == '材料3':\n",
    "        material_type_ont_hot.append([0, 0, 1, 0])\n",
    "    elif material_type[i] == '材料4':\n",
    "        material_type_ont_hot.append([0, 0, 0, 1]) \n",
    "    else:\n",
    "        print('############ error!')\n",
    "        \n",
    "material_feature = np.array(test_data.iloc[:, 1:3])\n",
    "material_DENSITY = np.array(test_data.iloc[:, 5:])\n",
    "material_feature = np.hstack((material_feature, wave_type_ont_hot))\n",
    "material_feature = np.hstack((material_feature, material_DENSITY))\n",
    "material_test_input_feature = np.hstack((material_type_ont_hot, material_feature))\n",
    "\n",
    "material_feature = np.array(test_data.iloc[:, 1:3])\n",
    "material_DENSITY = np.array(test_data.iloc[:, 5:])\n",
    "material_feature = np.hstack((material_feature, wave_type_ont_hot))\n",
    "material_feature = np.hstack((material_feature, material_DENSITY))\n",
    "material_test_input_feature = np.hstack((material_type_ont_hot, material_feature))\n",
    "pd.DataFrame(material_test_input_feature).to_csv('test_predict_data_all.txt', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340eaef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### 提取特征\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1)\n",
    "        self.fc1 = nn.Linear(128*7*7,256)#两个池化，所以是7*7而不是14*14\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64,3)\n",
    "        self.dp = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(-1, 128 * 7* 7)#将数据平整为一维的 \n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x = self.fc3(x)\n",
    "#         self.dp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "#         x = F.log_softmax(x,dim=1) NLLLoss()才需要，交叉熵不需要\n",
    "        return x\n",
    "\n",
    "def output_embedding(embeddings):\n",
    "    final_embeddings = np.array(embeddings[0].cpu())\n",
    "    for i in range(1, len(embeddings)):\n",
    "        batch_embedding = np.array(embeddings[i].cpu())\n",
    "        final_embeddings = np.vstack((final_embeddings, batch_embedding))\n",
    "    return final_embeddings\n",
    "\n",
    "def output_labels(input_labels):\n",
    "    final_labels = np.array(input_labels[0].cpu())\n",
    "    for i in range(1, len(input_labels)):\n",
    "        batch_labels = np.array(input_labels[i].cpu())\n",
    "        final_labels = np.append(final_labels, batch_labels)\n",
    "    return final_labels\n",
    "\n",
    "def train():\n",
    "        # 定义转换流程，将RGB图像转换为灰度图像并调整大小到28x28，归一化到[0, 1]范围\n",
    "    transform_to_mnist = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # 转换为单通道灰度图像\n",
    "        transforms.Resize((28, 28)),                  # 调整图像大小为28x28\n",
    "        transforms.ToTensor(),                        # 转换为Tensor并归一化到[0, 1]范          \n",
    "        transforms.Lambda(lambda x: 1 - x)            # 反转颜色，将白底变为黑底\n",
    "    ])\n",
    "\n",
    "    # 使用ImageFolder读取文件夹中的图片\n",
    "    train_data = datasets.ImageFolder(root='wave_graph/all_material_new/',\n",
    "                                      transform=transform_to_mnist)\n",
    "\n",
    "    # 加载数据\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "    # 查看数据集中的类别\n",
    "    print(train_data.classes)\n",
    "\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    total_batchs = len(train_loader)\n",
    "\n",
    "    net = CNN()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    train_accs = []\n",
    "    train_loss = []\n",
    "    test_accs = []\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = net.to(device)\n",
    "\n",
    "    ALL_EMBEDDINGS = []\n",
    "    ALL_LABELS = []\n",
    "\n",
    "    for epoch in range(11):\n",
    "        running_loss = 0.0\n",
    "        for i,data in enumerate(train_loader, 0):#0是下标起始位置默认为0\n",
    "            # data 的格式[[inputs, labels]]       \n",
    "    #         inputs,labels = data\n",
    "            inputs,labels = data[0].to(device), data[1].to(device)\n",
    "            #初始为0，清除上个batch的梯度信息\n",
    "            optimizer.zero_grad()\n",
    "            #前向+后向+优化     \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch == 10:\n",
    "                ALL_EMBEDDINGS.append(outputs.detach())\n",
    "                ALL_LABELS.append(labels.detach())\n",
    "\n",
    "            # loss 的输出，每个一百个batch输出，平均的loss\n",
    "            running_loss += loss.item()\n",
    "            if i == total_batchs-1:\n",
    "                print('[%d,%5d] loss :%.3f' %\n",
    "                     (epoch+1,i+1,running_loss/total_batchs))\n",
    "                running_loss = 0.0\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # 训练曲线的绘制 一个batch中的准确率\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = labels.size(0)# labels 的长度\n",
    "            correct = (predicted == labels).sum().item() # 预测正确的数目\n",
    "            train_accs.append(100*correct/total)\n",
    "            print('预测准确率： ', 100*correct/total)\n",
    "\n",
    "    print('Finished Training')\n",
    "    PATH = './mnist_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### 拼接特征（以材料1为例）\n",
    "file_name = pd.read_csv('ALL_FILES_NAME.txt', header=None)\n",
    "file_name = np.array(file_name)\n",
    "feature_embedding = np.array(pd.read_csv('FINAL_EMBS_ALL.txt', header=None))\n",
    "\n",
    "material_1_feature = material_1_data.iloc[:, :2]\n",
    "material_1_feature = np.array(material_1_feature)\n",
    "wave_shape = list(np.array(material_1_data.iloc[:, 3]))\n",
    "wave_ont_hot_encode = []\n",
    "for i in range(len(wave_shape)):\n",
    "    if wave_shape[i] == '正弦波':\n",
    "        wave_ont_hot_encode.append([0, 0, 1])\n",
    "    elif wave_shape[i] == '三角波':\n",
    "        wave_ont_hot_encode.append([0, 1, 0])\n",
    "    elif wave_shape[i] == '梯形波':\n",
    "        wave_ont_hot_encode.append([1, 0, 0])\n",
    "    else:\n",
    "        print('############# error !')\n",
    "\n",
    "wave_ont_hot_encode = np.array(wave_ont_hot_encode)\n",
    "material_1_feature = np.hstack((material_1_feature, wave_ont_hot_encode))\n",
    "material_1_type_feature = np.tile([1, 0, 0, 0], (material_1_feature.shape[0], 1))\n",
    "material_1_feature = np.hstack((material_1_type_feature, material_1_feature))\n",
    "\n",
    "material_1_wave_feature = np.zeros((material_1_data.shape[0], 3))\n",
    "for i in range(file_name.shape[0]):\n",
    "    if file_name[i][0].split('_')[1] == '1':\n",
    "        file_index = int(file_name[i][0].split('_')[-1].split('.')[0])\n",
    "        material_1_wave_feature[file_index] = feature_embedding[i]\n",
    "        \n",
    "material_1_inputs = np.hstack((material_1_feature, material_1_wave_feature))\n",
    "\n",
    "material_1_output = np.array(material_1_data.iloc[:, 2])\n",
    "\n",
    "material_1_input_data = np.column_stack((material_1_inputs, material_1_output))\n",
    "\n",
    "all_input_data = np.vstack((material_1_input_data, material_2_input_data, material_3_input_data, material_4_input_data))\n",
    "pd.DataFrame(all_input_data).to_csv('data_wave_feature.txt', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ 预测材料的属性\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "def train():\n",
    "    \n",
    "    test_data = pd.read_excel('test_3.xlsx', engine='openpyxl')\n",
    "    material_type = np.array(test_data.iloc[:, 3])\n",
    "    wave_type = np.array(test_data.iloc[:, 4])\n",
    "\n",
    "    wave_type_ont_hot = []\n",
    "    for i in range(wave_type.shape[0]):\n",
    "        if wave_type[i] == '正弦波':\n",
    "            wave_type_ont_hot.append([0, 0, 1])\n",
    "        elif wave_type[i] == '三角波':\n",
    "            wave_type_ont_hot.append([0, 1, 0])\n",
    "        elif wave_type[i] == '梯形波':\n",
    "            wave_type_ont_hot.append([1, 0, 0])\n",
    "        else:\n",
    "            print('############ error!')\n",
    "\n",
    "    material_type_ont_hot = []\n",
    "    for i in range(material_type.shape[0]):\n",
    "        if material_type[i] == '材料1':\n",
    "            material_type_ont_hot.append([1, 0, 0, 0])\n",
    "        elif material_type[i] == '材料2':\n",
    "            material_type_ont_hot.append([0, 1, 0, 0])\n",
    "        elif material_type[i] == '材料3':\n",
    "            material_type_ont_hot.append([0, 0, 1, 0])\n",
    "        elif material_type[i] == '材料4':\n",
    "            material_type_ont_hot.append([0, 0, 0, 1]) \n",
    "        else:\n",
    "            print('############ error!')\n",
    "\n",
    "    material_feature = np.array(test_data.iloc[:, 1:3])\n",
    "    material_DENSITY = np.array(test_data.iloc[:, 5:])\n",
    "    material_feature = np.hstack((material_feature, wave_type_ont_hot))\n",
    "    material_feature = np.hstack((material_feature, material_DENSITY))\n",
    "    material_test_input_feature = np.hstack((material_type_ont_hot, material_feature))\n",
    "\n",
    "    \n",
    "    # Load data and generate a train/test split \n",
    "    data = np.array(pd.read_csv('wave_data_all.txt', header=None))\n",
    "\n",
    "    x_max = np.amax(data, axis = 0)\n",
    "    data[:, 4:6] = np.log(data[:, 4:6]/x_max[4:6])\n",
    "    material_test_input_feature[:, 4:6] = np.log(material_test_input_feature[:, 4:6]/x_max[4:6])\n",
    "    data[:, -1:] = np.log(data[:,-1:]/x_max[-1:])\n",
    "\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "    # 初始化 CatBoostRegressor 模型\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=4000,        # 迭代次数\n",
    "        learning_rate=0.15,      # 学习率\n",
    "        depth=6,                # 树的深度\n",
    "        eval_metric='MAE',     # 使用 RMSE 作为评估指标\n",
    "        random_seed=42,\n",
    "        verbose=100             # 每100轮打印一次日志\n",
    "    )\n",
    "\n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=50)\n",
    "\n",
    "    # 预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    #y_test_pred = model.predict(material_test_input_feature)\n",
    "    # 计算均方根误差 (RMSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    \n",
    "    #return y_test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
