{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5a046d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:52:35.030251Z",
     "start_time": "2022-11-01T12:52:32.995652Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "#sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), os.pardir))\n",
    "# For replicating the experiments\n",
    "SEED = 42\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from model import LinTrans, LogReg\n",
    "from optimizer import loss_function\n",
    "from utils import *\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from clustering_metric import clustering_metrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, roc_auc_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07edf20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:52:35.093913Z",
     "start_time": "2022-11-01T12:52:35.080162Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--gnnlayers', type=int, default=1, help=\"Number of gnn layers\")\n",
    "parser.add_argument('--linlayers', type=int, default=1, help=\"Number of hidden layers\")\n",
    "parser.add_argument('--epochs', type=int, default=400, help='Number of epochs to train.')\n",
    "parser.add_argument('--dims', type=int, default=[500], help='Number of units in hidden layer 1.')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate.')\n",
    "parser.add_argument('--upth_st', type=float, default=0.0011, help='Upper Threshold start.')\n",
    "parser.add_argument('--lowth_st', type=float, default=0.1, help='Lower Threshold start.')\n",
    "parser.add_argument('--upth_ed', type=float, default=0.001, help='Upper Threshold end.')\n",
    "parser.add_argument('--lowth_ed', type=float, default=0.5, help='Lower Threshold end.')\n",
    "parser.add_argument('--upd', type=int, default=10, help='Update epoch.')\n",
    "parser.add_argument('--bs', type=int, default=100, help='Batchsize.')\n",
    "parser.add_argument('--dataset', type=str, default='karate', help='type of dataset.')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "args,_ = parser.parse_known_args()\n",
    "args.cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b9a62c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:52:35.156135Z",
     "start_time": "2022-11-01T12:52:35.142013Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_similarity(z, upper_threshold, lower_treshold, pos_num, neg_num):\n",
    "    f_adj = np.matmul(z, np.transpose(z))\n",
    "    cosine = f_adj\n",
    "    cosine = cosine.reshape([-1,])\n",
    "    pos_num = round(upper_threshold * len(cosine))\n",
    "    neg_num = round((1-lower_treshold) * len(cosine))\n",
    "    \n",
    "    pos_inds = np.argpartition(-cosine, pos_num)[:pos_num]\n",
    "    neg_inds = np.argpartition(cosine, neg_num)[:neg_num]\n",
    "    \n",
    "    return np.array(pos_inds), np.array(neg_inds)\n",
    "\n",
    "def update_threshold(upper_threshold, lower_treshold, up_eta, low_eta):\n",
    "    upth = upper_threshold + up_eta\n",
    "    lowth = lower_treshold + low_eta\n",
    "    return upth, lowth\n",
    "\n",
    "def load_network_data(adj_name, nodes_numbers):\n",
    "    if adj_name == 'karate':\n",
    "        adj_name = 'karate_edges'\n",
    "    raw_edges = pd.read_csv(\"data/\"+adj_name+\".txt\",header=None,sep=' ')\n",
    "    drop_self_loop = raw_edges[raw_edges[0]!=raw_edges[1]]\n",
    "    graph_np = np.zeros((nodes_numbers, nodes_numbers))\n",
    "    for i in range(drop_self_loop.shape[0]):\n",
    "        graph_np[drop_self_loop.iloc[i,0], drop_self_loop.iloc[i,1]]=1\n",
    "        graph_np[drop_self_loop.iloc[i,1], drop_self_loop.iloc[i,0]]=1\n",
    "    adj = nx.adjacency_matrix(nx.from_numpy_matrix(graph_np))\n",
    "    features = np.eye(nodes_numbers)\n",
    "    return adj, features\n",
    "\n",
    "def get_scores(emb, adj_orig, edges_pos, edges_neg):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    adj_rec = np.dot(emb, emb.T)\n",
    "    preds = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        pos.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        neg.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds))])\n",
    "    \n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335d3230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:52:35.233338Z",
     "start_time": "2022-11-01T12:52:35.204334Z"
    }
   },
   "outputs": [],
   "source": [
    "def gae_for(args):\n",
    "    print(\"Using {} dataset\".format(args.dataset))\n",
    "    \n",
    "    if args.dataset == 'cora':\n",
    "        nodes_number = 2708    # 这里需要输入网络的节点数量\n",
    "        n_clusters = 7     # 指定类簇数量\n",
    "    elif args.dataset == 'citeseer':\n",
    "        nodes_number = 3327    # 这里需要输入网络的节点数量\n",
    "        n_clusters = 6     # 指定类簇数量\n",
    "    elif args.dataset == 'wiki':\n",
    "        nodes_number = 2405    # 这里需要输入网络的节点数量\n",
    "        n_clusters = 17     # 指定类簇数量\n",
    "    elif args.dataset == 'celegans':\n",
    "        nodes_number = 297    # 这里需要输入网络的节点数量\n",
    "        n_clusters = 10     # 指定类簇数量\n",
    "    elif args.dataset == 'email':\n",
    "        nodes_number = 986    # 这里需要输入网络的节点数量\n",
    "        n_clusters = 10     # 指定类簇数量\n",
    "    elif args.dataset == 'polbooks':\n",
    "        nodes_number = 105    # 这里需要输入网络的节点数量\n",
    "        n_clusters = 10     # 指定类簇数量\n",
    "    elif args.dataset == 'texas':\n",
    "        nodes_number = 183    # 这里需要输入网络的节点数量\n",
    "        n_clusters = 10     # 指定类簇数量\n",
    "    elif args.dataset == 'wisconsin':\n",
    "        nodes_number = 215    # 这里需要输入网络的节点数量\n",
    "        n_clusters = 10     # 指定类簇数量\n",
    "    elif args.dataset == 'karate':\n",
    "        nodes_number = 34    # 这里需要输入网络的节点数量\n",
    "        n_clusters = 12     # 指定类簇数量\n",
    "        \n",
    "    Cluster = SpectralClustering(n_clusters=n_clusters, affinity = 'precomputed', random_state=0)\n",
    "    adj, features = load_network_data(args.dataset, nodes_number)\n",
    "\n",
    "    n_nodes, feat_dim = features.shape\n",
    "    dims = [feat_dim] + args.dims\n",
    "    \n",
    "    layers = args.linlayers\n",
    "    # Store original adjacency matrix (without diagonal entries) for later\n",
    "    \n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "    adj_orig = adj\n",
    "\n",
    "    #adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)    # val:0.05  test:0.1\n",
    "    if args.dataset == 'karate':\n",
    "        adj_train, train_edges, test_edges, test_edges_false = mask_test_edges(adj, adj_name='karate')   \n",
    "    else:\n",
    "        adj_train, train_edges, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "    adj = adj_train\n",
    "    n = adj.shape[0]\n",
    "\n",
    "    adj_norm_s = preprocess_graph(adj, args.gnnlayers, norm='sym', renorm=True)\n",
    "    sm_fea_s = sp.csr_matrix(features).toarray()\n",
    "    \n",
    "    print('Laplacian Smoothing...')\n",
    "    for a in adj_norm_s:\n",
    "        sm_fea_s = a.dot(sm_fea_s)\n",
    "    adj_1st = (adj + sp.eye(n)).toarray()\n",
    "\n",
    "    adj_label = torch.FloatTensor(adj_1st)\n",
    "    \n",
    "    model = LinTrans(layers, dims)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    sm_fea_s = torch.FloatTensor(sm_fea_s)\n",
    "    adj_label = adj_label.reshape([-1,])\n",
    "\n",
    "    inx = sm_fea_s\n",
    "    \n",
    "    pos_num = len(adj.indices)\n",
    "    neg_num = n_nodes*n_nodes-pos_num\n",
    "\n",
    "    up_eta = (args.upth_ed - args.upth_st) / (args.epochs/args.upd)\n",
    "    low_eta = (args.lowth_ed - args.lowth_st) / (args.epochs/args.upd)\n",
    "\n",
    "    pos_inds, neg_inds = update_similarity(normalize(sm_fea_s.numpy()), args.upth_st, args.lowth_st, pos_num, neg_num)\n",
    "    upth, lowth = update_threshold(args.upth_st, args.lowth_st, up_eta, low_eta)\n",
    "\n",
    "    bs = min(args.bs, len(pos_inds))\n",
    "    length = len(pos_inds)\n",
    "    \n",
    "    pos_inds_cuda = torch.LongTensor(pos_inds)\n",
    "    best_lp = 0.\n",
    "    print('Start Training...')\n",
    "    for epoch in range(args.epochs):\n",
    "        st, ed = 0, bs\n",
    "        batch_num = 0\n",
    "        model.train()\n",
    "        length = len(pos_inds)\n",
    "        \n",
    "        while ( ed <= length ):\n",
    "            sampled_neg = torch.LongTensor(np.random.choice(neg_inds, size=ed-st))\n",
    "            sampled_inds = torch.cat((pos_inds_cuda[st:ed], sampled_neg), 0)\n",
    "            t = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            xind = sampled_inds // n_nodes\n",
    "            yind = sampled_inds % n_nodes\n",
    "            x = torch.index_select(inx, 0, xind)\n",
    "            y = torch.index_select(inx, 0, yind)\n",
    "            zx = model(x)\n",
    "            zy = model(y)\n",
    "            batch_label = torch.cat((torch.ones(ed-st), torch.zeros(ed-st)))\n",
    "            batch_pred = model.dcs(zx, zy)\n",
    "            loss = loss_function(adj_preds=batch_pred, adj_labels=batch_label, n_nodes=ed-st)\n",
    "            \n",
    "            loss.backward()\n",
    "            cur_loss = loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            st = ed\n",
    "            batch_num += 1\n",
    "            if ed < length and ed + bs >= length:\n",
    "                ed += length - ed\n",
    "            else:\n",
    "                ed += bs\n",
    "\n",
    "        if (epoch + 1) % args.upd == 0:\n",
    "            model.eval()\n",
    "            mu = model(inx)\n",
    "            hidden_emb = mu.cpu().data.numpy()\n",
    "            upth, lowth = update_threshold(upth, lowth, up_eta, low_eta)\n",
    "            pos_inds, neg_inds = update_similarity(hidden_emb, upth, lowth, pos_num, neg_num)\n",
    "            bs = min(args.bs, len(pos_inds))\n",
    "            pos_inds_cuda = torch.LongTensor(pos_inds)\n",
    "            \n",
    "            #val_auc, val_ap, val_acc, val_f1 = get_scores(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
    "            #if val_auc + val_ap >= best_lp:\n",
    "                #best_lp = val_auc + val_ap\n",
    "                #best_emb = hidden_emb\n",
    "            #print(\"Epoch: {}, train_loss_gae={:.5f}, val_ap={:.5f}, val_acc={:.5f},time={:.5f}\".format(epoch + 1, cur_loss, val_ap, val_acc, time.time() - t))\n",
    "    \n",
    "    print(\"Optimization Finished!\")\n",
    "    #auc_score, ap_score, acc_score, f1_score = get_scores(best_emb, adj_orig, test_edges, test_edges_false)\n",
    "    auc_score, ap_score = get_scores(hidden_emb, adj_orig, test_edges, test_edges_false)\n",
    "    print('Test AP score: ',ap_score)\n",
    "    print('Test AUC score: ',auc_score)\n",
    "    return hidden_emb, adj_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4ac9f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:52:35.800511Z",
     "start_time": "2022-11-01T12:52:35.281247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using karate dataset\n",
      "Laplacian Smoothing...\n",
      "Start Training...\n",
      "Optimization Finished!\n",
      "Test AP score:  0.9821428571428572\n",
      "Test AUC score:  0.979591836734694\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    emb, adj = gae_for(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb4e355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:52:35.944513Z",
     "start_time": "2022-11-01T12:52:35.850717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gama :  0.2\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.25\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.3\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.35\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.4\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.45\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.5\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.55\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.6\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.65\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.7\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.75\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.8\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.85\n",
      "edges：  1122.0\n",
      "ACC：  0.1643598615916955\n",
      "AP：  0.5695187165775402\n",
      "RECALL：  0.517\n",
      "F1 SCORE：  0.15494773930494637\n",
      "gama :  0.9\n",
      "edges：  944.0\n",
      "ACC：  0.314878892733564\n",
      "AP：  0.576850815478094\n",
      "RECALL：  0.5985897435897436\n",
      "F1 SCORE：  0.3132673267326732\n",
      "gama :  0.95\n",
      "edges：  328.0\n",
      "ACC：  0.8304498269896193\n",
      "AP：  0.7122658183103571\n",
      "RECALL：  0.8695384615384616\n",
      "F1 SCORE：  0.7439101578747491\n",
      "gama :  0.96\n",
      "edges：  206.0\n",
      "ACC：  0.9152249134948097\n",
      "AP：  0.8077567705671946\n",
      "RECALL：  0.8860769230769231\n",
      "F1 SCORE：  0.8395126788496955\n",
      "gama :  0.965\n",
      "edges：  164.0\n",
      "ACC：  0.9377162629757786\n",
      "AP：  0.8619197482297404\n",
      "RECALL：  0.8774358974358973\n",
      "F1 SCORE：  0.8694277108433734\n",
      "gama :  0.97\n",
      "edges：  126.0\n",
      "ACC：  0.9394463667820069\n",
      "AP：  0.8963630759747265\n",
      "RECALL：  0.8297435897435897\n",
      "F1 SCORE：  0.8586451455123503\n",
      "gama :  0.975\n",
      "edges：  88.0\n",
      "ACC：  0.9238754325259516\n",
      "AP：  0.9066649642492339\n",
      "RECALL：  0.745\n",
      "F1 SCORE：  0.7983955354028602\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "adj_rec = np.dot(emb, emb.T)\n",
    "adj_rec = sigmoid(adj_rec)\n",
    "adj_rec = adj_rec/adj_rec.max()\n",
    "\n",
    "for i in range(adj_rec.shape[0]):\n",
    "    adj_rec[i, i] = 0\n",
    "s = adj_rec.reshape(adj_rec.shape[0]*adj_rec.shape[0])\n",
    "\n",
    "adj_true = adj.toarray()\n",
    "true_edges = adj_true.reshape(34*34)\n",
    "\n",
    "for gama in [0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9, 0.95, 0.96, 0.965, 0.97, 0.975]:\n",
    "    print(\"gama : \",gama)\n",
    "    predict_edges = copy.deepcopy(s)\n",
    "    predict_edges[predict_edges > gama] = 1\n",
    "    predict_edges[predict_edges <= gama] = 0\n",
    "    print(\"edges： \",predict_edges.sum())\n",
    "    print(\"ACC： \",accuracy_score(true_edges, predict_edges))\n",
    "    print(\"AP： \",precision_score(true_edges, predict_edges, average='macro'))\n",
    "    print(\"RECALL： \",recall_score(true_edges, predict_edges, average='macro'))\n",
    "    print(\"F1 SCORE： \",f1_score(true_edges, predict_edges, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41225805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:53:36.510771Z",
     "start_time": "2022-11-01T12:53:36.485405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges：  164.0\n",
      "ACC：  0.9377162629757786\n",
      "AP：  0.8619197482297404\n",
      "RECALL：  0.8774358974358973\n",
      "F1 SCORE：  0.8694277108433734\n"
     ]
    }
   ],
   "source": [
    "gama = 0.965\n",
    "predict_edges = copy.deepcopy(s)\n",
    "predict_edges[predict_edges > gama] = 1\n",
    "predict_edges[predict_edges <= gama] = 0\n",
    "print(\"edges： \",predict_edges.sum())\n",
    "print(\"ACC： \",accuracy_score(true_edges, predict_edges))\n",
    "print(\"AP： \",precision_score(true_edges, predict_edges, average='macro'))\n",
    "print(\"RECALL： \",recall_score(true_edges, predict_edges, average='macro'))\n",
    "print(\"F1 SCORE： \",f1_score(true_edges, predict_edges, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f171f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:53:57.275834Z",
     "start_time": "2022-11-01T12:53:57.269832Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_graph = predict_edges.reshape(34, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d609f9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:53:58.925056Z",
     "start_time": "2022-11-01T12:53:58.914974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 1.],\n",
       "       [1., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_graph[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ad47b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:54:00.319498Z",
     "start_time": "2022-11-01T12:54:00.307523Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(predict_graph).to_csv('AGE_recon_karate.txt', header=None, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d2405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
