{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0646c9",
   "metadata": {},
   "source": [
    "# 导入库函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae55df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T07:13:59.441344Z",
     "start_time": "2022-11-07T07:13:57.429730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x230b13c7668>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from gravity_gae.evaluation import compute_scores\n",
    "from gravity_gae.input_data import load_data\n",
    "from gravity_gae.model import *\n",
    "from gravity_gae.optimizer import OptimizerAE, OptimizerVAE\n",
    "from gravity_gae.preprocessing import *\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')#添加的，不报错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33ea38",
   "metadata": {},
   "source": [
    "# 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9a099a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T07:13:59.489457Z",
     "start_time": "2022-11-07T07:13:59.475339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x230b13f0390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('dataset', 'Cornell', 'Name of the graph dataset')\n",
    "\n",
    "# Select machine learning task to perform on graph\n",
    "flags.DEFINE_string('task', 'task_3', 'Name of the link prediction task')\n",
    "''' See section 4.1. of paper for details about tasks:\n",
    "\n",
    "- task_1: General Directed Link Prediction\n",
    "\n",
    "- task_2: Biased Negative Samples Directed Link Prediction\n",
    "\n",
    "- task_3: Bidirectionality Prediction\n",
    "'''\n",
    "\n",
    "# Model\n",
    "flags.DEFINE_string('model', 'gravity_gcn_vae', 'Name of the model')\n",
    "''' Available Models:\n",
    "\n",
    "- gcn_ae: Graph Autoencoder from Kipf and Welling (2016), with 2-layer\n",
    "          GCN encoder and inner product decoder\n",
    "\n",
    "- gcn_vae: Variational Graph Autoencoder from Kipf and Welling (2016), with\n",
    "           Gaussian priors, 2-layer GCN encoders and inner product decoder\n",
    "\n",
    "- source_target_gcn_ae: Source-Target Graph Autoencoder, as introduced\n",
    "                        in section 2.6 of paper, with 2-layer GCN encoder\n",
    "                        and asymmetric inner product decoder\n",
    "\n",
    "- source_target_gcn_vae: Source-Target Graph Variational Autoencoder, as\n",
    "                         introduced in section 2.6, with Gaussian priors,\n",
    "                         2-layer GCN encoders and asymmetric inner product\n",
    " \n",
    "- gravity_gcn_ae: Gravity-Inspired Graph Autoencoder, as introduced in\n",
    "                  section 3.3 of paper, with 2-layer GCN encoder and \n",
    "                  gravity-inspired asymmetric decoder\n",
    " \n",
    "- gravity_gcn_vae: Gravity-Inspired Graph Variational Autoencoder, as\n",
    "                   introduced in section 3.4 of paper, with Gaussian \n",
    "                   priors, 2-layer GCN encoders and gravity-inspired decoder\n",
    "'''\n",
    "\n",
    "# Model parameters\n",
    "flags.DEFINE_float('dropout', 0., 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs in training.')\n",
    "flags.DEFINE_boolean('features', False, 'Include node features or not in GCN')\n",
    "flags.DEFINE_float('lamb', 1., 'lambda parameter from Gravity AE/VAE models \\\n",
    "                                as introduced in section 3.5 of paper, to \\\n",
    "                                balance mass and proximity terms')\n",
    "flags.DEFINE_float('learning_rate', 0.1, 'Initial learning rate (with Adam)')\n",
    "flags.DEFINE_integer('hidden', 32, 'Number of units in GCN hidden layer.')\n",
    "flags.DEFINE_integer('dimension', 12, 'Dimension of GCN output: \\\n",
    "- equal to embedding dimension for standard AE/VAE and source-target AE/VAE \\\n",
    "- equal to (embedding dimension - 1) for gravity-inspired AE/VAE, as the \\\n",
    "last dimension captures the \"mass\" parameter tilde{m}')\n",
    "flags.DEFINE_boolean('normalize', False, 'Whether to normalize embedding \\\n",
    "                                          vectors of gravity models')\n",
    "flags.DEFINE_float('epsilon', 0.01, 'Add epsilon to distances computations \\\n",
    "                                       in gravity models, for numerical \\\n",
    "                                       stability')\n",
    "# Experimental setup parameters\n",
    "flags.DEFINE_integer('nb_run', 10, 'Number of model run + test')\n",
    "flags.DEFINE_float('prop_val', 5., 'Proportion of edges in validation set \\\n",
    "                                   (for Task 1)')\n",
    "flags.DEFINE_float('prop_test', 10., 'Proportion of edges in test set \\\n",
    "                                      (for Tasks 1 and 2)')\n",
    "flags.DEFINE_boolean('validation', False, 'Whether to report validation \\\n",
    "                                           results  at each epoch (for \\\n",
    "                                           Task 1)')\n",
    "flags.DEFINE_boolean('verbose', True, 'Whether to print comments details.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb910058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T07:14:12.291393Z",
     "start_time": "2022-11-07T07:13:59.523891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.58780 time= 0.10480\n",
      "Epoch: 0002 train_loss= 1.14401 time= 0.00298\n",
      "Epoch: 0003 train_loss= 0.83916 time= 0.00501\n",
      "Epoch: 0004 train_loss= 0.86263 time= 0.00299\n",
      "Epoch: 0005 train_loss= 0.84047 time= 0.00300\n",
      "Epoch: 0006 train_loss= 0.69165 time= 0.00301\n",
      "Epoch: 0007 train_loss= 0.62388 time= 0.00199\n",
      "Epoch: 0008 train_loss= 0.63602 time= 0.00300\n",
      "Epoch: 0009 train_loss= 0.64643 time= 0.00200\n",
      "Epoch: 0010 train_loss= 0.64566 time= 0.00199\n",
      "Epoch: 0011 train_loss= 0.61636 time= 0.00200\n",
      "Epoch: 0012 train_loss= 0.58302 time= 0.00200\n",
      "Epoch: 0013 train_loss= 0.56086 time= 0.00300\n",
      "Epoch: 0014 train_loss= 0.55374 time= 0.00200\n",
      "Epoch: 0015 train_loss= 0.55274 time= 0.00200\n",
      "Epoch: 0016 train_loss= 0.56331 time= 0.00300\n",
      "Epoch: 0017 train_loss= 0.55035 time= 0.00200\n",
      "Epoch: 0018 train_loss= 0.53339 time= 0.00200\n",
      "Epoch: 0019 train_loss= 0.52590 time= 0.00200\n",
      "Epoch: 0020 train_loss= 0.51026 time= 0.00200\n",
      "Epoch: 0021 train_loss= 0.51205 time= 0.00200\n",
      "Epoch: 0022 train_loss= 0.51750 time= 0.00201\n",
      "Epoch: 0023 train_loss= 0.50599 time= 0.00199\n",
      "Epoch: 0024 train_loss= 0.50983 time= 0.00300\n",
      "Epoch: 0025 train_loss= 0.49924 time= 0.00200\n",
      "Epoch: 0026 train_loss= 0.49816 time= 0.00200\n",
      "Epoch: 0027 train_loss= 0.49102 time= 0.00199\n",
      "Epoch: 0028 train_loss= 0.48425 time= 0.00201\n",
      "Epoch: 0029 train_loss= 0.48574 time= 0.00200\n",
      "Epoch: 0030 train_loss= 0.48611 time= 0.00200\n",
      "Epoch: 0031 train_loss= 0.48067 time= 0.00201\n",
      "Epoch: 0032 train_loss= 0.47658 time= 0.00198\n",
      "Epoch: 0033 train_loss= 0.47983 time= 0.00301\n",
      "Epoch: 0034 train_loss= 0.48175 time= 0.00199\n",
      "Epoch: 0035 train_loss= 0.47705 time= 0.00300\n",
      "Epoch: 0036 train_loss= 0.47645 time= 0.00200\n",
      "Epoch: 0037 train_loss= 0.47174 time= 0.00200\n",
      "Epoch: 0038 train_loss= 0.47725 time= 0.00300\n",
      "Epoch: 0039 train_loss= 0.46631 time= 0.00200\n",
      "Epoch: 0040 train_loss= 0.47708 time= 0.00201\n",
      "Epoch: 0041 train_loss= 0.46266 time= 0.00199\n",
      "Epoch: 0042 train_loss= 0.46455 time= 0.00200\n",
      "Epoch: 0043 train_loss= 0.46515 time= 0.00300\n",
      "Epoch: 0044 train_loss= 0.47171 time= 0.00199\n",
      "Epoch: 0045 train_loss= 0.46285 time= 0.00200\n",
      "Epoch: 0046 train_loss= 0.45880 time= 0.00099\n",
      "Epoch: 0047 train_loss= 0.46337 time= 0.00200\n",
      "Epoch: 0048 train_loss= 0.45320 time= 0.00200\n",
      "Epoch: 0049 train_loss= 0.45902 time= 0.00200\n",
      "Epoch: 0050 train_loss= 0.45688 time= 0.00200\n",
      "Epoch: 0051 train_loss= 0.45107 time= 0.00199\n",
      "Epoch: 0052 train_loss= 0.45991 time= 0.00200\n",
      "Epoch: 0053 train_loss= 0.45676 time= 0.00200\n",
      "Epoch: 0054 train_loss= 0.45834 time= 0.00199\n",
      "Epoch: 0055 train_loss= 0.44869 time= 0.00300\n",
      "Epoch: 0056 train_loss= 0.45190 time= 0.00200\n",
      "Epoch: 0057 train_loss= 0.45353 time= 0.00200\n",
      "Epoch: 0058 train_loss= 0.44639 time= 0.00200\n",
      "Epoch: 0059 train_loss= 0.45063 time= 0.00200\n",
      "Epoch: 0060 train_loss= 0.46165 time= 0.00201\n",
      "Epoch: 0061 train_loss= 0.45452 time= 0.00199\n",
      "Epoch: 0062 train_loss= 0.45159 time= 0.00200\n",
      "Epoch: 0063 train_loss= 0.44753 time= 0.00200\n",
      "Epoch: 0064 train_loss= 0.45641 time= 0.00198\n",
      "Epoch: 0065 train_loss= 0.45182 time= 0.00200\n",
      "Epoch: 0066 train_loss= 0.45191 time= 0.00200\n",
      "Epoch: 0067 train_loss= 0.44997 time= 0.00200\n",
      "Epoch: 0068 train_loss= 0.44509 time= 0.00200\n",
      "Epoch: 0069 train_loss= 0.45217 time= 0.00200\n",
      "Epoch: 0070 train_loss= 0.45312 time= 0.00200\n",
      "Epoch: 0071 train_loss= 0.45206 time= 0.00200\n",
      "Epoch: 0072 train_loss= 0.44715 time= 0.00199\n",
      "Epoch: 0073 train_loss= 0.44521 time= 0.00200\n",
      "Epoch: 0074 train_loss= 0.44592 time= 0.00200\n",
      "Epoch: 0075 train_loss= 0.44867 time= 0.00200\n",
      "Epoch: 0076 train_loss= 0.44758 time= 0.00200\n",
      "Epoch: 0077 train_loss= 0.44865 time= 0.00200\n",
      "Epoch: 0078 train_loss= 0.44191 time= 0.00199\n",
      "Epoch: 0079 train_loss= 0.45031 time= 0.00200\n",
      "Epoch: 0080 train_loss= 0.45681 time= 0.00200\n",
      "Epoch: 0081 train_loss= 0.45673 time= 0.00200\n",
      "Epoch: 0082 train_loss= 0.44861 time= 0.00200\n",
      "Epoch: 0083 train_loss= 0.44127 time= 0.00202\n",
      "Epoch: 0084 train_loss= 0.44434 time= 0.00198\n",
      "Epoch: 0085 train_loss= 0.44399 time= 0.00200\n",
      "Epoch: 0086 train_loss= 0.44585 time= 0.00201\n",
      "Epoch: 0087 train_loss= 0.44473 time= 0.00199\n",
      "Epoch: 0088 train_loss= 0.45044 time= 0.00200\n",
      "Epoch: 0089 train_loss= 0.44516 time= 0.00200\n",
      "Epoch: 0090 train_loss= 0.44162 time= 0.00200\n",
      "Epoch: 0091 train_loss= 0.44834 time= 0.00200\n",
      "Epoch: 0092 train_loss= 0.44421 time= 0.00200\n",
      "Epoch: 0093 train_loss= 0.44036 time= 0.00200\n",
      "Epoch: 0094 train_loss= 0.43931 time= 0.00200\n",
      "Epoch: 0095 train_loss= 0.43819 time= 0.00300\n",
      "Epoch: 0096 train_loss= 0.43861 time= 0.00200\n",
      "Epoch: 0097 train_loss= 0.44649 time= 0.00300\n",
      "Epoch: 0098 train_loss= 0.43915 time= 0.00200\n",
      "Epoch: 0099 train_loss= 0.44207 time= 0.00200\n",
      "Epoch: 0100 train_loss= 0.44172 time= 0.00200\n",
      "Epoch: 0101 train_loss= 0.44180 time= 0.00200\n",
      "Epoch: 0102 train_loss= 0.43488 time= 0.00199\n",
      "Epoch: 0103 train_loss= 0.44402 time= 0.00200\n",
      "Epoch: 0104 train_loss= 0.44473 time= 0.00200\n",
      "Epoch: 0105 train_loss= 0.43935 time= 0.00201\n",
      "Epoch: 0106 train_loss= 0.43325 time= 0.00199\n",
      "Epoch: 0107 train_loss= 0.43820 time= 0.00200\n",
      "Epoch: 0108 train_loss= 0.43463 time= 0.00199\n",
      "Epoch: 0109 train_loss= 0.43793 time= 0.00201\n",
      "Epoch: 0110 train_loss= 0.43702 time= 0.00199\n",
      "Epoch: 0111 train_loss= 0.43812 time= 0.00199\n",
      "Epoch: 0112 train_loss= 0.43353 time= 0.00200\n",
      "Epoch: 0113 train_loss= 0.44771 time= 0.00200\n",
      "Epoch: 0114 train_loss= 0.43539 time= 0.00200\n",
      "Epoch: 0115 train_loss= 0.43326 time= 0.00201\n",
      "Epoch: 0116 train_loss= 0.43183 time= 0.00198\n",
      "Epoch: 0117 train_loss= 0.42932 time= 0.00201\n",
      "Epoch: 0118 train_loss= 0.43388 time= 0.00303\n",
      "Epoch: 0119 train_loss= 0.43904 time= 0.00196\n",
      "Epoch: 0120 train_loss= 0.43017 time= 0.00200\n",
      "Epoch: 0121 train_loss= 0.44303 time= 0.00200\n",
      "Epoch: 0122 train_loss= 0.43868 time= 0.00200\n",
      "Epoch: 0123 train_loss= 0.43689 time= 0.00200\n",
      "Epoch: 0124 train_loss= 0.43845 time= 0.00200\n",
      "Epoch: 0125 train_loss= 0.42971 time= 0.00200\n",
      "Epoch: 0126 train_loss= 0.44028 time= 0.00200\n",
      "Epoch: 0127 train_loss= 0.43057 time= 0.00200\n",
      "Epoch: 0128 train_loss= 0.43715 time= 0.00300\n",
      "Epoch: 0129 train_loss= 0.43016 time= 0.00200\n",
      "Epoch: 0130 train_loss= 0.44075 time= 0.00200\n",
      "Epoch: 0131 train_loss= 0.43336 time= 0.00301\n",
      "Epoch: 0132 train_loss= 0.43224 time= 0.00199\n",
      "Epoch: 0133 train_loss= 0.43473 time= 0.00300\n",
      "Epoch: 0134 train_loss= 0.42773 time= 0.00200\n",
      "Epoch: 0135 train_loss= 0.43024 time= 0.00300\n",
      "Epoch: 0136 train_loss= 0.43071 time= 0.00200\n",
      "Epoch: 0137 train_loss= 0.43508 time= 0.00200\n",
      "Epoch: 0138 train_loss= 0.43059 time= 0.00201\n",
      "Epoch: 0139 train_loss= 0.42551 time= 0.00199\n",
      "Epoch: 0140 train_loss= 0.43286 time= 0.00200\n",
      "Epoch: 0141 train_loss= 0.43202 time= 0.00200\n",
      "Epoch: 0142 train_loss= 0.43511 time= 0.00200\n",
      "Epoch: 0143 train_loss= 0.42879 time= 0.00200\n",
      "Epoch: 0144 train_loss= 0.43275 time= 0.00200\n",
      "Epoch: 0145 train_loss= 0.43660 time= 0.00202\n",
      "Epoch: 0146 train_loss= 0.43039 time= 0.00200\n",
      "Epoch: 0147 train_loss= 0.42903 time= 0.00199\n",
      "Epoch: 0148 train_loss= 0.42939 time= 0.00200\n",
      "Epoch: 0149 train_loss= 0.42729 time= 0.00200\n",
      "Epoch: 0150 train_loss= 0.42520 time= 0.00200\n",
      "Epoch: 0151 train_loss= 0.43400 time= 0.00200\n",
      "Epoch: 0152 train_loss= 0.43160 time= 0.00200\n",
      "Epoch: 0153 train_loss= 0.42889 time= 0.00200\n",
      "Epoch: 0154 train_loss= 0.43246 time= 0.00200\n",
      "Epoch: 0155 train_loss= 0.43717 time= 0.00301\n",
      "Epoch: 0156 train_loss= 0.43474 time= 0.00200\n",
      "Epoch: 0157 train_loss= 0.43609 time= 0.00200\n",
      "Epoch: 0158 train_loss= 0.42846 time= 0.00201\n",
      "Epoch: 0159 train_loss= 0.43346 time= 0.00199\n",
      "Epoch: 0160 train_loss= 0.42971 time= 0.00199\n",
      "Epoch: 0161 train_loss= 0.42879 time= 0.00200\n",
      "Epoch: 0162 train_loss= 0.42577 time= 0.00200\n",
      "Epoch: 0163 train_loss= 0.42652 time= 0.00202\n",
      "Epoch: 0164 train_loss= 0.43235 time= 0.00198\n",
      "Epoch: 0165 train_loss= 0.43017 time= 0.00300\n",
      "Epoch: 0166 train_loss= 0.42773 time= 0.00200\n",
      "Epoch: 0167 train_loss= 0.42845 time= 0.00200\n",
      "Epoch: 0168 train_loss= 0.43032 time= 0.00200\n",
      "Epoch: 0169 train_loss= 0.42898 time= 0.00199\n",
      "Epoch: 0170 train_loss= 0.42773 time= 0.00201\n",
      "Epoch: 0171 train_loss= 0.43060 time= 0.00200\n",
      "Epoch: 0172 train_loss= 0.42668 time= 0.00200\n",
      "Epoch: 0173 train_loss= 0.42736 time= 0.00200\n",
      "Epoch: 0174 train_loss= 0.42744 time= 0.00201\n",
      "Epoch: 0175 train_loss= 0.43557 time= 0.00199\n",
      "Epoch: 0176 train_loss= 0.42939 time= 0.00200\n",
      "Epoch: 0177 train_loss= 0.42760 time= 0.00202\n",
      "Epoch: 0178 train_loss= 0.43582 time= 0.00198\n",
      "Epoch: 0179 train_loss= 0.42965 time= 0.00300\n",
      "Epoch: 0180 train_loss= 0.42357 time= 0.00200\n",
      "Epoch: 0181 train_loss= 0.42895 time= 0.00200\n",
      "Epoch: 0182 train_loss= 0.42525 time= 0.00199\n",
      "Epoch: 0183 train_loss= 0.43413 time= 0.00199\n",
      "Epoch: 0184 train_loss= 0.42358 time= 0.00201\n",
      "Epoch: 0185 train_loss= 0.42832 time= 0.00199\n",
      "Epoch: 0186 train_loss= 0.42841 time= 0.00200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0187 train_loss= 0.42119 time= 0.00201\n",
      "Epoch: 0188 train_loss= 0.43233 time= 0.00200\n",
      "Epoch: 0189 train_loss= 0.43410 time= 0.00200\n",
      "Epoch: 0190 train_loss= 0.43059 time= 0.00200\n",
      "Epoch: 0191 train_loss= 0.43044 time= 0.00200\n",
      "Epoch: 0192 train_loss= 0.43347 time= 0.00199\n",
      "Epoch: 0193 train_loss= 0.42357 time= 0.00200\n",
      "Epoch: 0194 train_loss= 0.43155 time= 0.00200\n",
      "Epoch: 0195 train_loss= 0.42636 time= 0.00200\n",
      "Epoch: 0196 train_loss= 0.43199 time= 0.00199\n",
      "Epoch: 0197 train_loss= 0.42711 time= 0.00200\n",
      "Epoch: 0198 train_loss= 0.42229 time= 0.00200\n",
      "Epoch: 0199 train_loss= 0.43145 time= 0.00200\n",
      "Epoch: 0200 train_loss= 0.43407 time= 0.00199\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.67665 time= 0.09110\n",
      "Epoch: 0002 train_loss= 1.30261 time= 0.00296\n",
      "Epoch: 0003 train_loss= 0.91900 time= 0.00206\n",
      "Epoch: 0004 train_loss= 0.73864 time= 0.00302\n",
      "Epoch: 0005 train_loss= 0.83533 time= 0.00293\n",
      "Epoch: 0006 train_loss= 0.73926 time= 0.00298\n",
      "Epoch: 0007 train_loss= 0.64360 time= 0.00200\n",
      "Epoch: 0008 train_loss= 0.60475 time= 0.00301\n",
      "Epoch: 0009 train_loss= 0.63667 time= 0.00199\n",
      "Epoch: 0010 train_loss= 0.65204 time= 0.00201\n",
      "Epoch: 0011 train_loss= 0.64762 time= 0.00300\n",
      "Epoch: 0012 train_loss= 0.62964 time= 0.00199\n",
      "Epoch: 0013 train_loss= 0.59154 time= 0.00200\n",
      "Epoch: 0014 train_loss= 0.56268 time= 0.00201\n",
      "Epoch: 0015 train_loss= 0.55721 time= 0.00199\n",
      "Epoch: 0016 train_loss= 0.55181 time= 0.00201\n",
      "Epoch: 0017 train_loss= 0.54571 time= 0.00200\n",
      "Epoch: 0018 train_loss= 0.53984 time= 0.00402\n",
      "Epoch: 0019 train_loss= 0.52683 time= 0.00198\n",
      "Epoch: 0020 train_loss= 0.51517 time= 0.00200\n",
      "Epoch: 0021 train_loss= 0.51368 time= 0.00200\n",
      "Epoch: 0022 train_loss= 0.50849 time= 0.00200\n",
      "Epoch: 0023 train_loss= 0.51232 time= 0.00300\n",
      "Epoch: 0024 train_loss= 0.50249 time= 0.00200\n",
      "Epoch: 0025 train_loss= 0.51161 time= 0.00200\n",
      "Epoch: 0026 train_loss= 0.49058 time= 0.00302\n",
      "Epoch: 0027 train_loss= 0.48855 time= 0.00198\n",
      "Epoch: 0028 train_loss= 0.49060 time= 0.00200\n",
      "Epoch: 0029 train_loss= 0.49470 time= 0.00201\n",
      "Epoch: 0030 train_loss= 0.48416 time= 0.00199\n",
      "Epoch: 0031 train_loss= 0.48136 time= 0.00200\n",
      "Epoch: 0032 train_loss= 0.48275 time= 0.00200\n",
      "Epoch: 0033 train_loss= 0.48607 time= 0.00199\n",
      "Epoch: 0034 train_loss= 0.47919 time= 0.00200\n",
      "Epoch: 0035 train_loss= 0.47705 time= 0.00200\n",
      "Epoch: 0036 train_loss= 0.48681 time= 0.00300\n",
      "Epoch: 0037 train_loss= 0.47052 time= 0.00200\n",
      "Epoch: 0038 train_loss= 0.47533 time= 0.00200\n",
      "Epoch: 0039 train_loss= 0.46761 time= 0.00300\n",
      "Epoch: 0040 train_loss= 0.46988 time= 0.00199\n",
      "Epoch: 0041 train_loss= 0.46629 time= 0.00199\n",
      "Epoch: 0042 train_loss= 0.47113 time= 0.00300\n",
      "Epoch: 0043 train_loss= 0.46533 time= 0.00200\n",
      "Epoch: 0044 train_loss= 0.45790 time= 0.00300\n",
      "Epoch: 0045 train_loss= 0.46317 time= 0.00200\n",
      "Epoch: 0046 train_loss= 0.46444 time= 0.00201\n",
      "Epoch: 0047 train_loss= 0.45852 time= 0.00199\n",
      "Epoch: 0048 train_loss= 0.46095 time= 0.00201\n",
      "Epoch: 0049 train_loss= 0.46143 time= 0.00199\n",
      "Epoch: 0050 train_loss= 0.45672 time= 0.00300\n",
      "Epoch: 0051 train_loss= 0.45306 time= 0.00301\n",
      "Epoch: 0052 train_loss= 0.46809 time= 0.00199\n",
      "Epoch: 0053 train_loss= 0.46145 time= 0.00199\n",
      "Epoch: 0054 train_loss= 0.45507 time= 0.00199\n",
      "Epoch: 0055 train_loss= 0.45866 time= 0.00301\n",
      "Epoch: 0056 train_loss= 0.45373 time= 0.00199\n",
      "Epoch: 0057 train_loss= 0.45267 time= 0.00199\n",
      "Epoch: 0058 train_loss= 0.46195 time= 0.00199\n",
      "Epoch: 0059 train_loss= 0.45670 time= 0.00200\n",
      "Epoch: 0060 train_loss= 0.45394 time= 0.00200\n",
      "Epoch: 0061 train_loss= 0.45609 time= 0.00200\n",
      "Epoch: 0062 train_loss= 0.45103 time= 0.00199\n",
      "Epoch: 0063 train_loss= 0.44116 time= 0.00200\n",
      "Epoch: 0064 train_loss= 0.44692 time= 0.00201\n",
      "Epoch: 0065 train_loss= 0.45099 time= 0.00299\n",
      "Epoch: 0066 train_loss= 0.44960 time= 0.00199\n",
      "Epoch: 0067 train_loss= 0.44973 time= 0.00200\n",
      "Epoch: 0068 train_loss= 0.44441 time= 0.00300\n",
      "Epoch: 0069 train_loss= 0.44655 time= 0.00200\n",
      "Epoch: 0070 train_loss= 0.44631 time= 0.00301\n",
      "Epoch: 0071 train_loss= 0.44241 time= 0.00199\n",
      "Epoch: 0072 train_loss= 0.45217 time= 0.00201\n",
      "Epoch: 0073 train_loss= 0.44695 time= 0.00199\n",
      "Epoch: 0074 train_loss= 0.44264 time= 0.00200\n",
      "Epoch: 0075 train_loss= 0.44517 time= 0.00199\n",
      "Epoch: 0076 train_loss= 0.44987 time= 0.00200\n",
      "Epoch: 0077 train_loss= 0.43859 time= 0.00300\n",
      "Epoch: 0078 train_loss= 0.44733 time= 0.00201\n",
      "Epoch: 0079 train_loss= 0.45480 time= 0.00202\n",
      "Epoch: 0080 train_loss= 0.44839 time= 0.00198\n",
      "Epoch: 0081 train_loss= 0.44077 time= 0.00301\n",
      "Epoch: 0082 train_loss= 0.44727 time= 0.00199\n",
      "Epoch: 0083 train_loss= 0.44437 time= 0.00191\n",
      "Epoch: 0084 train_loss= 0.44611 time= 0.00300\n",
      "Epoch: 0085 train_loss= 0.44385 time= 0.00200\n",
      "Epoch: 0086 train_loss= 0.43954 time= 0.00199\n",
      "Epoch: 0087 train_loss= 0.43896 time= 0.00201\n",
      "Epoch: 0088 train_loss= 0.43821 time= 0.00202\n",
      "Epoch: 0089 train_loss= 0.44207 time= 0.00199\n",
      "Epoch: 0090 train_loss= 0.43794 time= 0.00200\n",
      "Epoch: 0091 train_loss= 0.44369 time= 0.00200\n",
      "Epoch: 0092 train_loss= 0.44263 time= 0.00200\n",
      "Epoch: 0093 train_loss= 0.43562 time= 0.00201\n",
      "Epoch: 0094 train_loss= 0.43941 time= 0.00199\n",
      "Epoch: 0095 train_loss= 0.43760 time= 0.00200\n",
      "Epoch: 0096 train_loss= 0.44133 time= 0.00200\n",
      "Epoch: 0097 train_loss= 0.43648 time= 0.00200\n",
      "Epoch: 0098 train_loss= 0.43651 time= 0.00199\n",
      "Epoch: 0099 train_loss= 0.43853 time= 0.00201\n",
      "Epoch: 0100 train_loss= 0.43912 time= 0.00199\n",
      "Epoch: 0101 train_loss= 0.44057 time= 0.00199\n",
      "Epoch: 0102 train_loss= 0.43125 time= 0.00200\n",
      "Epoch: 0103 train_loss= 0.43337 time= 0.00200\n",
      "Epoch: 0104 train_loss= 0.43829 time= 0.00200\n",
      "Epoch: 0105 train_loss= 0.44100 time= 0.00201\n",
      "Epoch: 0106 train_loss= 0.43189 time= 0.00199\n",
      "Epoch: 0107 train_loss= 0.43591 time= 0.00199\n",
      "Epoch: 0108 train_loss= 0.43610 time= 0.00199\n",
      "Epoch: 0109 train_loss= 0.43694 time= 0.00199\n",
      "Epoch: 0110 train_loss= 0.43319 time= 0.00199\n",
      "Epoch: 0111 train_loss= 0.43392 time= 0.00199\n",
      "Epoch: 0112 train_loss= 0.43023 time= 0.00194\n",
      "Epoch: 0113 train_loss= 0.43773 time= 0.00199\n",
      "Epoch: 0114 train_loss= 0.43465 time= 0.00199\n",
      "Epoch: 0115 train_loss= 0.42677 time= 0.00201\n",
      "Epoch: 0116 train_loss= 0.43220 time= 0.00299\n",
      "Epoch: 0117 train_loss= 0.42994 time= 0.00199\n",
      "Epoch: 0118 train_loss= 0.43495 time= 0.00201\n",
      "Epoch: 0119 train_loss= 0.43850 time= 0.00199\n",
      "Epoch: 0120 train_loss= 0.42338 time= 0.00201\n",
      "Epoch: 0121 train_loss= 0.42761 time= 0.00199\n",
      "Epoch: 0122 train_loss= 0.42970 time= 0.00301\n",
      "Epoch: 0123 train_loss= 0.42919 time= 0.00199\n",
      "Epoch: 0124 train_loss= 0.43233 time= 0.00200\n",
      "Epoch: 0125 train_loss= 0.43889 time= 0.00200\n",
      "Epoch: 0126 train_loss= 0.42616 time= 0.00200\n",
      "Epoch: 0127 train_loss= 0.43259 time= 0.00202\n",
      "Epoch: 0128 train_loss= 0.43833 time= 0.00198\n",
      "Epoch: 0129 train_loss= 0.43107 time= 0.00201\n",
      "Epoch: 0130 train_loss= 0.42996 time= 0.00201\n",
      "Epoch: 0131 train_loss= 0.43048 time= 0.00199\n",
      "Epoch: 0132 train_loss= 0.43537 time= 0.00200\n",
      "Epoch: 0133 train_loss= 0.42818 time= 0.00199\n",
      "Epoch: 0134 train_loss= 0.43014 time= 0.00200\n",
      "Epoch: 0135 train_loss= 0.42855 time= 0.00243\n",
      "Epoch: 0136 train_loss= 0.42887 time= 0.00258\n",
      "Epoch: 0137 train_loss= 0.43048 time= 0.00200\n",
      "Epoch: 0138 train_loss= 0.42756 time= 0.00199\n",
      "Epoch: 0139 train_loss= 0.43217 time= 0.00199\n",
      "Epoch: 0140 train_loss= 0.42818 time= 0.00200\n",
      "Epoch: 0141 train_loss= 0.42947 time= 0.00201\n",
      "Epoch: 0142 train_loss= 0.42440 time= 0.00200\n",
      "Epoch: 0143 train_loss= 0.42899 time= 0.00201\n",
      "Epoch: 0144 train_loss= 0.42935 time= 0.00195\n",
      "Epoch: 0145 train_loss= 0.42678 time= 0.00199\n",
      "Epoch: 0146 train_loss= 0.42602 time= 0.00301\n",
      "Epoch: 0147 train_loss= 0.42691 time= 0.00199\n",
      "Epoch: 0148 train_loss= 0.43227 time= 0.00200\n",
      "Epoch: 0149 train_loss= 0.43160 time= 0.00202\n",
      "Epoch: 0150 train_loss= 0.42752 time= 0.00199\n",
      "Epoch: 0151 train_loss= 0.43163 time= 0.00200\n",
      "Epoch: 0152 train_loss= 0.44461 time= 0.00201\n",
      "Epoch: 0153 train_loss= 0.43062 time= 0.00201\n",
      "Epoch: 0154 train_loss= 0.43245 time= 0.00199\n",
      "Epoch: 0155 train_loss= 0.43145 time= 0.00200\n",
      "Epoch: 0156 train_loss= 0.43170 time= 0.00200\n",
      "Epoch: 0157 train_loss= 0.42815 time= 0.00201\n",
      "Epoch: 0158 train_loss= 0.42861 time= 0.00200\n",
      "Epoch: 0159 train_loss= 0.43057 time= 0.00200\n",
      "Epoch: 0160 train_loss= 0.43025 time= 0.00194\n",
      "Epoch: 0161 train_loss= 0.42615 time= 0.00199\n",
      "Epoch: 0162 train_loss= 0.43335 time= 0.00206\n",
      "Epoch: 0163 train_loss= 0.42811 time= 0.00193\n",
      "Epoch: 0164 train_loss= 0.42757 time= 0.00201\n",
      "Epoch: 0165 train_loss= 0.43125 time= 0.00200\n",
      "Epoch: 0166 train_loss= 0.43199 time= 0.00200\n",
      "Epoch: 0167 train_loss= 0.42366 time= 0.00200\n",
      "Epoch: 0168 train_loss= 0.42843 time= 0.00199\n",
      "Epoch: 0169 train_loss= 0.42960 time= 0.00200\n",
      "Epoch: 0170 train_loss= 0.43091 time= 0.00203\n",
      "Epoch: 0171 train_loss= 0.42852 time= 0.00199\n",
      "Epoch: 0172 train_loss= 0.42351 time= 0.00201\n",
      "Epoch: 0173 train_loss= 0.42764 time= 0.00199\n",
      "Epoch: 0174 train_loss= 0.42365 time= 0.00200\n",
      "Epoch: 0175 train_loss= 0.42482 time= 0.00200\n",
      "Epoch: 0176 train_loss= 0.42948 time= 0.00199\n",
      "Epoch: 0177 train_loss= 0.42391 time= 0.00300\n",
      "Epoch: 0178 train_loss= 0.42324 time= 0.00200\n",
      "Epoch: 0179 train_loss= 0.42545 time= 0.00302\n",
      "Epoch: 0180 train_loss= 0.42827 time= 0.00198\n",
      "Epoch: 0181 train_loss= 0.42066 time= 0.00200\n",
      "Epoch: 0182 train_loss= 0.41861 time= 0.00201\n",
      "Epoch: 0183 train_loss= 0.42124 time= 0.00199\n",
      "Epoch: 0184 train_loss= 0.42493 time= 0.00200\n",
      "Epoch: 0185 train_loss= 0.42908 time= 0.00200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0186 train_loss= 0.42372 time= 0.00200\n",
      "Epoch: 0187 train_loss= 0.42794 time= 0.00201\n",
      "Epoch: 0188 train_loss= 0.42354 time= 0.00199\n",
      "Epoch: 0189 train_loss= 0.42303 time= 0.00200\n",
      "Epoch: 0190 train_loss= 0.42334 time= 0.00199\n",
      "Epoch: 0191 train_loss= 0.42112 time= 0.00300\n",
      "Epoch: 0192 train_loss= 0.42051 time= 0.00200\n",
      "Epoch: 0193 train_loss= 0.42526 time= 0.00201\n",
      "Epoch: 0194 train_loss= 0.43185 time= 0.00199\n",
      "Epoch: 0195 train_loss= 0.42710 time= 0.00301\n",
      "Epoch: 0196 train_loss= 0.42247 time= 0.00200\n",
      "Epoch: 0197 train_loss= 0.42499 time= 0.00217\n",
      "Epoch: 0198 train_loss= 0.41948 time= 0.00283\n",
      "Epoch: 0199 train_loss= 0.42947 time= 0.00201\n",
      "Epoch: 0200 train_loss= 0.42476 time= 0.00199\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.61638 time= 0.11000\n",
      "Epoch: 0002 train_loss= 1.17874 time= 0.00300\n",
      "Epoch: 0003 train_loss= 0.81175 time= 0.00198\n",
      "Epoch: 0004 train_loss= 0.83545 time= 0.00200\n",
      "Epoch: 0005 train_loss= 0.84016 time= 0.00302\n",
      "Epoch: 0006 train_loss= 0.72545 time= 0.00299\n",
      "Epoch: 0007 train_loss= 0.62522 time= 0.00199\n",
      "Epoch: 0008 train_loss= 0.62286 time= 0.00199\n",
      "Epoch: 0009 train_loss= 0.64142 time= 0.00300\n",
      "Epoch: 0010 train_loss= 0.65038 time= 0.00200\n",
      "Epoch: 0011 train_loss= 0.63350 time= 0.00199\n",
      "Epoch: 0012 train_loss= 0.60063 time= 0.00200\n",
      "Epoch: 0013 train_loss= 0.57837 time= 0.00301\n",
      "Epoch: 0014 train_loss= 0.56124 time= 0.00199\n",
      "Epoch: 0015 train_loss= 0.56593 time= 0.00302\n",
      "Epoch: 0016 train_loss= 0.56798 time= 0.00198\n",
      "Epoch: 0017 train_loss= 0.57421 time= 0.00301\n",
      "Epoch: 0018 train_loss= 0.55259 time= 0.00299\n",
      "Epoch: 0019 train_loss= 0.53905 time= 0.00200\n",
      "Epoch: 0020 train_loss= 0.53168 time= 0.00200\n",
      "Epoch: 0021 train_loss= 0.52394 time= 0.00301\n",
      "Epoch: 0022 train_loss= 0.52858 time= 0.00199\n",
      "Epoch: 0023 train_loss= 0.51399 time= 0.00199\n",
      "Epoch: 0024 train_loss= 0.51037 time= 0.00301\n",
      "Epoch: 0025 train_loss= 0.50600 time= 0.00199\n",
      "Epoch: 0026 train_loss= 0.49848 time= 0.00201\n",
      "Epoch: 0027 train_loss= 0.49665 time= 0.00199\n",
      "Epoch: 0028 train_loss= 0.49209 time= 0.00300\n",
      "Epoch: 0029 train_loss= 0.48905 time= 0.00200\n",
      "Epoch: 0030 train_loss= 0.49208 time= 0.00300\n",
      "Epoch: 0031 train_loss= 0.48890 time= 0.00199\n",
      "Epoch: 0032 train_loss= 0.48124 time= 0.00200\n",
      "Epoch: 0033 train_loss= 0.48199 time= 0.00200\n",
      "Epoch: 0034 train_loss= 0.47851 time= 0.00199\n",
      "Epoch: 0035 train_loss= 0.47501 time= 0.00301\n",
      "Epoch: 0036 train_loss= 0.47730 time= 0.00300\n",
      "Epoch: 0037 train_loss= 0.47754 time= 0.00300\n",
      "Epoch: 0038 train_loss= 0.47688 time= 0.00199\n",
      "Epoch: 0039 train_loss= 0.47154 time= 0.00200\n",
      "Epoch: 0040 train_loss= 0.47773 time= 0.00200\n",
      "Epoch: 0041 train_loss= 0.46398 time= 0.00201\n",
      "Epoch: 0042 train_loss= 0.46639 time= 0.00199\n",
      "Epoch: 0043 train_loss= 0.46317 time= 0.00200\n",
      "Epoch: 0044 train_loss= 0.46467 time= 0.00302\n",
      "Epoch: 0045 train_loss= 0.46755 time= 0.00198\n",
      "Epoch: 0046 train_loss= 0.46320 time= 0.00302\n",
      "Epoch: 0047 train_loss= 0.47246 time= 0.00198\n",
      "Epoch: 0048 train_loss= 0.46845 time= 0.00200\n",
      "Epoch: 0049 train_loss= 0.47104 time= 0.00300\n",
      "Epoch: 0050 train_loss= 0.46173 time= 0.00201\n",
      "Epoch: 0051 train_loss= 0.46102 time= 0.00199\n",
      "Epoch: 0052 train_loss= 0.46229 time= 0.00202\n",
      "Epoch: 0053 train_loss= 0.45736 time= 0.00198\n",
      "Epoch: 0054 train_loss= 0.46663 time= 0.00199\n",
      "Epoch: 0055 train_loss= 0.46139 time= 0.00200\n",
      "Epoch: 0056 train_loss= 0.45092 time= 0.00200\n",
      "Epoch: 0057 train_loss= 0.45391 time= 0.00201\n",
      "Epoch: 0058 train_loss= 0.45582 time= 0.00199\n",
      "Epoch: 0059 train_loss= 0.45983 time= 0.00200\n",
      "Epoch: 0060 train_loss= 0.44946 time= 0.00200\n",
      "Epoch: 0061 train_loss= 0.45608 time= 0.00301\n",
      "Epoch: 0062 train_loss= 0.45844 time= 0.00200\n",
      "Epoch: 0063 train_loss= 0.44784 time= 0.00201\n",
      "Epoch: 0064 train_loss= 0.45249 time= 0.00299\n",
      "Epoch: 0065 train_loss= 0.45066 time= 0.00300\n",
      "Epoch: 0066 train_loss= 0.45866 time= 0.00202\n",
      "Epoch: 0067 train_loss= 0.44966 time= 0.00301\n",
      "Epoch: 0068 train_loss= 0.44675 time= 0.00198\n",
      "Epoch: 0069 train_loss= 0.45487 time= 0.00300\n",
      "Epoch: 0070 train_loss= 0.44948 time= 0.00200\n",
      "Epoch: 0071 train_loss= 0.44567 time= 0.00201\n",
      "Epoch: 0072 train_loss= 0.45169 time= 0.00300\n",
      "Epoch: 0073 train_loss= 0.44143 time= 0.00198\n",
      "Epoch: 0074 train_loss= 0.45269 time= 0.00302\n",
      "Epoch: 0075 train_loss= 0.44922 time= 0.00199\n",
      "Epoch: 0076 train_loss= 0.45575 time= 0.00200\n",
      "Epoch: 0077 train_loss= 0.44428 time= 0.00199\n",
      "Epoch: 0078 train_loss= 0.44763 time= 0.00199\n",
      "Epoch: 0079 train_loss= 0.44122 time= 0.00200\n",
      "Epoch: 0080 train_loss= 0.44316 time= 0.00199\n",
      "Epoch: 0081 train_loss= 0.44439 time= 0.00301\n",
      "Epoch: 0082 train_loss= 0.44379 time= 0.00301\n",
      "Epoch: 0083 train_loss= 0.43861 time= 0.00198\n",
      "Epoch: 0084 train_loss= 0.44383 time= 0.00301\n",
      "Epoch: 0085 train_loss= 0.44762 time= 0.00199\n",
      "Epoch: 0086 train_loss= 0.43957 time= 0.00201\n",
      "Epoch: 0087 train_loss= 0.44290 time= 0.00199\n",
      "Epoch: 0088 train_loss= 0.44210 time= 0.00300\n",
      "Epoch: 0089 train_loss= 0.44484 time= 0.00301\n",
      "Epoch: 0090 train_loss= 0.43790 time= 0.00199\n",
      "Epoch: 0091 train_loss= 0.43597 time= 0.00200\n",
      "Epoch: 0092 train_loss= 0.44193 time= 0.00199\n",
      "Epoch: 0093 train_loss= 0.43549 time= 0.00301\n",
      "Epoch: 0094 train_loss= 0.43631 time= 0.00200\n",
      "Epoch: 0095 train_loss= 0.44471 time= 0.00300\n",
      "Epoch: 0096 train_loss= 0.44577 time= 0.00200\n",
      "Epoch: 0097 train_loss= 0.44349 time= 0.00199\n",
      "Epoch: 0098 train_loss= 0.43849 time= 0.00310\n",
      "Epoch: 0099 train_loss= 0.43849 time= 0.00191\n",
      "Epoch: 0100 train_loss= 0.43490 time= 0.00200\n",
      "Epoch: 0101 train_loss= 0.43735 time= 0.00402\n",
      "Epoch: 0102 train_loss= 0.44490 time= 0.00198\n",
      "Epoch: 0103 train_loss= 0.44135 time= 0.00206\n",
      "Epoch: 0104 train_loss= 0.44360 time= 0.00194\n",
      "Epoch: 0105 train_loss= 0.43954 time= 0.00201\n",
      "Epoch: 0106 train_loss= 0.43854 time= 0.00199\n",
      "Epoch: 0107 train_loss= 0.43515 time= 0.00204\n",
      "Epoch: 0108 train_loss= 0.43254 time= 0.00292\n",
      "Epoch: 0109 train_loss= 0.43870 time= 0.00200\n",
      "Epoch: 0110 train_loss= 0.43403 time= 0.00200\n",
      "Epoch: 0111 train_loss= 0.44080 time= 0.00198\n",
      "Epoch: 0112 train_loss= 0.43919 time= 0.00209\n",
      "Epoch: 0113 train_loss= 0.43330 time= 0.00208\n",
      "Epoch: 0114 train_loss= 0.43071 time= 0.00306\n",
      "Epoch: 0115 train_loss= 0.43125 time= 0.00186\n",
      "Epoch: 0116 train_loss= 0.43340 time= 0.00204\n",
      "Epoch: 0117 train_loss= 0.43700 time= 0.00201\n",
      "Epoch: 0118 train_loss= 0.42767 time= 0.00300\n",
      "Epoch: 0119 train_loss= 0.43059 time= 0.00198\n",
      "Epoch: 0120 train_loss= 0.43622 time= 0.00296\n",
      "Epoch: 0121 train_loss= 0.43341 time= 0.00202\n",
      "Epoch: 0122 train_loss= 0.44169 time= 0.00300\n",
      "Epoch: 0123 train_loss= 0.43390 time= 0.00194\n",
      "Epoch: 0124 train_loss= 0.43610 time= 0.00204\n",
      "Epoch: 0125 train_loss= 0.43625 time= 0.00196\n",
      "Epoch: 0126 train_loss= 0.43394 time= 0.00300\n",
      "Epoch: 0127 train_loss= 0.43486 time= 0.00299\n",
      "Epoch: 0128 train_loss= 0.43816 time= 0.00196\n",
      "Epoch: 0129 train_loss= 0.43342 time= 0.00199\n",
      "Epoch: 0130 train_loss= 0.43356 time= 0.00306\n",
      "Epoch: 0131 train_loss= 0.44049 time= 0.00196\n",
      "Epoch: 0132 train_loss= 0.43076 time= 0.00200\n",
      "Epoch: 0133 train_loss= 0.43758 time= 0.00194\n",
      "Epoch: 0134 train_loss= 0.43560 time= 0.00196\n",
      "Epoch: 0135 train_loss= 0.43587 time= 0.00202\n",
      "Epoch: 0136 train_loss= 0.43133 time= 0.00293\n",
      "Epoch: 0137 train_loss= 0.42998 time= 0.00301\n",
      "Epoch: 0138 train_loss= 0.43055 time= 0.00307\n",
      "Epoch: 0139 train_loss= 0.42981 time= 0.00292\n",
      "Epoch: 0140 train_loss= 0.42299 time= 0.00316\n",
      "Epoch: 0141 train_loss= 0.43413 time= 0.00289\n",
      "Epoch: 0142 train_loss= 0.42476 time= 0.00201\n",
      "Epoch: 0143 train_loss= 0.43607 time= 0.00301\n",
      "Epoch: 0144 train_loss= 0.43998 time= 0.00302\n",
      "Epoch: 0145 train_loss= 0.42461 time= 0.00297\n",
      "Epoch: 0146 train_loss= 0.43392 time= 0.00200\n",
      "Epoch: 0147 train_loss= 0.43122 time= 0.00195\n",
      "Epoch: 0148 train_loss= 0.44465 time= 0.00196\n",
      "Epoch: 0149 train_loss= 0.43533 time= 0.00308\n",
      "Epoch: 0150 train_loss= 0.43999 time= 0.00292\n",
      "Epoch: 0151 train_loss= 0.43862 time= 0.00200\n",
      "Epoch: 0152 train_loss= 0.43580 time= 0.00298\n",
      "Epoch: 0153 train_loss= 0.43875 time= 0.00196\n",
      "Epoch: 0154 train_loss= 0.43462 time= 0.00209\n",
      "Epoch: 0155 train_loss= 0.43514 time= 0.00304\n",
      "Epoch: 0156 train_loss= 0.42926 time= 0.00294\n",
      "Epoch: 0157 train_loss= 0.42678 time= 0.00193\n",
      "Epoch: 0158 train_loss= 0.43278 time= 0.00208\n",
      "Epoch: 0159 train_loss= 0.42628 time= 0.00197\n",
      "Epoch: 0160 train_loss= 0.43182 time= 0.00299\n",
      "Epoch: 0161 train_loss= 0.44304 time= 0.00401\n",
      "Epoch: 0162 train_loss= 0.42733 time= 0.00299\n",
      "Epoch: 0163 train_loss= 0.42288 time= 0.00341\n",
      "Epoch: 0164 train_loss= 0.43507 time= 0.00300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0165 train_loss= 0.42739 time= 0.00401\n",
      "Epoch: 0166 train_loss= 0.42781 time= 0.00294\n",
      "Epoch: 0167 train_loss= 0.43739 time= 0.00201\n",
      "Epoch: 0168 train_loss= 0.42678 time= 0.00202\n",
      "Epoch: 0169 train_loss= 0.42542 time= 0.00297\n",
      "Epoch: 0170 train_loss= 0.42645 time= 0.00302\n",
      "Epoch: 0171 train_loss= 0.42842 time= 0.00396\n",
      "Epoch: 0172 train_loss= 0.42043 time= 0.00301\n",
      "Epoch: 0173 train_loss= 0.43005 time= 0.00197\n",
      "Epoch: 0174 train_loss= 0.42317 time= 0.00207\n",
      "Epoch: 0175 train_loss= 0.42851 time= 0.00202\n",
      "Epoch: 0176 train_loss= 0.42739 time= 0.00300\n",
      "Epoch: 0177 train_loss= 0.43108 time= 0.00200\n",
      "Epoch: 0178 train_loss= 0.42145 time= 0.00197\n",
      "Epoch: 0179 train_loss= 0.42764 time= 0.00197\n",
      "Epoch: 0180 train_loss= 0.42754 time= 0.00199\n",
      "Epoch: 0181 train_loss= 0.43307 time= 0.00297\n",
      "Epoch: 0182 train_loss= 0.43370 time= 0.00419\n",
      "Epoch: 0183 train_loss= 0.42118 time= 0.00288\n",
      "Epoch: 0184 train_loss= 0.42608 time= 0.00200\n",
      "Epoch: 0185 train_loss= 0.42690 time= 0.00301\n",
      "Epoch: 0186 train_loss= 0.42497 time= 0.00302\n",
      "Epoch: 0187 train_loss= 0.43038 time= 0.00299\n",
      "Epoch: 0188 train_loss= 0.42116 time= 0.00305\n",
      "Epoch: 0189 train_loss= 0.42460 time= 0.00291\n",
      "Epoch: 0190 train_loss= 0.42100 time= 0.00344\n",
      "Epoch: 0191 train_loss= 0.42147 time= 0.00160\n",
      "Epoch: 0192 train_loss= 0.42722 time= 0.00199\n",
      "Epoch: 0193 train_loss= 0.42662 time= 0.00201\n",
      "Epoch: 0194 train_loss= 0.42103 time= 0.00288\n",
      "Epoch: 0195 train_loss= 0.42364 time= 0.00299\n",
      "Epoch: 0196 train_loss= 0.42247 time= 0.00306\n",
      "Epoch: 0197 train_loss= 0.42325 time= 0.00290\n",
      "Epoch: 0198 train_loss= 0.41834 time= 0.00203\n",
      "Epoch: 0199 train_loss= 0.42444 time= 0.00299\n",
      "Epoch: 0200 train_loss= 0.42036 time= 0.00299\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.51442 time= 0.12805\n",
      "Epoch: 0002 train_loss= 1.20495 time= 0.00201\n",
      "Epoch: 0003 train_loss= 0.86979 time= 0.00299\n",
      "Epoch: 0004 train_loss= 0.88308 time= 0.00295\n",
      "Epoch: 0005 train_loss= 0.88208 time= 0.00200\n",
      "Epoch: 0006 train_loss= 0.71111 time= 0.00304\n",
      "Epoch: 0007 train_loss= 0.60788 time= 0.00197\n",
      "Epoch: 0008 train_loss= 0.61110 time= 0.00200\n",
      "Epoch: 0009 train_loss= 0.66836 time= 0.00304\n",
      "Epoch: 0010 train_loss= 0.66123 time= 0.00297\n",
      "Epoch: 0011 train_loss= 0.64171 time= 0.00394\n",
      "Epoch: 0012 train_loss= 0.60061 time= 0.00199\n",
      "Epoch: 0013 train_loss= 0.57231 time= 0.00197\n",
      "Epoch: 0014 train_loss= 0.56004 time= 0.00315\n",
      "Epoch: 0015 train_loss= 0.56140 time= 0.00281\n",
      "Epoch: 0016 train_loss= 0.56530 time= 0.00202\n",
      "Epoch: 0017 train_loss= 0.55898 time= 0.00294\n",
      "Epoch: 0018 train_loss= 0.55178 time= 0.00201\n",
      "Epoch: 0019 train_loss= 0.53286 time= 0.00202\n",
      "Epoch: 0020 train_loss= 0.53054 time= 0.00300\n",
      "Epoch: 0021 train_loss= 0.52355 time= 0.00194\n",
      "Epoch: 0022 train_loss= 0.52812 time= 0.00294\n",
      "Epoch: 0023 train_loss= 0.52128 time= 0.00198\n",
      "Epoch: 0024 train_loss= 0.51168 time= 0.00308\n",
      "Epoch: 0025 train_loss= 0.50497 time= 0.00293\n",
      "Epoch: 0026 train_loss= 0.50353 time= 0.00295\n",
      "Epoch: 0027 train_loss= 0.49372 time= 0.00200\n",
      "Epoch: 0028 train_loss= 0.49312 time= 0.00300\n",
      "Epoch: 0029 train_loss= 0.50227 time= 0.00201\n",
      "Epoch: 0030 train_loss= 0.49529 time= 0.00310\n",
      "Epoch: 0031 train_loss= 0.49162 time= 0.00299\n",
      "Epoch: 0032 train_loss= 0.48952 time= 0.00198\n",
      "Epoch: 0033 train_loss= 0.48341 time= 0.00190\n",
      "Epoch: 0034 train_loss= 0.48302 time= 0.00207\n",
      "Epoch: 0035 train_loss= 0.47828 time= 0.00190\n",
      "Epoch: 0036 train_loss= 0.47628 time= 0.00193\n",
      "Epoch: 0037 train_loss= 0.47559 time= 0.00309\n",
      "Epoch: 0038 train_loss= 0.47285 time= 0.00190\n",
      "Epoch: 0039 train_loss= 0.46458 time= 0.00203\n",
      "Epoch: 0040 train_loss= 0.46775 time= 0.00194\n",
      "Epoch: 0041 train_loss= 0.46260 time= 0.00200\n",
      "Epoch: 0042 train_loss= 0.46625 time= 0.00201\n",
      "Epoch: 0043 train_loss= 0.46686 time= 0.00195\n",
      "Epoch: 0044 train_loss= 0.46143 time= 0.00200\n",
      "Epoch: 0045 train_loss= 0.46430 time= 0.00212\n",
      "Epoch: 0046 train_loss= 0.45822 time= 0.00187\n",
      "Epoch: 0047 train_loss= 0.46018 time= 0.00205\n",
      "Epoch: 0048 train_loss= 0.46519 time= 0.00199\n",
      "Epoch: 0049 train_loss= 0.46150 time= 0.00305\n",
      "Epoch: 0050 train_loss= 0.48113 time= 0.00303\n",
      "Epoch: 0051 train_loss= 0.45399 time= 0.00292\n",
      "Epoch: 0052 train_loss= 0.46303 time= 0.00307\n",
      "Epoch: 0053 train_loss= 0.46157 time= 0.00300\n",
      "Epoch: 0054 train_loss= 0.45665 time= 0.00298\n",
      "Epoch: 0055 train_loss= 0.46262 time= 0.00196\n",
      "Epoch: 0056 train_loss= 0.45514 time= 0.00195\n",
      "Epoch: 0057 train_loss= 0.45919 time= 0.00308\n",
      "Epoch: 0058 train_loss= 0.45827 time= 0.00192\n",
      "Epoch: 0059 train_loss= 0.46084 time= 0.00206\n",
      "Epoch: 0060 train_loss= 0.45156 time= 0.00205\n",
      "Epoch: 0061 train_loss= 0.44956 time= 0.00195\n",
      "Epoch: 0062 train_loss= 0.45306 time= 0.00302\n",
      "Epoch: 0063 train_loss= 0.45133 time= 0.00316\n",
      "Epoch: 0064 train_loss= 0.44264 time= 0.00201\n",
      "Epoch: 0065 train_loss= 0.44856 time= 0.00299\n",
      "Epoch: 0066 train_loss= 0.45127 time= 0.00208\n",
      "Epoch: 0067 train_loss= 0.44633 time= 0.00299\n",
      "Epoch: 0068 train_loss= 0.46085 time= 0.00193\n",
      "Epoch: 0069 train_loss= 0.45804 time= 0.00202\n",
      "Epoch: 0070 train_loss= 0.45053 time= 0.00295\n",
      "Epoch: 0071 train_loss= 0.45231 time= 0.00201\n",
      "Epoch: 0072 train_loss= 0.45078 time= 0.00206\n",
      "Epoch: 0073 train_loss= 0.44568 time= 0.00195\n",
      "Epoch: 0074 train_loss= 0.44283 time= 0.00196\n",
      "Epoch: 0075 train_loss= 0.44787 time= 0.00198\n",
      "Epoch: 0076 train_loss= 0.44459 time= 0.00305\n",
      "Epoch: 0077 train_loss= 0.44111 time= 0.00194\n",
      "Epoch: 0078 train_loss= 0.44144 time= 0.00211\n",
      "Epoch: 0079 train_loss= 0.44844 time= 0.00298\n",
      "Epoch: 0080 train_loss= 0.44315 time= 0.00301\n",
      "Epoch: 0081 train_loss= 0.44187 time= 0.00299\n",
      "Epoch: 0082 train_loss= 0.44480 time= 0.00298\n",
      "Epoch: 0083 train_loss= 0.44293 time= 0.00193\n",
      "Epoch: 0084 train_loss= 0.45000 time= 0.00201\n",
      "Epoch: 0085 train_loss= 0.45136 time= 0.00298\n",
      "Epoch: 0086 train_loss= 0.44324 time= 0.00207\n",
      "Epoch: 0087 train_loss= 0.44663 time= 0.00217\n",
      "Epoch: 0088 train_loss= 0.44138 time= 0.00206\n",
      "Epoch: 0089 train_loss= 0.44188 time= 0.00293\n",
      "Epoch: 0090 train_loss= 0.44014 time= 0.00310\n",
      "Epoch: 0091 train_loss= 0.43880 time= 0.00292\n",
      "Epoch: 0092 train_loss= 0.43811 time= 0.00200\n",
      "Epoch: 0093 train_loss= 0.43796 time= 0.00200\n",
      "Epoch: 0094 train_loss= 0.44206 time= 0.00199\n",
      "Epoch: 0095 train_loss= 0.44251 time= 0.00303\n",
      "Epoch: 0096 train_loss= 0.43770 time= 0.00198\n",
      "Epoch: 0097 train_loss= 0.44049 time= 0.00205\n",
      "Epoch: 0098 train_loss= 0.44161 time= 0.00195\n",
      "Epoch: 0099 train_loss= 0.45101 time= 0.00309\n",
      "Epoch: 0100 train_loss= 0.45130 time= 0.00261\n",
      "Epoch: 0101 train_loss= 0.44463 time= 0.00189\n",
      "Epoch: 0102 train_loss= 0.44365 time= 0.00202\n",
      "Epoch: 0103 train_loss= 0.44051 time= 0.00201\n",
      "Epoch: 0104 train_loss= 0.44875 time= 0.00206\n",
      "Epoch: 0105 train_loss= 0.44543 time= 0.00202\n",
      "Epoch: 0106 train_loss= 0.43635 time= 0.00302\n",
      "Epoch: 0107 train_loss= 0.43784 time= 0.00198\n",
      "Epoch: 0108 train_loss= 0.43657 time= 0.00202\n",
      "Epoch: 0109 train_loss= 0.43700 time= 0.00199\n",
      "Epoch: 0110 train_loss= 0.43425 time= 0.00296\n",
      "Epoch: 0111 train_loss= 0.43655 time= 0.00201\n",
      "Epoch: 0112 train_loss= 0.43402 time= 0.00199\n",
      "Epoch: 0113 train_loss= 0.43063 time= 0.00200\n",
      "Epoch: 0114 train_loss= 0.43818 time= 0.00203\n",
      "Epoch: 0115 train_loss= 0.43467 time= 0.00191\n",
      "Epoch: 0116 train_loss= 0.43194 time= 0.00200\n",
      "Epoch: 0117 train_loss= 0.43937 time= 0.00099\n",
      "Epoch: 0118 train_loss= 0.43165 time= 0.00214\n",
      "Epoch: 0119 train_loss= 0.44040 time= 0.00153\n",
      "Epoch: 0120 train_loss= 0.43446 time= 0.00199\n",
      "Epoch: 0121 train_loss= 0.43879 time= 0.00197\n",
      "Epoch: 0122 train_loss= 0.43491 time= 0.00199\n",
      "Epoch: 0123 train_loss= 0.43139 time= 0.00200\n",
      "Epoch: 0124 train_loss= 0.44253 time= 0.00195\n",
      "Epoch: 0125 train_loss= 0.43252 time= 0.00310\n",
      "Epoch: 0126 train_loss= 0.43213 time= 0.00196\n",
      "Epoch: 0127 train_loss= 0.43984 time= 0.00213\n",
      "Epoch: 0128 train_loss= 0.43662 time= 0.00187\n",
      "Epoch: 0129 train_loss= 0.43743 time= 0.00206\n",
      "Epoch: 0130 train_loss= 0.43511 time= 0.00199\n",
      "Epoch: 0131 train_loss= 0.43483 time= 0.00196\n",
      "Epoch: 0132 train_loss= 0.43481 time= 0.00304\n",
      "Epoch: 0133 train_loss= 0.43301 time= 0.00296\n",
      "Epoch: 0134 train_loss= 0.42943 time= 0.00199\n",
      "Epoch: 0135 train_loss= 0.43368 time= 0.00201\n",
      "Epoch: 0136 train_loss= 0.42684 time= 0.00304\n",
      "Epoch: 0137 train_loss= 0.42781 time= 0.00195\n",
      "Epoch: 0138 train_loss= 0.43268 time= 0.00171\n",
      "Epoch: 0139 train_loss= 0.43057 time= 0.00309\n",
      "Epoch: 0140 train_loss= 0.43580 time= 0.00304\n",
      "Epoch: 0141 train_loss= 0.42962 time= 0.00190\n",
      "Epoch: 0142 train_loss= 0.43016 time= 0.00209\n",
      "Epoch: 0143 train_loss= 0.43831 time= 0.00210\n",
      "Epoch: 0144 train_loss= 0.42645 time= 0.00189\n",
      "Epoch: 0145 train_loss= 0.43319 time= 0.00308\n",
      "Epoch: 0146 train_loss= 0.43643 time= 0.00196\n",
      "Epoch: 0147 train_loss= 0.43002 time= 0.00305\n",
      "Epoch: 0148 train_loss= 0.43955 time= 0.00312\n",
      "Epoch: 0149 train_loss= 0.42901 time= 0.00293\n",
      "Epoch: 0150 train_loss= 0.43240 time= 0.00207\n",
      "Epoch: 0151 train_loss= 0.43619 time= 0.00283\n",
      "Epoch: 0152 train_loss= 0.42919 time= 0.00310\n",
      "Epoch: 0153 train_loss= 0.43322 time= 0.00208\n",
      "Epoch: 0154 train_loss= 0.42889 time= 0.00189\n",
      "Epoch: 0155 train_loss= 0.42740 time= 0.00202\n",
      "Epoch: 0156 train_loss= 0.42960 time= 0.00199\n",
      "Epoch: 0157 train_loss= 0.43201 time= 0.00201\n",
      "Epoch: 0158 train_loss= 0.42961 time= 0.00196\n",
      "Epoch: 0159 train_loss= 0.42978 time= 0.00304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0160 train_loss= 0.43225 time= 0.00195\n",
      "Epoch: 0161 train_loss= 0.42679 time= 0.00307\n",
      "Epoch: 0162 train_loss= 0.43169 time= 0.00199\n",
      "Epoch: 0163 train_loss= 0.43362 time= 0.00294\n",
      "Epoch: 0164 train_loss= 0.42763 time= 0.00207\n",
      "Epoch: 0165 train_loss= 0.43010 time= 0.00293\n",
      "Epoch: 0166 train_loss= 0.43712 time= 0.00201\n",
      "Epoch: 0167 train_loss= 0.42812 time= 0.00195\n",
      "Epoch: 0168 train_loss= 0.43014 time= 0.00199\n",
      "Epoch: 0169 train_loss= 0.42935 time= 0.00295\n",
      "Epoch: 0170 train_loss= 0.42900 time= 0.00308\n",
      "Epoch: 0171 train_loss= 0.43318 time= 0.00201\n",
      "Epoch: 0172 train_loss= 0.43552 time= 0.00199\n",
      "Epoch: 0173 train_loss= 0.42692 time= 0.00199\n",
      "Epoch: 0174 train_loss= 0.43084 time= 0.00200\n",
      "Epoch: 0175 train_loss= 0.42841 time= 0.00206\n",
      "Epoch: 0176 train_loss= 0.42408 time= 0.00299\n",
      "Epoch: 0177 train_loss= 0.42522 time= 0.00203\n",
      "Epoch: 0178 train_loss= 0.42691 time= 0.00206\n",
      "Epoch: 0179 train_loss= 0.42718 time= 0.00201\n",
      "Epoch: 0180 train_loss= 0.42621 time= 0.00200\n",
      "Epoch: 0181 train_loss= 0.42895 time= 0.00300\n",
      "Epoch: 0182 train_loss= 0.42221 time= 0.00211\n",
      "Epoch: 0183 train_loss= 0.42712 time= 0.00289\n",
      "Epoch: 0184 train_loss= 0.42365 time= 0.00206\n",
      "Epoch: 0185 train_loss= 0.42260 time= 0.00297\n",
      "Epoch: 0186 train_loss= 0.42503 time= 0.00303\n",
      "Epoch: 0187 train_loss= 0.42109 time= 0.00201\n",
      "Epoch: 0188 train_loss= 0.42436 time= 0.00193\n",
      "Epoch: 0189 train_loss= 0.43470 time= 0.00198\n",
      "Epoch: 0190 train_loss= 0.42916 time= 0.00201\n",
      "Epoch: 0191 train_loss= 0.42570 time= 0.00195\n",
      "Epoch: 0192 train_loss= 0.42143 time= 0.00301\n",
      "Epoch: 0193 train_loss= 0.43169 time= 0.00198\n",
      "Epoch: 0194 train_loss= 0.42553 time= 0.00194\n",
      "Epoch: 0195 train_loss= 0.43120 time= 0.00307\n",
      "Epoch: 0196 train_loss= 0.42950 time= 0.00194\n",
      "Epoch: 0197 train_loss= 0.42776 time= 0.00199\n",
      "Epoch: 0198 train_loss= 0.42810 time= 0.00199\n",
      "Epoch: 0199 train_loss= 0.42764 time= 0.00195\n",
      "Epoch: 0200 train_loss= 0.43016 time= 0.00305\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.55967 time= 0.13107\n",
      "Epoch: 0002 train_loss= 1.25147 time= 0.00302\n",
      "Epoch: 0003 train_loss= 0.95059 time= 0.00303\n",
      "Epoch: 0004 train_loss= 0.78188 time= 0.00302\n",
      "Epoch: 0005 train_loss= 0.80676 time= 0.00301\n",
      "Epoch: 0006 train_loss= 0.70318 time= 0.00291\n",
      "Epoch: 0007 train_loss= 0.60602 time= 0.00300\n",
      "Epoch: 0008 train_loss= 0.61705 time= 0.00396\n",
      "Epoch: 0009 train_loss= 0.64471 time= 0.00198\n",
      "Epoch: 0010 train_loss= 0.66055 time= 0.00305\n",
      "Epoch: 0011 train_loss= 0.63974 time= 0.00311\n",
      "Epoch: 0012 train_loss= 0.59976 time= 0.00206\n",
      "Epoch: 0013 train_loss= 0.56527 time= 0.00194\n",
      "Epoch: 0014 train_loss= 0.56382 time= 0.00299\n",
      "Epoch: 0015 train_loss= 0.56314 time= 0.00309\n",
      "Epoch: 0016 train_loss= 0.56432 time= 0.00295\n",
      "Epoch: 0017 train_loss= 0.55236 time= 0.00206\n",
      "Epoch: 0018 train_loss= 0.53644 time= 0.00288\n",
      "Epoch: 0019 train_loss= 0.52461 time= 0.00206\n",
      "Epoch: 0020 train_loss= 0.51631 time= 0.00208\n",
      "Epoch: 0021 train_loss= 0.51819 time= 0.00297\n",
      "Epoch: 0022 train_loss= 0.52036 time= 0.00202\n",
      "Epoch: 0023 train_loss= 0.51149 time= 0.00294\n",
      "Epoch: 0024 train_loss= 0.50550 time= 0.00301\n",
      "Epoch: 0025 train_loss= 0.50304 time= 0.00193\n",
      "Epoch: 0026 train_loss= 0.49381 time= 0.00309\n",
      "Epoch: 0027 train_loss= 0.48746 time= 0.00301\n",
      "Epoch: 0028 train_loss= 0.48968 time= 0.00190\n",
      "Epoch: 0029 train_loss= 0.48620 time= 0.00196\n",
      "Epoch: 0030 train_loss= 0.48125 time= 0.00309\n",
      "Epoch: 0031 train_loss= 0.48076 time= 0.00202\n",
      "Epoch: 0032 train_loss= 0.47475 time= 0.00205\n",
      "Epoch: 0033 train_loss= 0.47867 time= 0.00294\n",
      "Epoch: 0034 train_loss= 0.48494 time= 0.00205\n",
      "Epoch: 0035 train_loss= 0.46980 time= 0.00189\n",
      "Epoch: 0036 train_loss= 0.47660 time= 0.00299\n",
      "Epoch: 0037 train_loss= 0.47092 time= 0.00309\n",
      "Epoch: 0038 train_loss= 0.46262 time= 0.00196\n",
      "Epoch: 0039 train_loss= 0.47179 time= 0.00203\n",
      "Epoch: 0040 train_loss= 0.46724 time= 0.00208\n",
      "Epoch: 0041 train_loss= 0.47001 time= 0.00303\n",
      "Epoch: 0042 train_loss= 0.46135 time= 0.00188\n",
      "Epoch: 0043 train_loss= 0.46650 time= 0.00202\n",
      "Epoch: 0044 train_loss= 0.45552 time= 0.00303\n",
      "Epoch: 0045 train_loss= 0.45734 time= 0.00299\n",
      "Epoch: 0046 train_loss= 0.45809 time= 0.00190\n",
      "Epoch: 0047 train_loss= 0.44840 time= 0.00305\n",
      "Epoch: 0048 train_loss= 0.46658 time= 0.00303\n",
      "Epoch: 0049 train_loss= 0.46286 time= 0.00203\n",
      "Epoch: 0050 train_loss= 0.44874 time= 0.00194\n",
      "Epoch: 0051 train_loss= 0.45331 time= 0.00200\n",
      "Epoch: 0052 train_loss= 0.45376 time= 0.00305\n",
      "Epoch: 0053 train_loss= 0.45013 time= 0.00300\n",
      "Epoch: 0054 train_loss= 0.45114 time= 0.00301\n",
      "Epoch: 0055 train_loss= 0.45099 time= 0.00208\n",
      "Epoch: 0056 train_loss= 0.44770 time= 0.00291\n",
      "Epoch: 0057 train_loss= 0.44691 time= 0.00200\n",
      "Epoch: 0058 train_loss= 0.44389 time= 0.00208\n",
      "Epoch: 0059 train_loss= 0.44939 time= 0.00294\n",
      "Epoch: 0060 train_loss= 0.44863 time= 0.00206\n",
      "Epoch: 0061 train_loss= 0.44452 time= 0.00195\n",
      "Epoch: 0062 train_loss= 0.44548 time= 0.00201\n",
      "Epoch: 0063 train_loss= 0.44540 time= 0.00200\n",
      "Epoch: 0064 train_loss= 0.45092 time= 0.00206\n",
      "Epoch: 0065 train_loss= 0.44485 time= 0.00300\n",
      "Epoch: 0066 train_loss= 0.44813 time= 0.00302\n",
      "Epoch: 0067 train_loss= 0.44824 time= 0.00295\n",
      "Epoch: 0068 train_loss= 0.44777 time= 0.00194\n",
      "Epoch: 0069 train_loss= 0.44886 time= 0.00193\n",
      "Epoch: 0070 train_loss= 0.43993 time= 0.00194\n",
      "Epoch: 0071 train_loss= 0.44595 time= 0.00399\n",
      "Epoch: 0072 train_loss= 0.44216 time= 0.00205\n",
      "Epoch: 0073 train_loss= 0.44228 time= 0.00199\n",
      "Epoch: 0074 train_loss= 0.44723 time= 0.00213\n",
      "Epoch: 0075 train_loss= 0.44783 time= 0.00188\n",
      "Epoch: 0076 train_loss= 0.44602 time= 0.00201\n",
      "Epoch: 0077 train_loss= 0.44850 time= 0.00298\n",
      "Epoch: 0078 train_loss= 0.43700 time= 0.00302\n",
      "Epoch: 0079 train_loss= 0.44289 time= 0.00297\n",
      "Epoch: 0080 train_loss= 0.44162 time= 0.00194\n",
      "Epoch: 0081 train_loss= 0.44068 time= 0.00301\n",
      "Epoch: 0082 train_loss= 0.44221 time= 0.00309\n",
      "Epoch: 0083 train_loss= 0.43631 time= 0.00295\n",
      "Epoch: 0084 train_loss= 0.44455 time= 0.00206\n",
      "Epoch: 0085 train_loss= 0.43661 time= 0.00301\n",
      "Epoch: 0086 train_loss= 0.44614 time= 0.00298\n",
      "Epoch: 0087 train_loss= 0.44678 time= 0.00301\n",
      "Epoch: 0088 train_loss= 0.44639 time= 0.00295\n",
      "Epoch: 0089 train_loss= 0.44100 time= 0.00207\n",
      "Epoch: 0090 train_loss= 0.44263 time= 0.00287\n",
      "Epoch: 0091 train_loss= 0.43432 time= 0.00203\n",
      "Epoch: 0092 train_loss= 0.43535 time= 0.00206\n",
      "Epoch: 0093 train_loss= 0.43941 time= 0.00390\n",
      "Epoch: 0094 train_loss= 0.43123 time= 0.00206\n",
      "Epoch: 0095 train_loss= 0.43718 time= 0.00200\n",
      "Epoch: 0096 train_loss= 0.43891 time= 0.00300\n",
      "Epoch: 0097 train_loss= 0.43209 time= 0.00201\n",
      "Epoch: 0098 train_loss= 0.43245 time= 0.00200\n",
      "Epoch: 0099 train_loss= 0.43485 time= 0.00208\n",
      "Epoch: 0100 train_loss= 0.43556 time= 0.00187\n",
      "Epoch: 0101 train_loss= 0.43168 time= 0.00405\n",
      "Epoch: 0102 train_loss= 0.43902 time= 0.00300\n",
      "Epoch: 0103 train_loss= 0.42900 time= 0.00204\n",
      "Epoch: 0104 train_loss= 0.43932 time= 0.00300\n",
      "Epoch: 0105 train_loss= 0.43490 time= 0.00197\n",
      "Epoch: 0106 train_loss= 0.43648 time= 0.00199\n",
      "Epoch: 0107 train_loss= 0.43220 time= 0.00199\n",
      "Epoch: 0108 train_loss= 0.43224 time= 0.00305\n",
      "Epoch: 0109 train_loss= 0.43101 time= 0.00305\n",
      "Epoch: 0110 train_loss= 0.43255 time= 0.00189\n",
      "Epoch: 0111 train_loss= 0.43617 time= 0.00205\n",
      "Epoch: 0112 train_loss= 0.44114 time= 0.00201\n",
      "Epoch: 0113 train_loss= 0.42810 time= 0.00201\n",
      "Epoch: 0114 train_loss= 0.43175 time= 0.00193\n",
      "Epoch: 0115 train_loss= 0.43094 time= 0.00308\n",
      "Epoch: 0116 train_loss= 0.43193 time= 0.00192\n",
      "Epoch: 0117 train_loss= 0.43261 time= 0.00304\n",
      "Epoch: 0118 train_loss= 0.42503 time= 0.00198\n",
      "Epoch: 0119 train_loss= 0.43310 time= 0.00201\n",
      "Epoch: 0120 train_loss= 0.43207 time= 0.00198\n",
      "Epoch: 0121 train_loss= 0.43179 time= 0.00307\n",
      "Epoch: 0122 train_loss= 0.42867 time= 0.00198\n",
      "Epoch: 0123 train_loss= 0.42743 time= 0.00201\n",
      "Epoch: 0124 train_loss= 0.42893 time= 0.00298\n",
      "Epoch: 0125 train_loss= 0.44710 time= 0.00197\n",
      "Epoch: 0126 train_loss= 0.43366 time= 0.00198\n",
      "Epoch: 0127 train_loss= 0.42796 time= 0.00206\n",
      "Epoch: 0128 train_loss= 0.43565 time= 0.00200\n",
      "Epoch: 0129 train_loss= 0.44240 time= 0.00304\n",
      "Epoch: 0130 train_loss= 0.43180 time= 0.00197\n",
      "Epoch: 0131 train_loss= 0.43221 time= 0.00297\n",
      "Epoch: 0132 train_loss= 0.43078 time= 0.00305\n",
      "Epoch: 0133 train_loss= 0.42380 time= 0.00296\n",
      "Epoch: 0134 train_loss= 0.42775 time= 0.00202\n",
      "Epoch: 0135 train_loss= 0.43249 time= 0.00200\n",
      "Epoch: 0136 train_loss= 0.43490 time= 0.00310\n",
      "Epoch: 0137 train_loss= 0.43141 time= 0.00192\n",
      "Epoch: 0138 train_loss= 0.43360 time= 0.00201\n",
      "Epoch: 0139 train_loss= 0.42709 time= 0.00305\n",
      "Epoch: 0140 train_loss= 0.42773 time= 0.00195\n",
      "Epoch: 0141 train_loss= 0.43072 time= 0.00307\n",
      "Epoch: 0142 train_loss= 0.44409 time= 0.00192\n",
      "Epoch: 0143 train_loss= 0.42404 time= 0.00194\n",
      "Epoch: 0144 train_loss= 0.42902 time= 0.00200\n",
      "Epoch: 0145 train_loss= 0.43323 time= 0.00302\n",
      "Epoch: 0146 train_loss= 0.44057 time= 0.00202\n",
      "Epoch: 0147 train_loss= 0.43204 time= 0.00293\n",
      "Epoch: 0148 train_loss= 0.43017 time= 0.00301\n",
      "Epoch: 0149 train_loss= 0.42794 time= 0.00200\n",
      "Epoch: 0150 train_loss= 0.43062 time= 0.00305\n",
      "Epoch: 0151 train_loss= 0.43031 time= 0.00303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0152 train_loss= 0.43193 time= 0.00292\n",
      "Epoch: 0153 train_loss= 0.42389 time= 0.00300\n",
      "Epoch: 0154 train_loss= 0.43303 time= 0.00307\n",
      "Epoch: 0155 train_loss= 0.42266 time= 0.00299\n",
      "Epoch: 0156 train_loss= 0.43047 time= 0.00197\n",
      "Epoch: 0157 train_loss= 0.42415 time= 0.00301\n",
      "Epoch: 0158 train_loss= 0.43446 time= 0.00300\n",
      "Epoch: 0159 train_loss= 0.42401 time= 0.00299\n",
      "Epoch: 0160 train_loss= 0.42489 time= 0.00401\n",
      "Epoch: 0161 train_loss= 0.42584 time= 0.00194\n",
      "Epoch: 0162 train_loss= 0.42696 time= 0.00312\n",
      "Epoch: 0163 train_loss= 0.42703 time= 0.00200\n",
      "Epoch: 0164 train_loss= 0.42420 time= 0.00200\n",
      "Epoch: 0165 train_loss= 0.43147 time= 0.00294\n",
      "Epoch: 0166 train_loss= 0.42400 time= 0.00206\n",
      "Epoch: 0167 train_loss= 0.43092 time= 0.00305\n",
      "Epoch: 0168 train_loss= 0.42651 time= 0.00289\n",
      "Epoch: 0169 train_loss= 0.42362 time= 0.00307\n",
      "Epoch: 0170 train_loss= 0.43157 time= 0.00295\n",
      "Epoch: 0171 train_loss= 0.43368 time= 0.00298\n",
      "Epoch: 0172 train_loss= 0.42431 time= 0.00300\n",
      "Epoch: 0173 train_loss= 0.42853 time= 0.00200\n",
      "Epoch: 0174 train_loss= 0.42968 time= 0.00199\n",
      "Epoch: 0175 train_loss= 0.42766 time= 0.00311\n",
      "Epoch: 0176 train_loss= 0.42274 time= 0.00296\n",
      "Epoch: 0177 train_loss= 0.42603 time= 0.00298\n",
      "Epoch: 0178 train_loss= 0.42665 time= 0.00196\n",
      "Epoch: 0179 train_loss= 0.42081 time= 0.00209\n",
      "Epoch: 0180 train_loss= 0.42267 time= 0.00298\n",
      "Epoch: 0181 train_loss= 0.43090 time= 0.00293\n",
      "Epoch: 0182 train_loss= 0.42657 time= 0.00299\n",
      "Epoch: 0183 train_loss= 0.42655 time= 0.00300\n",
      "Epoch: 0184 train_loss= 0.43535 time= 0.00195\n",
      "Epoch: 0185 train_loss= 0.42366 time= 0.00301\n",
      "Epoch: 0186 train_loss= 0.42199 time= 0.00200\n",
      "Epoch: 0187 train_loss= 0.42208 time= 0.00199\n",
      "Epoch: 0188 train_loss= 0.42439 time= 0.00312\n",
      "Epoch: 0189 train_loss= 0.42961 time= 0.00296\n",
      "Epoch: 0190 train_loss= 0.42574 time= 0.00205\n",
      "Epoch: 0191 train_loss= 0.42299 time= 0.00191\n",
      "Epoch: 0192 train_loss= 0.42692 time= 0.00201\n",
      "Epoch: 0193 train_loss= 0.42700 time= 0.00299\n",
      "Epoch: 0194 train_loss= 0.42560 time= 0.00394\n",
      "Epoch: 0195 train_loss= 0.42507 time= 0.00309\n",
      "Epoch: 0196 train_loss= 0.42264 time= 0.00192\n",
      "Epoch: 0197 train_loss= 0.42528 time= 0.00307\n",
      "Epoch: 0198 train_loss= 0.42521 time= 0.00209\n",
      "Epoch: 0199 train_loss= 0.43527 time= 0.00494\n",
      "Epoch: 0200 train_loss= 0.42555 time= 0.00304\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.60831 time= 0.13001\n",
      "Epoch: 0002 train_loss= 1.39312 time= 0.00401\n",
      "Epoch: 0003 train_loss= 0.99225 time= 0.00304\n",
      "Epoch: 0004 train_loss= 0.76738 time= 0.00296\n",
      "Epoch: 0005 train_loss= 0.88763 time= 0.00397\n",
      "Epoch: 0006 train_loss= 0.81000 time= 0.00300\n",
      "Epoch: 0007 train_loss= 0.67295 time= 0.00299\n",
      "Epoch: 0008 train_loss= 0.60188 time= 0.00301\n",
      "Epoch: 0009 train_loss= 0.63198 time= 0.00295\n",
      "Epoch: 0010 train_loss= 0.64320 time= 0.00305\n",
      "Epoch: 0011 train_loss= 0.65434 time= 0.00300\n",
      "Epoch: 0012 train_loss= 0.65208 time= 0.00301\n",
      "Epoch: 0013 train_loss= 0.61301 time= 0.00301\n",
      "Epoch: 0014 train_loss= 0.57857 time= 0.00303\n",
      "Epoch: 0015 train_loss= 0.55537 time= 0.00294\n",
      "Epoch: 0016 train_loss= 0.54793 time= 0.00400\n",
      "Epoch: 0017 train_loss= 0.55494 time= 0.00300\n",
      "Epoch: 0018 train_loss= 0.55466 time= 0.00208\n",
      "Epoch: 0019 train_loss= 0.54897 time= 0.00201\n",
      "Epoch: 0020 train_loss= 0.54090 time= 0.00295\n",
      "Epoch: 0021 train_loss= 0.52149 time= 0.00301\n",
      "Epoch: 0022 train_loss= 0.51755 time= 0.00196\n",
      "Epoch: 0023 train_loss= 0.52112 time= 0.00310\n",
      "Epoch: 0024 train_loss= 0.51432 time= 0.00203\n",
      "Epoch: 0025 train_loss= 0.51819 time= 0.00302\n",
      "Epoch: 0026 train_loss= 0.51870 time= 0.00301\n",
      "Epoch: 0027 train_loss= 0.50888 time= 0.00295\n",
      "Epoch: 0028 train_loss= 0.50480 time= 0.00195\n",
      "Epoch: 0029 train_loss= 0.48666 time= 0.00199\n",
      "Epoch: 0030 train_loss= 0.49064 time= 0.00301\n",
      "Epoch: 0031 train_loss= 0.49786 time= 0.00296\n",
      "Epoch: 0032 train_loss= 0.48762 time= 0.00310\n",
      "Epoch: 0033 train_loss= 0.48637 time= 0.00189\n",
      "Epoch: 0034 train_loss= 0.48173 time= 0.00206\n",
      "Epoch: 0035 train_loss= 0.48317 time= 0.00202\n",
      "Epoch: 0036 train_loss= 0.47368 time= 0.00195\n",
      "Epoch: 0037 train_loss= 0.47877 time= 0.00206\n",
      "Epoch: 0038 train_loss= 0.47300 time= 0.00195\n",
      "Epoch: 0039 train_loss= 0.47392 time= 0.00199\n",
      "Epoch: 0040 train_loss= 0.47786 time= 0.00204\n",
      "Epoch: 0041 train_loss= 0.46903 time= 0.00300\n",
      "Epoch: 0042 train_loss= 0.46416 time= 0.00192\n",
      "Epoch: 0043 train_loss= 0.46591 time= 0.00302\n",
      "Epoch: 0044 train_loss= 0.46616 time= 0.00304\n",
      "Epoch: 0045 train_loss= 0.45963 time= 0.00195\n",
      "Epoch: 0046 train_loss= 0.46221 time= 0.00195\n",
      "Epoch: 0047 train_loss= 0.47009 time= 0.00305\n",
      "Epoch: 0048 train_loss= 0.45999 time= 0.00301\n",
      "Epoch: 0049 train_loss= 0.46287 time= 0.00294\n",
      "Epoch: 0050 train_loss= 0.45887 time= 0.00203\n",
      "Epoch: 0051 train_loss= 0.45832 time= 0.00298\n",
      "Epoch: 0052 train_loss= 0.45892 time= 0.00193\n",
      "Epoch: 0053 train_loss= 0.46207 time= 0.00200\n",
      "Epoch: 0054 train_loss= 0.45573 time= 0.00311\n",
      "Epoch: 0055 train_loss= 0.46584 time= 0.00294\n",
      "Epoch: 0056 train_loss= 0.45805 time= 0.00295\n",
      "Epoch: 0057 train_loss= 0.46483 time= 0.00207\n",
      "Epoch: 0058 train_loss= 0.45833 time= 0.00200\n",
      "Epoch: 0059 train_loss= 0.45323 time= 0.00302\n",
      "Epoch: 0060 train_loss= 0.45694 time= 0.00198\n",
      "Epoch: 0061 train_loss= 0.45779 time= 0.00301\n",
      "Epoch: 0062 train_loss= 0.45423 time= 0.00210\n",
      "Epoch: 0063 train_loss= 0.45477 time= 0.00189\n",
      "Epoch: 0064 train_loss= 0.44704 time= 0.00200\n",
      "Epoch: 0065 train_loss= 0.45340 time= 0.00208\n",
      "Epoch: 0066 train_loss= 0.45821 time= 0.00189\n",
      "Epoch: 0067 train_loss= 0.45223 time= 0.00294\n",
      "Epoch: 0068 train_loss= 0.44553 time= 0.00306\n",
      "Epoch: 0069 train_loss= 0.44449 time= 0.00299\n",
      "Epoch: 0070 train_loss= 0.44501 time= 0.00306\n",
      "Epoch: 0071 train_loss= 0.44769 time= 0.00188\n",
      "Epoch: 0072 train_loss= 0.45235 time= 0.00194\n",
      "Epoch: 0073 train_loss= 0.46338 time= 0.00297\n",
      "Epoch: 0074 train_loss= 0.45708 time= 0.00197\n",
      "Epoch: 0075 train_loss= 0.44548 time= 0.00199\n",
      "Epoch: 0076 train_loss= 0.44451 time= 0.00306\n",
      "Epoch: 0077 train_loss= 0.45077 time= 0.00194\n",
      "Epoch: 0078 train_loss= 0.44775 time= 0.00304\n",
      "Epoch: 0079 train_loss= 0.44844 time= 0.00305\n",
      "Epoch: 0080 train_loss= 0.45018 time= 0.00197\n",
      "Epoch: 0081 train_loss= 0.44823 time= 0.00301\n",
      "Epoch: 0082 train_loss= 0.44707 time= 0.00199\n",
      "Epoch: 0083 train_loss= 0.43993 time= 0.00200\n",
      "Epoch: 0084 train_loss= 0.43998 time= 0.00301\n",
      "Epoch: 0085 train_loss= 0.44395 time= 0.00299\n",
      "Epoch: 0086 train_loss= 0.44205 time= 0.00301\n",
      "Epoch: 0087 train_loss= 0.44406 time= 0.00300\n",
      "Epoch: 0088 train_loss= 0.44656 time= 0.00300\n",
      "Epoch: 0089 train_loss= 0.44612 time= 0.00200\n",
      "Epoch: 0090 train_loss= 0.45404 time= 0.00199\n",
      "Epoch: 0091 train_loss= 0.45539 time= 0.00309\n",
      "Epoch: 0092 train_loss= 0.44398 time= 0.00298\n",
      "Epoch: 0093 train_loss= 0.44805 time= 0.00293\n",
      "Epoch: 0094 train_loss= 0.44180 time= 0.00301\n",
      "Epoch: 0095 train_loss= 0.44400 time= 0.00309\n",
      "Epoch: 0096 train_loss= 0.43751 time= 0.00297\n",
      "Epoch: 0097 train_loss= 0.44610 time= 0.00404\n",
      "Epoch: 0098 train_loss= 0.44169 time= 0.00302\n",
      "Epoch: 0099 train_loss= 0.44103 time= 0.00200\n",
      "Epoch: 0100 train_loss= 0.44431 time= 0.00207\n",
      "Epoch: 0101 train_loss= 0.45004 time= 0.00295\n",
      "Epoch: 0102 train_loss= 0.45087 time= 0.00299\n",
      "Epoch: 0103 train_loss= 0.44644 time= 0.00200\n",
      "Epoch: 0104 train_loss= 0.44847 time= 0.00200\n",
      "Epoch: 0105 train_loss= 0.44721 time= 0.00199\n",
      "Epoch: 0106 train_loss= 0.44109 time= 0.00307\n",
      "Epoch: 0107 train_loss= 0.43772 time= 0.00193\n",
      "Epoch: 0108 train_loss= 0.44164 time= 0.00301\n",
      "Epoch: 0109 train_loss= 0.44483 time= 0.00211\n",
      "Epoch: 0110 train_loss= 0.43441 time= 0.00211\n",
      "Epoch: 0111 train_loss= 0.43428 time= 0.00200\n",
      "Epoch: 0112 train_loss= 0.44696 time= 0.00295\n",
      "Epoch: 0113 train_loss= 0.43933 time= 0.00202\n",
      "Epoch: 0114 train_loss= 0.44185 time= 0.00195\n",
      "Epoch: 0115 train_loss= 0.44120 time= 0.00207\n",
      "Epoch: 0116 train_loss= 0.43827 time= 0.00199\n",
      "Epoch: 0117 train_loss= 0.43379 time= 0.00202\n",
      "Epoch: 0118 train_loss= 0.44811 time= 0.00206\n",
      "Epoch: 0119 train_loss= 0.43784 time= 0.00298\n",
      "Epoch: 0120 train_loss= 0.43926 time= 0.00190\n",
      "Epoch: 0121 train_loss= 0.43831 time= 0.00203\n",
      "Epoch: 0122 train_loss= 0.43861 time= 0.00198\n",
      "Epoch: 0123 train_loss= 0.44492 time= 0.00300\n",
      "Epoch: 0124 train_loss= 0.43373 time= 0.00199\n",
      "Epoch: 0125 train_loss= 0.43889 time= 0.00200\n",
      "Epoch: 0126 train_loss= 0.44390 time= 0.00305\n",
      "Epoch: 0127 train_loss= 0.43637 time= 0.00195\n",
      "Epoch: 0128 train_loss= 0.43830 time= 0.00306\n",
      "Epoch: 0129 train_loss= 0.43299 time= 0.00201\n",
      "Epoch: 0130 train_loss= 0.43346 time= 0.00194\n",
      "Epoch: 0131 train_loss= 0.43648 time= 0.00208\n",
      "Epoch: 0132 train_loss= 0.43293 time= 0.00301\n",
      "Epoch: 0133 train_loss= 0.43282 time= 0.00199\n",
      "Epoch: 0134 train_loss= 0.43215 time= 0.00194\n",
      "Epoch: 0135 train_loss= 0.43472 time= 0.00305\n",
      "Epoch: 0136 train_loss= 0.43688 time= 0.00300\n",
      "Epoch: 0137 train_loss= 0.43426 time= 0.00302\n",
      "Epoch: 0138 train_loss= 0.43582 time= 0.00303\n",
      "Epoch: 0139 train_loss= 0.43569 time= 0.00306\n",
      "Epoch: 0140 train_loss= 0.44369 time= 0.00291\n",
      "Epoch: 0141 train_loss= 0.43586 time= 0.00301\n",
      "Epoch: 0142 train_loss= 0.43402 time= 0.00297\n",
      "Epoch: 0143 train_loss= 0.43683 time= 0.00302\n",
      "Epoch: 0144 train_loss= 0.43116 time= 0.00300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0145 train_loss= 0.43943 time= 0.00304\n",
      "Epoch: 0146 train_loss= 0.43302 time= 0.00295\n",
      "Epoch: 0147 train_loss= 0.43467 time= 0.00296\n",
      "Epoch: 0148 train_loss= 0.43153 time= 0.00404\n",
      "Epoch: 0149 train_loss= 0.43737 time= 0.00299\n",
      "Epoch: 0150 train_loss= 0.43457 time= 0.00212\n",
      "Epoch: 0151 train_loss= 0.42893 time= 0.00194\n",
      "Epoch: 0152 train_loss= 0.42671 time= 0.00294\n",
      "Epoch: 0153 train_loss= 0.43458 time= 0.00304\n",
      "Epoch: 0154 train_loss= 0.43412 time= 0.00296\n",
      "Epoch: 0155 train_loss= 0.43495 time= 0.00399\n",
      "Epoch: 0156 train_loss= 0.43136 time= 0.00301\n",
      "Epoch: 0157 train_loss= 0.43170 time= 0.00301\n",
      "Epoch: 0158 train_loss= 0.43522 time= 0.00308\n",
      "Epoch: 0159 train_loss= 0.43310 time= 0.00287\n",
      "Epoch: 0160 train_loss= 0.43255 time= 0.00402\n",
      "Epoch: 0161 train_loss= 0.43480 time= 0.00301\n",
      "Epoch: 0162 train_loss= 0.43119 time= 0.00294\n",
      "Epoch: 0163 train_loss= 0.42736 time= 0.00406\n",
      "Epoch: 0164 train_loss= 0.42974 time= 0.00303\n",
      "Epoch: 0165 train_loss= 0.43145 time= 0.00290\n",
      "Epoch: 0166 train_loss= 0.42617 time= 0.00404\n",
      "Epoch: 0167 train_loss= 0.43186 time= 0.00296\n",
      "Epoch: 0168 train_loss= 0.43752 time= 0.00201\n",
      "Epoch: 0169 train_loss= 0.42957 time= 0.00302\n",
      "Epoch: 0170 train_loss= 0.43159 time= 0.00194\n",
      "Epoch: 0171 train_loss= 0.43002 time= 0.00304\n",
      "Epoch: 0172 train_loss= 0.42777 time= 0.00304\n",
      "Epoch: 0173 train_loss= 0.42905 time= 0.00295\n",
      "Epoch: 0174 train_loss= 0.42826 time= 0.00202\n",
      "Epoch: 0175 train_loss= 0.42915 time= 0.00203\n",
      "Epoch: 0176 train_loss= 0.42534 time= 0.00194\n",
      "Epoch: 0177 train_loss= 0.42265 time= 0.00300\n",
      "Epoch: 0178 train_loss= 0.42766 time= 0.00200\n",
      "Epoch: 0179 train_loss= 0.43331 time= 0.00407\n",
      "Epoch: 0180 train_loss= 0.42835 time= 0.00199\n",
      "Epoch: 0181 train_loss= 0.42712 time= 0.00205\n",
      "Epoch: 0182 train_loss= 0.43531 time= 0.00298\n",
      "Epoch: 0183 train_loss= 0.42233 time= 0.00299\n",
      "Epoch: 0184 train_loss= 0.43049 time= 0.00201\n",
      "Epoch: 0185 train_loss= 0.43281 time= 0.00194\n",
      "Epoch: 0186 train_loss= 0.42359 time= 0.00206\n",
      "Epoch: 0187 train_loss= 0.43111 time= 0.00199\n",
      "Epoch: 0188 train_loss= 0.42564 time= 0.00310\n",
      "Epoch: 0189 train_loss= 0.42578 time= 0.00295\n",
      "Epoch: 0190 train_loss= 0.42985 time= 0.00303\n",
      "Epoch: 0191 train_loss= 0.43019 time= 0.00298\n",
      "Epoch: 0192 train_loss= 0.43030 time= 0.00195\n",
      "Epoch: 0193 train_loss= 0.43132 time= 0.00201\n",
      "Epoch: 0194 train_loss= 0.42977 time= 0.00295\n",
      "Epoch: 0195 train_loss= 0.43230 time= 0.00200\n",
      "Epoch: 0196 train_loss= 0.42559 time= 0.00300\n",
      "Epoch: 0197 train_loss= 0.42821 time= 0.00312\n",
      "Epoch: 0198 train_loss= 0.42553 time= 0.00291\n",
      "Epoch: 0199 train_loss= 0.43100 time= 0.00201\n",
      "Epoch: 0200 train_loss= 0.43242 time= 0.00295\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.53494 time= 0.14302\n",
      "Epoch: 0002 train_loss= 1.24323 time= 0.00305\n",
      "Epoch: 0003 train_loss= 0.85782 time= 0.00495\n",
      "Epoch: 0004 train_loss= 0.83253 time= 0.00300\n",
      "Epoch: 0005 train_loss= 0.85187 time= 0.00300\n",
      "Epoch: 0006 train_loss= 0.74400 time= 0.00300\n",
      "Epoch: 0007 train_loss= 0.64922 time= 0.00299\n",
      "Epoch: 0008 train_loss= 0.61449 time= 0.00298\n",
      "Epoch: 0009 train_loss= 0.65448 time= 0.00298\n",
      "Epoch: 0010 train_loss= 0.65128 time= 0.00199\n",
      "Epoch: 0011 train_loss= 0.64426 time= 0.00208\n",
      "Epoch: 0012 train_loss= 0.62067 time= 0.00293\n",
      "Epoch: 0013 train_loss= 0.58809 time= 0.00400\n",
      "Epoch: 0014 train_loss= 0.57821 time= 0.00301\n",
      "Epoch: 0015 train_loss= 0.56746 time= 0.00199\n",
      "Epoch: 0016 train_loss= 0.57351 time= 0.00200\n",
      "Epoch: 0017 train_loss= 0.57712 time= 0.00207\n",
      "Epoch: 0018 train_loss= 0.56117 time= 0.00300\n",
      "Epoch: 0019 train_loss= 0.54912 time= 0.00200\n",
      "Epoch: 0020 train_loss= 0.53859 time= 0.00200\n",
      "Epoch: 0021 train_loss= 0.53269 time= 0.00208\n",
      "Epoch: 0022 train_loss= 0.52261 time= 0.00205\n",
      "Epoch: 0023 train_loss= 0.52249 time= 0.00203\n",
      "Epoch: 0024 train_loss= 0.51925 time= 0.00295\n",
      "Epoch: 0025 train_loss= 0.50899 time= 0.00306\n",
      "Epoch: 0026 train_loss= 0.50670 time= 0.00197\n",
      "Epoch: 0027 train_loss= 0.50805 time= 0.00206\n",
      "Epoch: 0028 train_loss= 0.49425 time= 0.00203\n",
      "Epoch: 0029 train_loss= 0.49928 time= 0.00202\n",
      "Epoch: 0030 train_loss= 0.48949 time= 0.00298\n",
      "Epoch: 0031 train_loss= 0.49543 time= 0.00305\n",
      "Epoch: 0032 train_loss= 0.49355 time= 0.00299\n",
      "Epoch: 0033 train_loss= 0.48488 time= 0.00302\n",
      "Epoch: 0034 train_loss= 0.48176 time= 0.00194\n",
      "Epoch: 0035 train_loss= 0.47622 time= 0.00299\n",
      "Epoch: 0036 train_loss= 0.47438 time= 0.00200\n",
      "Epoch: 0037 train_loss= 0.47108 time= 0.00300\n",
      "Epoch: 0038 train_loss= 0.48221 time= 0.00405\n",
      "Epoch: 0039 train_loss= 0.47866 time= 0.00192\n",
      "Epoch: 0040 train_loss= 0.46567 time= 0.00509\n",
      "Epoch: 0041 train_loss= 0.47365 time= 0.00291\n",
      "Epoch: 0042 train_loss= 0.47661 time= 0.00201\n",
      "Epoch: 0043 train_loss= 0.46392 time= 0.00206\n",
      "Epoch: 0044 train_loss= 0.46333 time= 0.00304\n",
      "Epoch: 0045 train_loss= 0.46445 time= 0.00290\n",
      "Epoch: 0046 train_loss= 0.47530 time= 0.00199\n",
      "Epoch: 0047 train_loss= 0.47817 time= 0.00199\n",
      "Epoch: 0048 train_loss= 0.46152 time= 0.00310\n",
      "Epoch: 0049 train_loss= 0.45719 time= 0.00296\n",
      "Epoch: 0050 train_loss= 0.47272 time= 0.00201\n",
      "Epoch: 0051 train_loss= 0.46519 time= 0.00205\n",
      "Epoch: 0052 train_loss= 0.46440 time= 0.00295\n",
      "Epoch: 0053 train_loss= 0.45479 time= 0.00304\n",
      "Epoch: 0054 train_loss= 0.46168 time= 0.00204\n",
      "Epoch: 0055 train_loss= 0.45830 time= 0.00302\n",
      "Epoch: 0056 train_loss= 0.46214 time= 0.00293\n",
      "Epoch: 0057 train_loss= 0.45579 time= 0.00198\n",
      "Epoch: 0058 train_loss= 0.45781 time= 0.00198\n",
      "Epoch: 0059 train_loss= 0.45634 time= 0.00306\n",
      "Epoch: 0060 train_loss= 0.45368 time= 0.00400\n",
      "Epoch: 0061 train_loss= 0.46096 time= 0.00295\n",
      "Epoch: 0062 train_loss= 0.45341 time= 0.00302\n",
      "Epoch: 0063 train_loss= 0.46112 time= 0.00304\n",
      "Epoch: 0064 train_loss= 0.45188 time= 0.00295\n",
      "Epoch: 0065 train_loss= 0.46465 time= 0.00307\n",
      "Epoch: 0066 train_loss= 0.45955 time= 0.00291\n",
      "Epoch: 0067 train_loss= 0.44735 time= 0.00310\n",
      "Epoch: 0068 train_loss= 0.45733 time= 0.00204\n",
      "Epoch: 0069 train_loss= 0.44964 time= 0.00299\n",
      "Epoch: 0070 train_loss= 0.44930 time= 0.00304\n",
      "Epoch: 0071 train_loss= 0.44767 time= 0.00296\n",
      "Epoch: 0072 train_loss= 0.44831 time= 0.00197\n",
      "Epoch: 0073 train_loss= 0.45392 time= 0.00206\n",
      "Epoch: 0074 train_loss= 0.44934 time= 0.00203\n",
      "Epoch: 0075 train_loss= 0.44786 time= 0.00193\n",
      "Epoch: 0076 train_loss= 0.44923 time= 0.00207\n",
      "Epoch: 0077 train_loss= 0.44875 time= 0.00201\n",
      "Epoch: 0078 train_loss= 0.44903 time= 0.00299\n",
      "Epoch: 0079 train_loss= 0.45612 time= 0.00308\n",
      "Epoch: 0080 train_loss= 0.45143 time= 0.00199\n",
      "Epoch: 0081 train_loss= 0.44385 time= 0.00201\n",
      "Epoch: 0082 train_loss= 0.44559 time= 0.00309\n",
      "Epoch: 0083 train_loss= 0.45072 time= 0.00191\n",
      "Epoch: 0084 train_loss= 0.44796 time= 0.00201\n",
      "Epoch: 0085 train_loss= 0.44875 time= 0.00196\n",
      "Epoch: 0086 train_loss= 0.44680 time= 0.00206\n",
      "Epoch: 0087 train_loss= 0.44818 time= 0.00297\n",
      "Epoch: 0088 train_loss= 0.45074 time= 0.00196\n",
      "Epoch: 0089 train_loss= 0.44178 time= 0.00200\n",
      "Epoch: 0090 train_loss= 0.44532 time= 0.00303\n",
      "Epoch: 0091 train_loss= 0.44234 time= 0.00205\n",
      "Epoch: 0092 train_loss= 0.44127 time= 0.00292\n",
      "Epoch: 0093 train_loss= 0.44499 time= 0.00299\n",
      "Epoch: 0094 train_loss= 0.44582 time= 0.00200\n",
      "Epoch: 0095 train_loss= 0.44733 time= 0.00196\n",
      "Epoch: 0096 train_loss= 0.44522 time= 0.00300\n",
      "Epoch: 0097 train_loss= 0.44186 time= 0.00408\n",
      "Epoch: 0098 train_loss= 0.44494 time= 0.00392\n",
      "Epoch: 0099 train_loss= 0.43784 time= 0.00300\n",
      "Epoch: 0100 train_loss= 0.44838 time= 0.00200\n",
      "Epoch: 0101 train_loss= 0.44181 time= 0.00304\n",
      "Epoch: 0102 train_loss= 0.44449 time= 0.00301\n",
      "Epoch: 0103 train_loss= 0.44130 time= 0.00295\n",
      "Epoch: 0104 train_loss= 0.43829 time= 0.00306\n",
      "Epoch: 0105 train_loss= 0.43631 time= 0.00296\n",
      "Epoch: 0106 train_loss= 0.44572 time= 0.00295\n",
      "Epoch: 0107 train_loss= 0.43731 time= 0.00300\n",
      "Epoch: 0108 train_loss= 0.44310 time= 0.00245\n",
      "Epoch: 0109 train_loss= 0.43812 time= 0.00251\n",
      "Epoch: 0110 train_loss= 0.44442 time= 0.00204\n",
      "Epoch: 0111 train_loss= 0.45138 time= 0.00293\n",
      "Epoch: 0112 train_loss= 0.43984 time= 0.00301\n",
      "Epoch: 0113 train_loss= 0.43762 time= 0.00298\n",
      "Epoch: 0114 train_loss= 0.44178 time= 0.00315\n",
      "Epoch: 0115 train_loss= 0.43870 time= 0.00200\n",
      "Epoch: 0116 train_loss= 0.43915 time= 0.00231\n",
      "Epoch: 0117 train_loss= 0.43994 time= 0.00397\n",
      "Epoch: 0118 train_loss= 0.43652 time= 0.00399\n",
      "Epoch: 0119 train_loss= 0.43974 time= 0.00198\n",
      "Epoch: 0120 train_loss= 0.44366 time= 0.00305\n",
      "Epoch: 0121 train_loss= 0.44252 time= 0.00294\n",
      "Epoch: 0122 train_loss= 0.43739 time= 0.00300\n",
      "Epoch: 0123 train_loss= 0.43828 time= 0.00405\n",
      "Epoch: 0124 train_loss= 0.44257 time= 0.00295\n",
      "Epoch: 0125 train_loss= 0.44470 time= 0.00199\n",
      "Epoch: 0126 train_loss= 0.43534 time= 0.00295\n",
      "Epoch: 0127 train_loss= 0.44206 time= 0.00303\n",
      "Epoch: 0128 train_loss= 0.43703 time= 0.00392\n",
      "Epoch: 0129 train_loss= 0.43863 time= 0.00199\n",
      "Epoch: 0130 train_loss= 0.43699 time= 0.00305\n",
      "Epoch: 0131 train_loss= 0.45007 time= 0.00223\n",
      "Epoch: 0132 train_loss= 0.44051 time= 0.00202\n",
      "Epoch: 0133 train_loss= 0.43400 time= 0.00197\n",
      "Epoch: 0134 train_loss= 0.43682 time= 0.00506\n",
      "Epoch: 0135 train_loss= 0.43788 time= 0.00300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0136 train_loss= 0.43271 time= 0.00301\n",
      "Epoch: 0137 train_loss= 0.43120 time= 0.00303\n",
      "Epoch: 0138 train_loss= 0.43703 time= 0.00330\n",
      "Epoch: 0139 train_loss= 0.44061 time= 0.00264\n",
      "Epoch: 0140 train_loss= 0.43437 time= 0.00299\n",
      "Epoch: 0141 train_loss= 0.43296 time= 0.00308\n",
      "Epoch: 0142 train_loss= 0.43574 time= 0.00196\n",
      "Epoch: 0143 train_loss= 0.42958 time= 0.00267\n",
      "Epoch: 0144 train_loss= 0.43344 time= 0.00201\n",
      "Epoch: 0145 train_loss= 0.42841 time= 0.00189\n",
      "Epoch: 0146 train_loss= 0.42896 time= 0.00301\n",
      "Epoch: 0147 train_loss= 0.43623 time= 0.00204\n",
      "Epoch: 0148 train_loss= 0.43446 time= 0.00300\n",
      "Epoch: 0149 train_loss= 0.43516 time= 0.00313\n",
      "Epoch: 0150 train_loss= 0.43538 time= 0.00297\n",
      "Epoch: 0151 train_loss= 0.43180 time= 0.00299\n",
      "Epoch: 0152 train_loss= 0.43511 time= 0.00196\n",
      "Epoch: 0153 train_loss= 0.43767 time= 0.00412\n",
      "Epoch: 0154 train_loss= 0.43518 time= 0.00293\n",
      "Epoch: 0155 train_loss= 0.43189 time= 0.00311\n",
      "Epoch: 0156 train_loss= 0.43458 time= 0.00288\n",
      "Epoch: 0157 train_loss= 0.43907 time= 0.00197\n",
      "Epoch: 0158 train_loss= 0.43441 time= 0.00326\n",
      "Epoch: 0159 train_loss= 0.43124 time= 0.00344\n",
      "Epoch: 0160 train_loss= 0.43816 time= 0.00300\n",
      "Epoch: 0161 train_loss= 0.43213 time= 0.00200\n",
      "Epoch: 0162 train_loss= 0.42890 time= 0.00306\n",
      "Epoch: 0163 train_loss= 0.44129 time= 0.00391\n",
      "Epoch: 0164 train_loss= 0.43008 time= 0.00306\n",
      "Epoch: 0165 train_loss= 0.43587 time= 0.00400\n",
      "Epoch: 0166 train_loss= 0.43004 time= 0.00334\n",
      "Epoch: 0167 train_loss= 0.43095 time= 0.00295\n",
      "Epoch: 0168 train_loss= 0.43663 time= 0.00305\n",
      "Epoch: 0169 train_loss= 0.43284 time= 0.00300\n",
      "Epoch: 0170 train_loss= 0.42785 time= 0.00206\n",
      "Epoch: 0171 train_loss= 0.43883 time= 0.00313\n",
      "Epoch: 0172 train_loss= 0.43262 time= 0.00197\n",
      "Epoch: 0173 train_loss= 0.43171 time= 0.00405\n",
      "Epoch: 0174 train_loss= 0.43550 time= 0.00295\n",
      "Epoch: 0175 train_loss= 0.43279 time= 0.00200\n",
      "Epoch: 0176 train_loss= 0.43733 time= 0.00305\n",
      "Epoch: 0177 train_loss= 0.42891 time= 0.00404\n",
      "Epoch: 0178 train_loss= 0.42830 time= 0.00192\n",
      "Epoch: 0179 train_loss= 0.43707 time= 0.00195\n",
      "Epoch: 0180 train_loss= 0.43139 time= 0.00300\n",
      "Epoch: 0181 train_loss= 0.43895 time= 0.00300\n",
      "Epoch: 0182 train_loss= 0.43523 time= 0.00307\n",
      "Epoch: 0183 train_loss= 0.43369 time= 0.00194\n",
      "Epoch: 0184 train_loss= 0.43571 time= 0.00300\n",
      "Epoch: 0185 train_loss= 0.44699 time= 0.00306\n",
      "Epoch: 0186 train_loss= 0.42828 time= 0.00300\n",
      "Epoch: 0187 train_loss= 0.43540 time= 0.00194\n",
      "Epoch: 0188 train_loss= 0.43087 time= 0.00201\n",
      "Epoch: 0189 train_loss= 0.43226 time= 0.00198\n",
      "Epoch: 0190 train_loss= 0.44381 time= 0.00300\n",
      "Epoch: 0191 train_loss= 0.42986 time= 0.00205\n",
      "Epoch: 0192 train_loss= 0.42625 time= 0.00302\n",
      "Epoch: 0193 train_loss= 0.42273 time= 0.00303\n",
      "Epoch: 0194 train_loss= 0.43355 time= 0.00195\n",
      "Epoch: 0195 train_loss= 0.42572 time= 0.00200\n",
      "Epoch: 0196 train_loss= 0.43028 time= 0.00202\n",
      "Epoch: 0197 train_loss= 0.42815 time= 0.00195\n",
      "Epoch: 0198 train_loss= 0.43676 time= 0.00300\n",
      "Epoch: 0199 train_loss= 0.43309 time= 0.00300\n",
      "Epoch: 0200 train_loss= 0.43144 time= 0.00308\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.56542 time= 0.15894\n",
      "Epoch: 0002 train_loss= 1.35374 time= 0.00300\n",
      "Epoch: 0003 train_loss= 1.04073 time= 0.00300\n",
      "Epoch: 0004 train_loss= 0.81326 time= 0.00301\n",
      "Epoch: 0005 train_loss= 0.83745 time= 0.00400\n",
      "Epoch: 0006 train_loss= 0.77926 time= 0.00399\n",
      "Epoch: 0007 train_loss= 0.66224 time= 0.00301\n",
      "Epoch: 0008 train_loss= 0.61810 time= 0.00300\n",
      "Epoch: 0009 train_loss= 0.62350 time= 0.00400\n",
      "Epoch: 0010 train_loss= 0.64783 time= 0.00399\n",
      "Epoch: 0011 train_loss= 0.62383 time= 0.00300\n",
      "Epoch: 0012 train_loss= 0.61569 time= 0.00299\n",
      "Epoch: 0013 train_loss= 0.59246 time= 0.00401\n",
      "Epoch: 0014 train_loss= 0.56800 time= 0.00442\n",
      "Epoch: 0015 train_loss= 0.55629 time= 0.00196\n",
      "Epoch: 0016 train_loss= 0.55604 time= 0.00305\n",
      "Epoch: 0017 train_loss= 0.56071 time= 0.00201\n",
      "Epoch: 0018 train_loss= 0.56121 time= 0.00401\n",
      "Epoch: 0019 train_loss= 0.54813 time= 0.00312\n",
      "Epoch: 0020 train_loss= 0.54080 time= 0.00197\n",
      "Epoch: 0021 train_loss= 0.53725 time= 0.00304\n",
      "Epoch: 0022 train_loss= 0.53464 time= 0.00297\n",
      "Epoch: 0023 train_loss= 0.53638 time= 0.00307\n",
      "Epoch: 0024 train_loss= 0.51137 time= 0.00293\n",
      "Epoch: 0025 train_loss= 0.51343 time= 0.00305\n",
      "Epoch: 0026 train_loss= 0.50695 time= 0.00302\n",
      "Epoch: 0027 train_loss= 0.50145 time= 0.00311\n",
      "Epoch: 0028 train_loss= 0.49696 time= 0.00287\n",
      "Epoch: 0029 train_loss= 0.50055 time= 0.00396\n",
      "Epoch: 0030 train_loss= 0.49030 time= 0.00296\n",
      "Epoch: 0031 train_loss= 0.49513 time= 0.00203\n",
      "Epoch: 0032 train_loss= 0.49914 time= 0.00302\n",
      "Epoch: 0033 train_loss= 0.48687 time= 0.00299\n",
      "Epoch: 0034 train_loss= 0.48863 time= 0.00198\n",
      "Epoch: 0035 train_loss= 0.48236 time= 0.00193\n",
      "Epoch: 0036 train_loss= 0.48296 time= 0.00300\n",
      "Epoch: 0037 train_loss= 0.47418 time= 0.00307\n",
      "Epoch: 0038 train_loss= 0.47863 time= 0.00295\n",
      "Epoch: 0039 train_loss= 0.46897 time= 0.00407\n",
      "Epoch: 0040 train_loss= 0.47175 time= 0.00292\n",
      "Epoch: 0041 train_loss= 0.47527 time= 0.00305\n",
      "Epoch: 0042 train_loss= 0.47296 time= 0.00298\n",
      "Epoch: 0043 train_loss= 0.46711 time= 0.00301\n",
      "Epoch: 0044 train_loss= 0.47120 time= 0.00407\n",
      "Epoch: 0045 train_loss= 0.46384 time= 0.00303\n",
      "Epoch: 0046 train_loss= 0.47549 time= 0.00292\n",
      "Epoch: 0047 train_loss= 0.45819 time= 0.00296\n",
      "Epoch: 0048 train_loss= 0.46380 time= 0.00401\n",
      "Epoch: 0049 train_loss= 0.46081 time= 0.00308\n",
      "Epoch: 0050 train_loss= 0.46155 time= 0.00290\n",
      "Epoch: 0051 train_loss= 0.45707 time= 0.00206\n",
      "Epoch: 0052 train_loss= 0.46046 time= 0.00300\n",
      "Epoch: 0053 train_loss= 0.46037 time= 0.00190\n",
      "Epoch: 0054 train_loss= 0.45837 time= 0.00300\n",
      "Epoch: 0055 train_loss= 0.45334 time= 0.00195\n",
      "Epoch: 0056 train_loss= 0.45123 time= 0.00201\n",
      "Epoch: 0057 train_loss= 0.44608 time= 0.00200\n",
      "Epoch: 0058 train_loss= 0.45622 time= 0.00306\n",
      "Epoch: 0059 train_loss= 0.45043 time= 0.00295\n",
      "Epoch: 0060 train_loss= 0.45174 time= 0.00299\n",
      "Epoch: 0061 train_loss= 0.44524 time= 0.00199\n",
      "Epoch: 0062 train_loss= 0.45095 time= 0.00311\n",
      "Epoch: 0063 train_loss= 0.45257 time= 0.00299\n",
      "Epoch: 0064 train_loss= 0.46178 time= 0.00196\n",
      "Epoch: 0065 train_loss= 0.45384 time= 0.00207\n",
      "Epoch: 0066 train_loss= 0.45172 time= 0.00201\n",
      "Epoch: 0067 train_loss= 0.44761 time= 0.00194\n",
      "Epoch: 0068 train_loss= 0.44777 time= 0.00208\n",
      "Epoch: 0069 train_loss= 0.45080 time= 0.00293\n",
      "Epoch: 0070 train_loss= 0.44703 time= 0.00196\n",
      "Epoch: 0071 train_loss= 0.44916 time= 0.00200\n",
      "Epoch: 0072 train_loss= 0.44304 time= 0.00298\n",
      "Epoch: 0073 train_loss= 0.44553 time= 0.00193\n",
      "Epoch: 0074 train_loss= 0.44707 time= 0.00307\n",
      "Epoch: 0075 train_loss= 0.44601 time= 0.00198\n",
      "Epoch: 0076 train_loss= 0.45096 time= 0.00204\n",
      "Epoch: 0077 train_loss= 0.43920 time= 0.00196\n",
      "Epoch: 0078 train_loss= 0.44199 time= 0.00201\n",
      "Epoch: 0079 train_loss= 0.44351 time= 0.00195\n",
      "Epoch: 0080 train_loss= 0.44316 time= 0.00205\n",
      "Epoch: 0081 train_loss= 0.44545 time= 0.00294\n",
      "Epoch: 0082 train_loss= 0.45043 time= 0.00206\n",
      "Epoch: 0083 train_loss= 0.44348 time= 0.00195\n",
      "Epoch: 0084 train_loss= 0.44974 time= 0.00188\n",
      "Epoch: 0085 train_loss= 0.45368 time= 0.00193\n",
      "Epoch: 0086 train_loss= 0.44609 time= 0.00312\n",
      "Epoch: 0087 train_loss= 0.44692 time= 0.00197\n",
      "Epoch: 0088 train_loss= 0.44747 time= 0.00206\n",
      "Epoch: 0089 train_loss= 0.44381 time= 0.00191\n",
      "Epoch: 0090 train_loss= 0.44377 time= 0.00197\n",
      "Epoch: 0091 train_loss= 0.44950 time= 0.00304\n",
      "Epoch: 0092 train_loss= 0.43896 time= 0.00204\n",
      "Epoch: 0093 train_loss= 0.43538 time= 0.00303\n",
      "Epoch: 0094 train_loss= 0.43798 time= 0.00186\n",
      "Epoch: 0095 train_loss= 0.44365 time= 0.00200\n",
      "Epoch: 0096 train_loss= 0.44070 time= 0.00300\n",
      "Epoch: 0097 train_loss= 0.43704 time= 0.00206\n",
      "Epoch: 0098 train_loss= 0.44472 time= 0.00198\n",
      "Epoch: 0099 train_loss= 0.43753 time= 0.00198\n",
      "Epoch: 0100 train_loss= 0.43588 time= 0.00199\n",
      "Epoch: 0101 train_loss= 0.44378 time= 0.00304\n",
      "Epoch: 0102 train_loss= 0.43849 time= 0.00296\n",
      "Epoch: 0103 train_loss= 0.43876 time= 0.00309\n",
      "Epoch: 0104 train_loss= 0.44251 time= 0.00291\n",
      "Epoch: 0105 train_loss= 0.44176 time= 0.00201\n",
      "Epoch: 0106 train_loss= 0.44219 time= 0.00203\n",
      "Epoch: 0107 train_loss= 0.43388 time= 0.00303\n",
      "Epoch: 0108 train_loss= 0.43550 time= 0.00299\n",
      "Epoch: 0109 train_loss= 0.43692 time= 0.00296\n",
      "Epoch: 0110 train_loss= 0.43665 time= 0.00203\n",
      "Epoch: 0111 train_loss= 0.43527 time= 0.00319\n",
      "Epoch: 0112 train_loss= 0.42998 time= 0.00286\n",
      "Epoch: 0113 train_loss= 0.43132 time= 0.00304\n",
      "Epoch: 0114 train_loss= 0.43908 time= 0.00395\n",
      "Epoch: 0115 train_loss= 0.42970 time= 0.00400\n",
      "Epoch: 0116 train_loss= 0.45118 time= 0.00315\n",
      "Epoch: 0117 train_loss= 0.44091 time= 0.00186\n",
      "Epoch: 0118 train_loss= 0.44170 time= 0.00207\n",
      "Epoch: 0119 train_loss= 0.43485 time= 0.00294\n",
      "Epoch: 0120 train_loss= 0.43046 time= 0.00299\n",
      "Epoch: 0121 train_loss= 0.43941 time= 0.00208\n",
      "Epoch: 0122 train_loss= 0.43736 time= 0.00300\n",
      "Epoch: 0123 train_loss= 0.42931 time= 0.00200\n",
      "Epoch: 0124 train_loss= 0.43487 time= 0.00296\n",
      "Epoch: 0125 train_loss= 0.43773 time= 0.00303\n",
      "Epoch: 0126 train_loss= 0.43496 time= 0.00304\n",
      "Epoch: 0127 train_loss= 0.44634 time= 0.00195\n",
      "Epoch: 0128 train_loss= 0.43416 time= 0.00304\n",
      "Epoch: 0129 train_loss= 0.43947 time= 0.00302\n",
      "Epoch: 0130 train_loss= 0.43117 time= 0.00293\n",
      "Epoch: 0131 train_loss= 0.43182 time= 0.00299\n",
      "Epoch: 0132 train_loss= 0.43357 time= 0.00310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0133 train_loss= 0.42968 time= 0.00287\n",
      "Epoch: 0134 train_loss= 0.43213 time= 0.00306\n",
      "Epoch: 0135 train_loss= 0.43342 time= 0.00196\n",
      "Epoch: 0136 train_loss= 0.43757 time= 0.00196\n",
      "Epoch: 0137 train_loss= 0.44160 time= 0.00308\n",
      "Epoch: 0138 train_loss= 0.43118 time= 0.00394\n",
      "Epoch: 0139 train_loss= 0.43072 time= 0.00204\n",
      "Epoch: 0140 train_loss= 0.43426 time= 0.00300\n",
      "Epoch: 0141 train_loss= 0.43207 time= 0.00406\n",
      "Epoch: 0142 train_loss= 0.43060 time= 0.00299\n",
      "Epoch: 0143 train_loss= 0.43204 time= 0.00301\n",
      "Epoch: 0144 train_loss= 0.42820 time= 0.00294\n",
      "Epoch: 0145 train_loss= 0.43118 time= 0.00315\n",
      "Epoch: 0146 train_loss= 0.42744 time= 0.00484\n",
      "Epoch: 0147 train_loss= 0.43178 time= 0.00305\n",
      "Epoch: 0148 train_loss= 0.42735 time= 0.00195\n",
      "Epoch: 0149 train_loss= 0.43244 time= 0.00203\n",
      "Epoch: 0150 train_loss= 0.43592 time= 0.00306\n",
      "Epoch: 0151 train_loss= 0.43280 time= 0.00196\n",
      "Epoch: 0152 train_loss= 0.42514 time= 0.00303\n",
      "Epoch: 0153 train_loss= 0.42940 time= 0.00299\n",
      "Epoch: 0154 train_loss= 0.42745 time= 0.00201\n",
      "Epoch: 0155 train_loss= 0.43290 time= 0.00310\n",
      "Epoch: 0156 train_loss= 0.42906 time= 0.00196\n",
      "Epoch: 0157 train_loss= 0.43573 time= 0.00199\n",
      "Epoch: 0158 train_loss= 0.42699 time= 0.00304\n",
      "Epoch: 0159 train_loss= 0.42975 time= 0.00291\n",
      "Epoch: 0160 train_loss= 0.42990 time= 0.00205\n",
      "Epoch: 0161 train_loss= 0.42356 time= 0.00305\n",
      "Epoch: 0162 train_loss= 0.42765 time= 0.00301\n",
      "Epoch: 0163 train_loss= 0.42261 time= 0.00298\n",
      "Epoch: 0164 train_loss= 0.42858 time= 0.00296\n",
      "Epoch: 0165 train_loss= 0.42449 time= 0.00200\n",
      "Epoch: 0166 train_loss= 0.43245 time= 0.00295\n",
      "Epoch: 0167 train_loss= 0.42718 time= 0.00300\n",
      "Epoch: 0168 train_loss= 0.42645 time= 0.00310\n",
      "Epoch: 0169 train_loss= 0.43087 time= 0.00290\n",
      "Epoch: 0170 train_loss= 0.42675 time= 0.00400\n",
      "Epoch: 0171 train_loss= 0.42971 time= 0.00305\n",
      "Epoch: 0172 train_loss= 0.42373 time= 0.00299\n",
      "Epoch: 0173 train_loss= 0.42757 time= 0.00195\n",
      "Epoch: 0174 train_loss= 0.43045 time= 0.00306\n",
      "Epoch: 0175 train_loss= 0.42270 time= 0.00300\n",
      "Epoch: 0176 train_loss= 0.42833 time= 0.00203\n",
      "Epoch: 0177 train_loss= 0.42346 time= 0.00398\n",
      "Epoch: 0178 train_loss= 0.42596 time= 0.00194\n",
      "Epoch: 0179 train_loss= 0.43356 time= 0.00302\n",
      "Epoch: 0180 train_loss= 0.42715 time= 0.00315\n",
      "Epoch: 0181 train_loss= 0.42436 time= 0.00284\n",
      "Epoch: 0182 train_loss= 0.42309 time= 0.00304\n",
      "Epoch: 0183 train_loss= 0.42839 time= 0.00196\n",
      "Epoch: 0184 train_loss= 0.43087 time= 0.00300\n",
      "Epoch: 0185 train_loss= 0.42372 time= 0.00298\n",
      "Epoch: 0186 train_loss= 0.42994 time= 0.00297\n",
      "Epoch: 0187 train_loss= 0.42834 time= 0.00411\n",
      "Epoch: 0188 train_loss= 0.42400 time= 0.00294\n",
      "Epoch: 0189 train_loss= 0.42241 time= 0.00299\n",
      "Epoch: 0190 train_loss= 0.43041 time= 0.00203\n",
      "Epoch: 0191 train_loss= 0.42375 time= 0.00302\n",
      "Epoch: 0192 train_loss= 0.42533 time= 0.00205\n",
      "Epoch: 0193 train_loss= 0.42303 time= 0.00197\n",
      "Epoch: 0194 train_loss= 0.42489 time= 0.00300\n",
      "Epoch: 0195 train_loss= 0.42238 time= 0.00201\n",
      "Epoch: 0196 train_loss= 0.41969 time= 0.00301\n",
      "Epoch: 0197 train_loss= 0.42699 time= 0.00191\n",
      "Epoch: 0198 train_loss= 0.42721 time= 0.00307\n",
      "Epoch: 0199 train_loss= 0.42427 time= 0.00300\n",
      "Epoch: 0200 train_loss= 0.42766 time= 0.00293\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.59883 time= 0.16200\n",
      "Epoch: 0002 train_loss= 1.37737 time= 0.00408\n",
      "Epoch: 0003 train_loss= 1.12550 time= 0.00296\n",
      "Epoch: 0004 train_loss= 0.80144 time= 0.00299\n",
      "Epoch: 0005 train_loss= 0.79668 time= 0.00310\n",
      "Epoch: 0006 train_loss= 0.85464 time= 0.00294\n",
      "Epoch: 0007 train_loss= 0.74892 time= 0.00294\n",
      "Epoch: 0008 train_loss= 0.67349 time= 0.00405\n",
      "Epoch: 0009 train_loss= 0.61690 time= 0.00295\n",
      "Epoch: 0010 train_loss= 0.63214 time= 0.00305\n",
      "Epoch: 0011 train_loss= 0.65732 time= 0.00297\n",
      "Epoch: 0012 train_loss= 0.65000 time= 0.00395\n",
      "Epoch: 0013 train_loss= 0.64014 time= 0.00302\n",
      "Epoch: 0014 train_loss= 0.62490 time= 0.00199\n",
      "Epoch: 0015 train_loss= 0.58382 time= 0.00302\n",
      "Epoch: 0016 train_loss= 0.56508 time= 0.00297\n",
      "Epoch: 0017 train_loss= 0.56105 time= 0.00306\n",
      "Epoch: 0018 train_loss= 0.55846 time= 0.00290\n",
      "Epoch: 0019 train_loss= 0.55589 time= 0.00306\n",
      "Epoch: 0020 train_loss= 0.55003 time= 0.00298\n",
      "Epoch: 0021 train_loss= 0.53427 time= 0.00197\n",
      "Epoch: 0022 train_loss= 0.53148 time= 0.00294\n",
      "Epoch: 0023 train_loss= 0.52282 time= 0.00295\n",
      "Epoch: 0024 train_loss= 0.51357 time= 0.00295\n",
      "Epoch: 0025 train_loss= 0.51740 time= 0.00302\n",
      "Epoch: 0026 train_loss= 0.51348 time= 0.00311\n",
      "Epoch: 0027 train_loss= 0.51115 time= 0.00289\n",
      "Epoch: 0028 train_loss= 0.50732 time= 0.00189\n",
      "Epoch: 0029 train_loss= 0.49450 time= 0.00200\n",
      "Epoch: 0030 train_loss= 0.49188 time= 0.00301\n",
      "Epoch: 0031 train_loss= 0.50033 time= 0.00193\n",
      "Epoch: 0032 train_loss= 0.48528 time= 0.00201\n",
      "Epoch: 0033 train_loss= 0.49301 time= 0.00299\n",
      "Epoch: 0034 train_loss= 0.49375 time= 0.00407\n",
      "Epoch: 0035 train_loss= 0.47734 time= 0.00298\n",
      "Epoch: 0036 train_loss= 0.48548 time= 0.00299\n",
      "Epoch: 0037 train_loss= 0.49095 time= 0.00299\n",
      "Epoch: 0038 train_loss= 0.48231 time= 0.00403\n",
      "Epoch: 0039 train_loss= 0.47712 time= 0.00305\n",
      "Epoch: 0040 train_loss= 0.47188 time= 0.00298\n",
      "Epoch: 0041 train_loss= 0.48007 time= 0.00407\n",
      "Epoch: 0042 train_loss= 0.47975 time= 0.00393\n",
      "Epoch: 0043 train_loss= 0.47219 time= 0.00300\n",
      "Epoch: 0044 train_loss= 0.47904 time= 0.00300\n",
      "Epoch: 0045 train_loss= 0.47103 time= 0.00304\n",
      "Epoch: 0046 train_loss= 0.46327 time= 0.00401\n",
      "Epoch: 0047 train_loss= 0.46477 time= 0.00296\n",
      "Epoch: 0048 train_loss= 0.46326 time= 0.00305\n",
      "Epoch: 0049 train_loss= 0.46486 time= 0.00197\n",
      "Epoch: 0050 train_loss= 0.46476 time= 0.00201\n",
      "Epoch: 0051 train_loss= 0.46107 time= 0.00405\n",
      "Epoch: 0052 train_loss= 0.46047 time= 0.00291\n",
      "Epoch: 0053 train_loss= 0.47154 time= 0.00301\n",
      "Epoch: 0054 train_loss= 0.46124 time= 0.00203\n",
      "Epoch: 0055 train_loss= 0.46648 time= 0.00203\n",
      "Epoch: 0056 train_loss= 0.45769 time= 0.00301\n",
      "Epoch: 0057 train_loss= 0.46079 time= 0.00195\n",
      "Epoch: 0058 train_loss= 0.46315 time= 0.00200\n",
      "Epoch: 0059 train_loss= 0.45008 time= 0.00300\n",
      "Epoch: 0060 train_loss= 0.45755 time= 0.00300\n",
      "Epoch: 0061 train_loss= 0.45123 time= 0.00200\n",
      "Epoch: 0062 train_loss= 0.45835 time= 0.00300\n",
      "Epoch: 0063 train_loss= 0.45472 time= 0.00199\n",
      "Epoch: 0064 train_loss= 0.44908 time= 0.00312\n",
      "Epoch: 0065 train_loss= 0.45251 time= 0.00297\n",
      "Epoch: 0066 train_loss= 0.45752 time= 0.00302\n",
      "Epoch: 0067 train_loss= 0.46149 time= 0.00294\n",
      "Epoch: 0068 train_loss= 0.45807 time= 0.00300\n",
      "Epoch: 0069 train_loss= 0.45270 time= 0.00303\n",
      "Epoch: 0070 train_loss= 0.45054 time= 0.00305\n",
      "Epoch: 0071 train_loss= 0.45921 time= 0.00289\n",
      "Epoch: 0072 train_loss= 0.45220 time= 0.00407\n",
      "Epoch: 0073 train_loss= 0.45686 time= 0.00297\n",
      "Epoch: 0074 train_loss= 0.44757 time= 0.00295\n",
      "Epoch: 0075 train_loss= 0.45293 time= 0.00306\n",
      "Epoch: 0076 train_loss= 0.44846 time= 0.00306\n",
      "Epoch: 0077 train_loss= 0.45149 time= 0.00197\n",
      "Epoch: 0078 train_loss= 0.44905 time= 0.00300\n",
      "Epoch: 0079 train_loss= 0.44683 time= 0.00297\n",
      "Epoch: 0080 train_loss= 0.45408 time= 0.00199\n",
      "Epoch: 0081 train_loss= 0.44493 time= 0.00304\n",
      "Epoch: 0082 train_loss= 0.44955 time= 0.00302\n",
      "Epoch: 0083 train_loss= 0.44779 time= 0.00304\n",
      "Epoch: 0084 train_loss= 0.45448 time= 0.00295\n",
      "Epoch: 0085 train_loss= 0.44118 time= 0.00408\n",
      "Epoch: 0086 train_loss= 0.45154 time= 0.00394\n",
      "Epoch: 0087 train_loss= 0.43896 time= 0.00200\n",
      "Epoch: 0088 train_loss= 0.45089 time= 0.00304\n",
      "Epoch: 0089 train_loss= 0.44601 time= 0.00296\n",
      "Epoch: 0090 train_loss= 0.44282 time= 0.00201\n",
      "Epoch: 0091 train_loss= 0.44568 time= 0.00412\n",
      "Epoch: 0092 train_loss= 0.44755 time= 0.00308\n",
      "Epoch: 0093 train_loss= 0.44461 time= 0.00389\n",
      "Epoch: 0094 train_loss= 0.44366 time= 0.00401\n",
      "Epoch: 0095 train_loss= 0.44148 time= 0.00399\n",
      "Epoch: 0096 train_loss= 0.44329 time= 0.00300\n",
      "Epoch: 0097 train_loss= 0.44630 time= 0.00200\n",
      "Epoch: 0098 train_loss= 0.44291 time= 0.00300\n",
      "Epoch: 0099 train_loss= 0.44836 time= 0.00193\n",
      "Epoch: 0100 train_loss= 0.43780 time= 0.00200\n",
      "Epoch: 0101 train_loss= 0.44115 time= 0.00200\n",
      "Epoch: 0102 train_loss= 0.44678 time= 0.00208\n",
      "Epoch: 0103 train_loss= 0.44098 time= 0.00301\n",
      "Epoch: 0104 train_loss= 0.43880 time= 0.00302\n",
      "Epoch: 0105 train_loss= 0.43824 time= 0.00194\n",
      "Epoch: 0106 train_loss= 0.43889 time= 0.00305\n",
      "Epoch: 0107 train_loss= 0.43565 time= 0.00195\n",
      "Epoch: 0108 train_loss= 0.44718 time= 0.00202\n",
      "Epoch: 0109 train_loss= 0.44430 time= 0.00294\n",
      "Epoch: 0110 train_loss= 0.44408 time= 0.00204\n",
      "Epoch: 0111 train_loss= 0.43579 time= 0.00292\n",
      "Epoch: 0112 train_loss= 0.44384 time= 0.00207\n",
      "Epoch: 0113 train_loss= 0.44066 time= 0.00204\n",
      "Epoch: 0114 train_loss= 0.44677 time= 0.00191\n",
      "Epoch: 0115 train_loss= 0.44091 time= 0.00200\n",
      "Epoch: 0116 train_loss= 0.44979 time= 0.00206\n",
      "Epoch: 0117 train_loss= 0.44081 time= 0.00196\n",
      "Epoch: 0118 train_loss= 0.43846 time= 0.00205\n",
      "Epoch: 0119 train_loss= 0.44308 time= 0.00307\n",
      "Epoch: 0120 train_loss= 0.43839 time= 0.00188\n",
      "Epoch: 0121 train_loss= 0.43618 time= 0.00300\n",
      "Epoch: 0122 train_loss= 0.43714 time= 0.00200\n",
      "Epoch: 0123 train_loss= 0.44632 time= 0.00200\n",
      "Epoch: 0124 train_loss= 0.43575 time= 0.00201\n",
      "Epoch: 0125 train_loss= 0.43348 time= 0.00295\n",
      "Epoch: 0126 train_loss= 0.43976 time= 0.00200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0127 train_loss= 0.43763 time= 0.00400\n",
      "Epoch: 0128 train_loss= 0.43623 time= 0.00300\n",
      "Epoch: 0129 train_loss= 0.43702 time= 0.00200\n",
      "Epoch: 0130 train_loss= 0.43899 time= 0.00200\n",
      "Epoch: 0131 train_loss= 0.44956 time= 0.00303\n",
      "Epoch: 0132 train_loss= 0.44024 time= 0.00303\n",
      "Epoch: 0133 train_loss= 0.43701 time= 0.00299\n",
      "Epoch: 0134 train_loss= 0.43582 time= 0.00300\n",
      "Epoch: 0135 train_loss= 0.43549 time= 0.00195\n",
      "Epoch: 0136 train_loss= 0.43934 time= 0.00197\n",
      "Epoch: 0137 train_loss= 0.43808 time= 0.00300\n",
      "Epoch: 0138 train_loss= 0.43505 time= 0.00306\n",
      "Epoch: 0139 train_loss= 0.43935 time= 0.00296\n",
      "Epoch: 0140 train_loss= 0.44173 time= 0.00301\n",
      "Epoch: 0141 train_loss= 0.43358 time= 0.00400\n",
      "Epoch: 0142 train_loss= 0.43652 time= 0.00201\n",
      "Epoch: 0143 train_loss= 0.44230 time= 0.00398\n",
      "Epoch: 0144 train_loss= 0.43528 time= 0.00304\n",
      "Epoch: 0145 train_loss= 0.44368 time= 0.00196\n",
      "Epoch: 0146 train_loss= 0.43814 time= 0.00306\n",
      "Epoch: 0147 train_loss= 0.43590 time= 0.00194\n",
      "Epoch: 0148 train_loss= 0.43721 time= 0.00405\n",
      "Epoch: 0149 train_loss= 0.43792 time= 0.00196\n",
      "Epoch: 0150 train_loss= 0.43499 time= 0.00312\n",
      "Epoch: 0151 train_loss= 0.43524 time= 0.00292\n",
      "Epoch: 0152 train_loss= 0.43147 time= 0.00303\n",
      "Epoch: 0153 train_loss= 0.43183 time= 0.00293\n",
      "Epoch: 0154 train_loss= 0.43518 time= 0.00409\n",
      "Epoch: 0155 train_loss= 0.43439 time= 0.00392\n",
      "Epoch: 0156 train_loss= 0.43513 time= 0.00399\n",
      "Epoch: 0157 train_loss= 0.43564 time= 0.00316\n",
      "Epoch: 0158 train_loss= 0.43110 time= 0.00293\n",
      "Epoch: 0159 train_loss= 0.43531 time= 0.00315\n",
      "Epoch: 0160 train_loss= 0.43521 time= 0.00197\n",
      "Epoch: 0161 train_loss= 0.43403 time= 0.00201\n",
      "Epoch: 0162 train_loss= 0.43171 time= 0.00401\n",
      "Epoch: 0163 train_loss= 0.43917 time= 0.00300\n",
      "Epoch: 0164 train_loss= 0.43529 time= 0.00299\n",
      "Epoch: 0165 train_loss= 0.43147 time= 0.00303\n",
      "Epoch: 0166 train_loss= 0.43400 time= 0.00297\n",
      "Epoch: 0167 train_loss= 0.42823 time= 0.00312\n",
      "Epoch: 0168 train_loss= 0.43733 time= 0.00397\n",
      "Epoch: 0169 train_loss= 0.44046 time= 0.00197\n",
      "Epoch: 0170 train_loss= 0.42977 time= 0.00315\n",
      "Epoch: 0171 train_loss= 0.42936 time= 0.00195\n",
      "Epoch: 0172 train_loss= 0.42968 time= 0.00407\n",
      "Epoch: 0173 train_loss= 0.44064 time= 0.00303\n",
      "Epoch: 0174 train_loss= 0.42869 time= 0.00292\n",
      "Epoch: 0175 train_loss= 0.42610 time= 0.00302\n",
      "Epoch: 0176 train_loss= 0.43168 time= 0.00298\n",
      "Epoch: 0177 train_loss= 0.42876 time= 0.00406\n",
      "Epoch: 0178 train_loss= 0.42856 time= 0.00294\n",
      "Epoch: 0179 train_loss= 0.43336 time= 0.00407\n",
      "Epoch: 0180 train_loss= 0.42816 time= 0.00296\n",
      "Epoch: 0181 train_loss= 0.42963 time= 0.00404\n",
      "Epoch: 0182 train_loss= 0.43824 time= 0.00301\n",
      "Epoch: 0183 train_loss= 0.43161 time= 0.00302\n",
      "Epoch: 0184 train_loss= 0.42743 time= 0.00199\n",
      "Epoch: 0185 train_loss= 0.42836 time= 0.00309\n",
      "Epoch: 0186 train_loss= 0.42748 time= 0.00196\n",
      "Epoch: 0187 train_loss= 0.42575 time= 0.00499\n",
      "Epoch: 0188 train_loss= 0.43276 time= 0.00297\n",
      "Epoch: 0189 train_loss= 0.43221 time= 0.00300\n",
      "Epoch: 0190 train_loss= 0.43133 time= 0.00294\n",
      "Epoch: 0191 train_loss= 0.42564 time= 0.00226\n",
      "Epoch: 0192 train_loss= 0.42679 time= 0.00386\n",
      "Epoch: 0193 train_loss= 0.42968 time= 0.00301\n",
      "Epoch: 0194 train_loss= 0.42853 time= 0.00302\n",
      "Epoch: 0195 train_loss= 0.43530 time= 0.00309\n",
      "Epoch: 0196 train_loss= 0.43078 time= 0.00197\n",
      "Epoch: 0197 train_loss= 0.42951 time= 0.00295\n",
      "Epoch: 0198 train_loss= 0.43324 time= 0.00197\n",
      "Epoch: 0199 train_loss= 0.43316 time= 0.00314\n",
      "Epoch: 0200 train_loss= 0.43132 time= 0.00300\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.58017 time= 0.16656\n",
      "Epoch: 0002 train_loss= 1.36555 time= 0.00401\n",
      "Epoch: 0003 train_loss= 1.00053 time= 0.00299\n",
      "Epoch: 0004 train_loss= 0.78913 time= 0.00401\n",
      "Epoch: 0005 train_loss= 0.82359 time= 0.00401\n",
      "Epoch: 0006 train_loss= 0.78445 time= 0.00310\n",
      "Epoch: 0007 train_loss= 0.66190 time= 0.00400\n",
      "Epoch: 0008 train_loss= 0.61708 time= 0.00200\n",
      "Epoch: 0009 train_loss= 0.63318 time= 0.00301\n",
      "Epoch: 0010 train_loss= 0.65015 time= 0.00300\n",
      "Epoch: 0011 train_loss= 0.64611 time= 0.00201\n",
      "Epoch: 0012 train_loss= 0.62711 time= 0.00300\n",
      "Epoch: 0013 train_loss= 0.60274 time= 0.00300\n",
      "Epoch: 0014 train_loss= 0.57277 time= 0.00300\n",
      "Epoch: 0015 train_loss= 0.55900 time= 0.00301\n",
      "Epoch: 0016 train_loss= 0.55677 time= 0.00201\n",
      "Epoch: 0017 train_loss= 0.54985 time= 0.00304\n",
      "Epoch: 0018 train_loss= 0.54656 time= 0.00299\n",
      "Epoch: 0019 train_loss= 0.54163 time= 0.00397\n",
      "Epoch: 0020 train_loss= 0.51932 time= 0.00306\n",
      "Epoch: 0021 train_loss= 0.51397 time= 0.00308\n",
      "Epoch: 0022 train_loss= 0.51627 time= 0.00297\n",
      "Epoch: 0023 train_loss= 0.51897 time= 0.00516\n",
      "Epoch: 0024 train_loss= 0.49491 time= 0.00198\n",
      "Epoch: 0025 train_loss= 0.50562 time= 0.00403\n",
      "Epoch: 0026 train_loss= 0.49767 time= 0.00299\n",
      "Epoch: 0027 train_loss= 0.49666 time= 0.00304\n",
      "Epoch: 0028 train_loss= 0.49074 time= 0.00302\n",
      "Epoch: 0029 train_loss= 0.48569 time= 0.00302\n",
      "Epoch: 0030 train_loss= 0.48000 time= 0.00297\n",
      "Epoch: 0031 train_loss= 0.47984 time= 0.00301\n",
      "Epoch: 0032 train_loss= 0.48394 time= 0.00500\n",
      "Epoch: 0033 train_loss= 0.47899 time= 0.00300\n",
      "Epoch: 0034 train_loss= 0.47921 time= 0.00194\n",
      "Epoch: 0035 train_loss= 0.46987 time= 0.00304\n",
      "Epoch: 0036 train_loss= 0.47852 time= 0.00401\n",
      "Epoch: 0037 train_loss= 0.47015 time= 0.00299\n",
      "Epoch: 0038 train_loss= 0.46930 time= 0.00297\n",
      "Epoch: 0039 train_loss= 0.46629 time= 0.00305\n",
      "Epoch: 0040 train_loss= 0.46415 time= 0.00197\n",
      "Epoch: 0041 train_loss= 0.46506 time= 0.00415\n",
      "Epoch: 0042 train_loss= 0.46809 time= 0.00195\n",
      "Epoch: 0043 train_loss= 0.46636 time= 0.00319\n",
      "Epoch: 0044 train_loss= 0.46177 time= 0.00196\n",
      "Epoch: 0045 train_loss= 0.45447 time= 0.00401\n",
      "Epoch: 0046 train_loss= 0.45653 time= 0.00299\n",
      "Epoch: 0047 train_loss= 0.45708 time= 0.00302\n",
      "Epoch: 0048 train_loss= 0.45753 time= 0.00295\n",
      "Epoch: 0049 train_loss= 0.45903 time= 0.00200\n",
      "Epoch: 0050 train_loss= 0.45444 time= 0.00305\n",
      "Epoch: 0051 train_loss= 0.48726 time= 0.00297\n",
      "Epoch: 0052 train_loss= 0.45444 time= 0.00410\n",
      "Epoch: 0053 train_loss= 0.45464 time= 0.00395\n",
      "Epoch: 0054 train_loss= 0.45668 time= 0.00296\n",
      "Epoch: 0055 train_loss= 0.45953 time= 0.00303\n",
      "Epoch: 0056 train_loss= 0.45724 time= 0.00301\n",
      "Epoch: 0057 train_loss= 0.45513 time= 0.00305\n",
      "Epoch: 0058 train_loss= 0.45593 time= 0.00300\n",
      "Epoch: 0059 train_loss= 0.45341 time= 0.00301\n",
      "Epoch: 0060 train_loss= 0.45774 time= 0.00296\n",
      "Epoch: 0061 train_loss= 0.46049 time= 0.00399\n",
      "Epoch: 0062 train_loss= 0.44956 time= 0.00308\n",
      "Epoch: 0063 train_loss= 0.45156 time= 0.00292\n",
      "Epoch: 0064 train_loss= 0.45079 time= 0.00409\n",
      "Epoch: 0065 train_loss= 0.45011 time= 0.00297\n",
      "Epoch: 0066 train_loss= 0.46038 time= 0.00299\n",
      "Epoch: 0067 train_loss= 0.45020 time= 0.00360\n",
      "Epoch: 0068 train_loss= 0.44887 time= 0.00205\n",
      "Epoch: 0069 train_loss= 0.44470 time= 0.00191\n",
      "Epoch: 0070 train_loss= 0.45167 time= 0.00200\n",
      "Epoch: 0071 train_loss= 0.45062 time= 0.00317\n",
      "Epoch: 0072 train_loss= 0.44466 time= 0.00197\n",
      "Epoch: 0073 train_loss= 0.44870 time= 0.00201\n",
      "Epoch: 0074 train_loss= 0.44691 time= 0.00300\n",
      "Epoch: 0075 train_loss= 0.44776 time= 0.00297\n",
      "Epoch: 0076 train_loss= 0.44605 time= 0.00307\n",
      "Epoch: 0077 train_loss= 0.44658 time= 0.00411\n",
      "Epoch: 0078 train_loss= 0.44367 time= 0.00403\n",
      "Epoch: 0079 train_loss= 0.44637 time= 0.00298\n",
      "Epoch: 0080 train_loss= 0.44524 time= 0.00396\n",
      "Epoch: 0081 train_loss= 0.44238 time= 0.00298\n",
      "Epoch: 0082 train_loss= 0.44351 time= 0.00307\n",
      "Epoch: 0083 train_loss= 0.44161 time= 0.00300\n",
      "Epoch: 0084 train_loss= 0.43739 time= 0.00301\n",
      "Epoch: 0085 train_loss= 0.44269 time= 0.00302\n",
      "Epoch: 0086 train_loss= 0.43998 time= 0.00396\n",
      "Epoch: 0087 train_loss= 0.44261 time= 0.00315\n",
      "Epoch: 0088 train_loss= 0.43650 time= 0.00301\n",
      "Epoch: 0089 train_loss= 0.44824 time= 0.00404\n",
      "Epoch: 0090 train_loss= 0.44135 time= 0.00412\n",
      "Epoch: 0091 train_loss= 0.44156 time= 0.00391\n",
      "Epoch: 0092 train_loss= 0.44057 time= 0.00306\n",
      "Epoch: 0093 train_loss= 0.44482 time= 0.00198\n",
      "Epoch: 0094 train_loss= 0.44563 time= 0.00313\n",
      "Epoch: 0095 train_loss= 0.44554 time= 0.00300\n",
      "Epoch: 0096 train_loss= 0.44612 time= 0.00197\n",
      "Epoch: 0097 train_loss= 0.43944 time= 0.00299\n",
      "Epoch: 0098 train_loss= 0.43754 time= 0.00404\n",
      "Epoch: 0099 train_loss= 0.44276 time= 0.00195\n",
      "Epoch: 0100 train_loss= 0.43820 time= 0.00307\n",
      "Epoch: 0101 train_loss= 0.43799 time= 0.00293\n",
      "Epoch: 0102 train_loss= 0.44421 time= 0.00303\n",
      "Epoch: 0103 train_loss= 0.43485 time= 0.00402\n",
      "Epoch: 0104 train_loss= 0.43434 time= 0.00303\n",
      "Epoch: 0105 train_loss= 0.44404 time= 0.00298\n",
      "Epoch: 0106 train_loss= 0.44336 time= 0.00294\n",
      "Epoch: 0107 train_loss= 0.43342 time= 0.00202\n",
      "Epoch: 0108 train_loss= 0.44695 time= 0.00300\n",
      "Epoch: 0109 train_loss= 0.44211 time= 0.00305\n",
      "Epoch: 0110 train_loss= 0.44292 time= 0.00305\n",
      "Epoch: 0111 train_loss= 0.44391 time= 0.00294\n",
      "Epoch: 0112 train_loss= 0.43853 time= 0.00299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0113 train_loss= 0.44051 time= 0.00401\n",
      "Epoch: 0114 train_loss= 0.43980 time= 0.00302\n",
      "Epoch: 0115 train_loss= 0.43729 time= 0.00200\n",
      "Epoch: 0116 train_loss= 0.43536 time= 0.00304\n",
      "Epoch: 0117 train_loss= 0.43466 time= 0.00303\n",
      "Epoch: 0118 train_loss= 0.42944 time= 0.00301\n",
      "Epoch: 0119 train_loss= 0.42954 time= 0.00193\n",
      "Epoch: 0120 train_loss= 0.43255 time= 0.00302\n",
      "Epoch: 0121 train_loss= 0.43991 time= 0.00306\n",
      "Epoch: 0122 train_loss= 0.43388 time= 0.00296\n",
      "Epoch: 0123 train_loss= 0.43407 time= 0.00196\n",
      "Epoch: 0124 train_loss= 0.43687 time= 0.00175\n",
      "Epoch: 0125 train_loss= 0.43131 time= 0.00196\n",
      "Epoch: 0126 train_loss= 0.43164 time= 0.00200\n",
      "Epoch: 0127 train_loss= 0.43589 time= 0.00207\n",
      "Epoch: 0128 train_loss= 0.43347 time= 0.00295\n",
      "Epoch: 0129 train_loss= 0.42735 time= 0.00302\n",
      "Epoch: 0130 train_loss= 0.43252 time= 0.00302\n",
      "Epoch: 0131 train_loss= 0.43744 time= 0.00304\n",
      "Epoch: 0132 train_loss= 0.44496 time= 0.00189\n",
      "Epoch: 0133 train_loss= 0.43430 time= 0.00201\n",
      "Epoch: 0134 train_loss= 0.43674 time= 0.00304\n",
      "Epoch: 0135 train_loss= 0.42825 time= 0.00299\n",
      "Epoch: 0136 train_loss= 0.43055 time= 0.00295\n",
      "Epoch: 0137 train_loss= 0.43029 time= 0.00206\n",
      "Epoch: 0138 train_loss= 0.43056 time= 0.00191\n",
      "Epoch: 0139 train_loss= 0.43056 time= 0.00197\n",
      "Epoch: 0140 train_loss= 0.42832 time= 0.00307\n",
      "Epoch: 0141 train_loss= 0.44099 time= 0.00293\n",
      "Epoch: 0142 train_loss= 0.43468 time= 0.00200\n",
      "Epoch: 0143 train_loss= 0.43493 time= 0.00200\n",
      "Epoch: 0144 train_loss= 0.42764 time= 0.00210\n",
      "Epoch: 0145 train_loss= 0.43314 time= 0.00194\n",
      "Epoch: 0146 train_loss= 0.43894 time= 0.00198\n",
      "Epoch: 0147 train_loss= 0.43410 time= 0.00207\n",
      "Epoch: 0148 train_loss= 0.42803 time= 0.00301\n",
      "Epoch: 0149 train_loss= 0.42882 time= 0.00307\n",
      "Epoch: 0150 train_loss= 0.42779 time= 0.00299\n",
      "Epoch: 0151 train_loss= 0.42751 time= 0.00301\n",
      "Epoch: 0152 train_loss= 0.43137 time= 0.00301\n",
      "Epoch: 0153 train_loss= 0.43014 time= 0.00205\n",
      "Epoch: 0154 train_loss= 0.43411 time= 0.00298\n",
      "Epoch: 0155 train_loss= 0.43172 time= 0.00306\n",
      "Epoch: 0156 train_loss= 0.43073 time= 0.00338\n",
      "Epoch: 0157 train_loss= 0.43783 time= 0.00405\n",
      "Epoch: 0158 train_loss= 0.43258 time= 0.00403\n",
      "Epoch: 0159 train_loss= 0.42973 time= 0.00296\n",
      "Epoch: 0160 train_loss= 0.42961 time= 0.00304\n",
      "Epoch: 0161 train_loss= 0.43283 time= 0.00299\n",
      "Epoch: 0162 train_loss= 0.42703 time= 0.00292\n",
      "Epoch: 0163 train_loss= 0.42551 time= 0.00308\n",
      "Epoch: 0164 train_loss= 0.43260 time= 0.00305\n",
      "Epoch: 0165 train_loss= 0.42912 time= 0.00289\n",
      "Epoch: 0166 train_loss= 0.42888 time= 0.00201\n",
      "Epoch: 0167 train_loss= 0.42816 time= 0.00295\n",
      "Epoch: 0168 train_loss= 0.43293 time= 0.00312\n",
      "Epoch: 0169 train_loss= 0.42607 time= 0.00293\n",
      "Epoch: 0170 train_loss= 0.42650 time= 0.00300\n",
      "Epoch: 0171 train_loss= 0.42808 time= 0.00195\n",
      "Epoch: 0172 train_loss= 0.42421 time= 0.00443\n",
      "Epoch: 0173 train_loss= 0.42716 time= 0.00289\n",
      "Epoch: 0174 train_loss= 0.42977 time= 0.00300\n",
      "Epoch: 0175 train_loss= 0.42292 time= 0.00302\n",
      "Epoch: 0176 train_loss= 0.42432 time= 0.00298\n",
      "Epoch: 0177 train_loss= 0.43031 time= 0.00509\n",
      "Epoch: 0178 train_loss= 0.42040 time= 0.00492\n",
      "Epoch: 0179 train_loss= 0.43041 time= 0.00402\n",
      "Epoch: 0180 train_loss= 0.42061 time= 0.00297\n",
      "Epoch: 0181 train_loss= 0.42354 time= 0.00304\n",
      "Epoch: 0182 train_loss= 0.42466 time= 0.00299\n",
      "Epoch: 0183 train_loss= 0.42400 time= 0.00302\n",
      "Epoch: 0184 train_loss= 0.42275 time= 0.00295\n",
      "Epoch: 0185 train_loss= 0.42901 time= 0.00309\n",
      "Epoch: 0186 train_loss= 0.42630 time= 0.00294\n",
      "Epoch: 0187 train_loss= 0.42421 time= 0.00406\n",
      "Epoch: 0188 train_loss= 0.42253 time= 0.00311\n",
      "Epoch: 0189 train_loss= 0.42121 time= 0.00199\n",
      "Epoch: 0190 train_loss= 0.42264 time= 0.00442\n",
      "Epoch: 0191 train_loss= 0.42460 time= 0.00307\n",
      "Epoch: 0192 train_loss= 0.42514 time= 0.00298\n",
      "Epoch: 0193 train_loss= 0.42768 time= 0.00196\n",
      "Epoch: 0194 train_loss= 0.42735 time= 0.00302\n",
      "Epoch: 0195 train_loss= 0.42133 time= 0.00303\n",
      "Epoch: 0196 train_loss= 0.42054 time= 0.00396\n",
      "Epoch: 0197 train_loss= 0.42331 time= 0.00305\n",
      "Epoch: 0198 train_loss= 0.43088 time= 0.00299\n",
      "Epoch: 0199 train_loss= 0.43049 time= 0.00309\n",
      "Epoch: 0200 train_loss= 0.42066 time= 0.00293\n",
      "Testing model...\n",
      "\n",
      "Test results for gravity_gcn_vae model on Cornell on task_3 \n",
      " ___________________________________________________\n",
      "\n",
      "AUC scores\n",
      " [0.7376543209876543, 0.6358024691358024, 0.7746913580246914, 0.7283950617283951, 0.7746913580246914, 0.8240740740740741, 0.6790123456790124, 0.712962962962963, 0.802469135802469, 0.8302469135802469]\n",
      "Mean AUC score:  0.75 \n",
      "Std of AUC scores:  0.05997510025427713 \n",
      " \n",
      "\n",
      "AP scores \n",
      " [0.7985652686323185, 0.6143910981901177, 0.8351491494465351, 0.7371376847295079, 0.7954925894984375, 0.8547277945970757, 0.7496183830791527, 0.7551121137696664, 0.8407180434062155, 0.8067162563642942]\n",
      "Mean AP score:  0.7787628381713321 \n",
      "Std of AP scores:  0.06663439870730155 \n",
      " \n",
      "\n",
      "Running times\n",
      " [0.5977706909179688, 0.5910751819610596, 0.666001558303833, 0.6682412624359131, 0.7040536403656006, 0.7189459800720215, 0.7536554336547852, 0.78094482421875, 0.8072283267974854, 0.8344826698303223]\n",
      "Mean running time:  0.7122399568557739 \n",
      "Std of running time:  0.07897572315173577 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lists to collect average results\n",
    "mean_roc = []\n",
    "mean_ap = []\n",
    "mean_time = []\n",
    "\n",
    "\n",
    "# Load graph dataset\n",
    "if FLAGS.verbose:\n",
    "    print(\"Loading data...\")\n",
    "adj_init, features = load_data(FLAGS.dataset)\n",
    "\n",
    "\n",
    "# The entire training process is repeated FLAGS.nb_run times\n",
    "for i in range(FLAGS.nb_run):\n",
    "\n",
    "    # Edge Masking: compute Train/Validation/Test set\n",
    "    if FLAGS.verbose:\n",
    "        print(\"Masking test edges...\")\n",
    "\n",
    "    if FLAGS.task == 'task_1':\n",
    "        # Edge masking for General Directed Link Prediction\n",
    "        adj, val_edges, val_edges_false, test_edges, test_edges_false = \\\n",
    "        mask_test_edges_general_link_prediction(adj_init, FLAGS.prop_test,\n",
    "                                                FLAGS.prop_val)\n",
    "    elif FLAGS.task == 'task_2':\n",
    "        # Edge masking for B.N.S. Directed Link Prediction\n",
    "        adj, val_edges, val_edges_false, test_edges, test_edges_false = \\\n",
    "        mask_test_edges_biased_negative_samples(adj_init, FLAGS.prop_test)\n",
    "    elif FLAGS.task == 'task_3':\n",
    "        # Edge masking for Bidirectionality Prediction\n",
    "        adj, val_edges, val_edges_false, test_edges, test_edges_false = \\\n",
    "        mask_test_edges_bidirectional_link_prediction(adj_init)\n",
    "    else:\n",
    "        raise ValueError('Undefined task!')\n",
    "\n",
    "    # Preprocessing and initialization\n",
    "    if FLAGS.verbose:\n",
    "        print(\"Preprocessing and Initializing...\")\n",
    "    # Compute number of nodes\n",
    "    num_nodes = adj.shape[0]\n",
    "    # If features are not used, replace feature matrix by identity matrix\n",
    "    if not FLAGS.features:\n",
    "        features = sp.identity(adj.shape[0])\n",
    "    # Preprocessing on node features\n",
    "    features = sparse_to_tuple(features)\n",
    "    num_features = features[2][1]\n",
    "    features_nonzero = features[1].shape[0]\n",
    "\n",
    "    # Define placeholders\n",
    "    placeholders = {\n",
    "        'features': tf.sparse_placeholder(tf.float32),\n",
    "        'adj': tf.sparse_placeholder(tf.float32),\n",
    "        'adj_orig': tf.sparse_placeholder(tf.float32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=())\n",
    "    }\n",
    "\n",
    "    # Create model\n",
    "    model = None\n",
    "    if FLAGS.model == 'gcn_ae':\n",
    "        # Standard Graph Autoencoder\n",
    "        model = GCNModelAE(placeholders, num_features, features_nonzero)\n",
    "    elif FLAGS.model == 'gcn_vae':\n",
    "        # Standard Graph Variational Autoencoder\n",
    "        model = GCNModelVAE(placeholders, num_features, num_nodes,\n",
    "                            features_nonzero)\n",
    "    elif FLAGS.model == 'source_target_gcn_ae':\n",
    "        # Source-Target Graph Autoencoder\n",
    "        if FLAGS.dimension % 2 != 0:\n",
    "            raise ValueError('Dimension must be even for Source-Target models')\n",
    "        model = SourceTargetGCNModelAE(placeholders, num_features,\n",
    "                                     features_nonzero)\n",
    "    elif FLAGS.model == 'source_target_gcn_vae':\n",
    "        # Source-Target Graph Variational Autoencoder\n",
    "        if FLAGS.dimension % 2 != 0:\n",
    "            raise ValueError('Dimension must be even for Source-Target models')\n",
    "        model = SourceTargetGCNModelVAE(placeholders, num_features,\n",
    "                                      num_nodes, features_nonzero)\n",
    "    elif FLAGS.model == 'gravity_gcn_ae':\n",
    "        # Gravity-Inspired Graph Autoencoder\n",
    "        model = GravityGCNModelAE(placeholders, num_features,\n",
    "                                  features_nonzero)\n",
    "    elif FLAGS.model == 'gravity_gcn_vae':\n",
    "        # Gravity-Inspired Graph Variational Autoencoder\n",
    "        model = GravityGCNModelVAE(placeholders, num_features, num_nodes,\n",
    "                                   features_nonzero)\n",
    "    else:\n",
    "        raise ValueError('Undefined model!')\n",
    "\n",
    "    # Optimizer (see tkipf/gae original GAE repository for details)\n",
    "    pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0]\n",
    "                                                - adj.sum()) * 2)\n",
    "    with tf.name_scope('optimizer'):\n",
    "        # Optimizer for Non-Variational Autoencoders\n",
    "        if FLAGS.model in ('gcn_ae', 'source_target_gcn_ae', 'gravity_gcn_ae'):\n",
    "            opt = OptimizerAE(preds = model.reconstructions,\n",
    "                              labels = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                            validate_indices = False), [-1]),\n",
    "                              pos_weight = pos_weight,\n",
    "                              norm = norm)\n",
    "        # Optimizer for Variational Autoencoders\n",
    "        elif FLAGS.model in ('gcn_vae', 'source_target_gcn_vae', 'gravity_gcn_vae'):\n",
    "            opt = OptimizerVAE(preds = model.reconstructions,\n",
    "                               labels = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                             validate_indices = False), [-1]),\n",
    "                               model = model,\n",
    "                               num_nodes = num_nodes,\n",
    "                               pos_weight = pos_weight,\n",
    "                               norm = norm)\n",
    "\n",
    "    # Normalization and preprocessing on adjacency matrix\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    adj_label = sparse_to_tuple(adj + sp.eye(adj.shape[0]))\n",
    "\n",
    "    # Initialize TF session\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Model training\n",
    "    if FLAGS.verbose:\n",
    "        print(\"Training...\")\n",
    "    # Flag to compute total running time\n",
    "    t_start = time.time()\n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        # Flag to compute running time for each epoch\n",
    "        t = time.time()\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = construct_feed_dict(adj_norm, adj_label, features,\n",
    "                                        placeholders)\n",
    "        feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "        # Weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.accuracy],\n",
    "                        feed_dict = feed_dict)\n",
    "        # Compute average loss\n",
    "        avg_cost = outs[1]\n",
    "        if FLAGS.verbose:\n",
    "            # Display epoch information\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
    "                  \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "            # Validation (implemented for Task 1 only)\n",
    "            if FLAGS.validation and FLAGS.task == 'task_1':\n",
    "                feed_dict.update({placeholders['dropout']: 0})\n",
    "                emb = sess.run(model.z_mean, feed_dict = feed_dict)\n",
    "                feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "                val_roc, val_ap = compute_scores(val_edges, val_edges_false, emb)\n",
    "                print(\"val_roc=\", \"{:.5f}\".format(val_roc), \"val_ap=\", \"{:.5f}\".format(val_ap))\n",
    "\n",
    "    # Compute total running time\n",
    "    mean_time.append(time.time() - t_start)\n",
    "\n",
    "    # Get embedding from model\n",
    "    emb = sess.run(model.z_mean, feed_dict = feed_dict)\n",
    "\n",
    "    # Test model\n",
    "    if FLAGS.verbose:\n",
    "        print(\"Testing model...\")\n",
    "    # Compute ROC and AP scores on test sets\n",
    "    roc_score, ap_score = compute_scores(test_edges, test_edges_false, emb)\n",
    "    # Append to list of scores over all runs\n",
    "    mean_roc.append(roc_score)\n",
    "    mean_ap.append(ap_score)\n",
    "\n",
    "# Report final results\n",
    "print(\"\\nTest results for\", FLAGS.model,\n",
    "      \"model on\", FLAGS.dataset, \"on\", FLAGS.task, \"\\n\",\n",
    "      \"___________________________________________________\\n\")\n",
    "\n",
    "print(\"AUC scores\\n\", mean_roc)\n",
    "print(\"Mean AUC score: \", np.mean(mean_roc),\n",
    "      \"\\nStd of AUC scores: \", np.std(mean_roc), \"\\n \\n\")\n",
    "\n",
    "print(\"AP scores \\n\", mean_ap)\n",
    "print(\"Mean AP score: \", np.mean(mean_ap),\n",
    "      \"\\nStd of AP scores: \", np.std(mean_ap), \"\\n \\n\")\n",
    "\n",
    "print(\"Running times\\n\", mean_time)\n",
    "print(\"Mean running time: \", np.mean(mean_time),\n",
    "      \"\\nStd of running time: \", np.std(mean_time), \"\\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8957159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.15",
   "language": "python",
   "name": "tf1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
