{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0646c9",
   "metadata": {},
   "source": [
    "# 导入库函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae55df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T06:17:51.679394Z",
     "start_time": "2022-11-12T06:17:49.801508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x21fb3127668>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from gravity_gae.evaluation import compute_scores\n",
    "from gravity_gae.input_data import load_data\n",
    "from gravity_gae.model import *\n",
    "from gravity_gae.optimizer import OptimizerAE, OptimizerVAE\n",
    "from gravity_gae.preprocessing import *\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')#添加的，不报错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33ea38",
   "metadata": {},
   "source": [
    "# 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9a099a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T06:17:51.756495Z",
     "start_time": "2022-11-12T06:17:51.742438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x21fb3155940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('dataset', 'Cornell', 'Name of the graph dataset')\n",
    "\n",
    "# Select machine learning task to perform on graph\n",
    "flags.DEFINE_string('task', 'task_3', 'Name of the link prediction task')\n",
    "''' See section 4.1. of paper for details about tasks:\n",
    "\n",
    "- task_1: General Directed Link Prediction\n",
    "\n",
    "- task_2: Biased Negative Samples Directed Link Prediction\n",
    "\n",
    "- task_3: Bidirectionality Prediction\n",
    "'''\n",
    "\n",
    "# Model\n",
    "flags.DEFINE_string('model', 'gravity_gcn_vae', 'Name of the model')\n",
    "''' Available Models:\n",
    "\n",
    "- gcn_ae: Graph Autoencoder from Kipf and Welling (2016), with 2-layer\n",
    "          GCN encoder and inner product decoder\n",
    "\n",
    "- gcn_vae: Variational Graph Autoencoder from Kipf and Welling (2016), with\n",
    "           Gaussian priors, 2-layer GCN encoders and inner product decoder\n",
    "\n",
    "- source_target_gcn_ae: Source-Target Graph Autoencoder, as introduced\n",
    "                        in section 2.6 of paper, with 2-layer GCN encoder\n",
    "                        and asymmetric inner product decoder\n",
    "\n",
    "- source_target_gcn_vae: Source-Target Graph Variational Autoencoder, as\n",
    "                         introduced in section 2.6, with Gaussian priors,\n",
    "                         2-layer GCN encoders and asymmetric inner product\n",
    " \n",
    "- gravity_gcn_ae: Gravity-Inspired Graph Autoencoder, as introduced in\n",
    "                  section 3.3 of paper, with 2-layer GCN encoder and \n",
    "                  gravity-inspired asymmetric decoder\n",
    " \n",
    "- gravity_gcn_vae: Gravity-Inspired Graph Variational Autoencoder, as\n",
    "                   introduced in section 3.4 of paper, with Gaussian \n",
    "                   priors, 2-layer GCN encoders and gravity-inspired decoder\n",
    "'''\n",
    "\n",
    "# Model parameters\n",
    "flags.DEFINE_float('dropout', 0., 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs in training.')\n",
    "flags.DEFINE_boolean('features', False, 'Include node features or not in GCN')\n",
    "flags.DEFINE_float('lamb', 1., 'lambda parameter from Gravity AE/VAE models \\\n",
    "                                as introduced in section 3.5 of paper, to \\\n",
    "                                balance mass and proximity terms')\n",
    "flags.DEFINE_float('learning_rate', 0.1, 'Initial learning rate (with Adam)')\n",
    "flags.DEFINE_integer('hidden', 24, 'Number of units in GCN hidden layer.')\n",
    "flags.DEFINE_integer('dimension', 12, 'Dimension of GCN output: \\\n",
    "- equal to embedding dimension for standard AE/VAE and source-target AE/VAE \\\n",
    "- equal to (embedding dimension - 1) for gravity-inspired AE/VAE, as the \\\n",
    "last dimension captures the \"mass\" parameter tilde{m}')\n",
    "flags.DEFINE_boolean('normalize', False, 'Whether to normalize embedding \\\n",
    "                                          vectors of gravity models')\n",
    "flags.DEFINE_float('epsilon', 0.01, 'Add epsilon to distances computations \\\n",
    "                                       in gravity models, for numerical \\\n",
    "                                       stability')\n",
    "# Experimental setup parameters\n",
    "flags.DEFINE_integer('nb_run', 10, 'Number of model run + test')\n",
    "flags.DEFINE_float('prop_val', 5., 'Proportion of edges in validation set \\\n",
    "                                   (for Task 1)')\n",
    "flags.DEFINE_float('prop_test', 10., 'Proportion of edges in test set \\\n",
    "                                      (for Tasks 1 and 2)')\n",
    "flags.DEFINE_boolean('validation', False, 'Whether to report validation \\\n",
    "                                           results  at each epoch (for \\\n",
    "                                           Task 1)')\n",
    "flags.DEFINE_boolean('verbose', True, 'Whether to print comments details.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb910058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T06:18:05.899083Z",
     "start_time": "2022-11-12T06:17:51.819870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.57523 time= 0.12400\n",
      "Epoch: 0002 train_loss= 1.35512 time= 0.00310\n",
      "Epoch: 0003 train_loss= 1.14451 time= 0.00290\n",
      "Epoch: 0004 train_loss= 0.80497 time= 0.00308\n",
      "Epoch: 0005 train_loss= 0.77999 time= 0.00298\n",
      "Epoch: 0006 train_loss= 0.79737 time= 0.00291\n",
      "Epoch: 0007 train_loss= 0.71308 time= 0.00297\n",
      "Epoch: 0008 train_loss= 0.62923 time= 0.00301\n",
      "Epoch: 0009 train_loss= 0.61081 time= 0.00300\n",
      "Epoch: 0010 train_loss= 0.63003 time= 0.00300\n",
      "Epoch: 0011 train_loss= 0.64732 time= 0.00301\n",
      "Epoch: 0012 train_loss= 0.64769 time= 0.00300\n",
      "Epoch: 0013 train_loss= 0.62424 time= 0.00299\n",
      "Epoch: 0014 train_loss= 0.59573 time= 0.00300\n",
      "Epoch: 0015 train_loss= 0.56789 time= 0.00200\n",
      "Epoch: 0016 train_loss= 0.55220 time= 0.00200\n",
      "Epoch: 0017 train_loss= 0.54910 time= 0.00301\n",
      "Epoch: 0018 train_loss= 0.54703 time= 0.00299\n",
      "Epoch: 0019 train_loss= 0.54500 time= 0.00301\n",
      "Epoch: 0020 train_loss= 0.53574 time= 0.00300\n",
      "Epoch: 0021 train_loss= 0.52366 time= 0.00311\n",
      "Epoch: 0022 train_loss= 0.51548 time= 0.00300\n",
      "Epoch: 0023 train_loss= 0.51697 time= 0.00300\n",
      "Epoch: 0024 train_loss= 0.51192 time= 0.00302\n",
      "Epoch: 0025 train_loss= 0.51510 time= 0.00199\n",
      "Epoch: 0026 train_loss= 0.51333 time= 0.00200\n",
      "Epoch: 0027 train_loss= 0.49937 time= 0.00301\n",
      "Epoch: 0028 train_loss= 0.49323 time= 0.00301\n",
      "Epoch: 0029 train_loss= 0.49139 time= 0.00299\n",
      "Epoch: 0030 train_loss= 0.49213 time= 0.00300\n",
      "Epoch: 0031 train_loss= 0.49383 time= 0.00300\n",
      "Epoch: 0032 train_loss= 0.48449 time= 0.00301\n",
      "Epoch: 0033 train_loss= 0.48653 time= 0.00299\n",
      "Epoch: 0034 train_loss= 0.48103 time= 0.00300\n",
      "Epoch: 0035 train_loss= 0.47677 time= 0.00299\n",
      "Epoch: 0036 train_loss= 0.47772 time= 0.00301\n",
      "Epoch: 0037 train_loss= 0.47843 time= 0.00200\n",
      "Epoch: 0038 train_loss= 0.46754 time= 0.00200\n",
      "Epoch: 0039 train_loss= 0.46141 time= 0.00300\n",
      "Epoch: 0040 train_loss= 0.48013 time= 0.00301\n",
      "Epoch: 0041 train_loss= 0.47951 time= 0.00300\n",
      "Epoch: 0042 train_loss= 0.46299 time= 0.00300\n",
      "Epoch: 0043 train_loss= 0.47411 time= 0.00200\n",
      "Epoch: 0044 train_loss= 0.46984 time= 0.00299\n",
      "Epoch: 0045 train_loss= 0.46339 time= 0.00200\n",
      "Epoch: 0046 train_loss= 0.46339 time= 0.00301\n",
      "Epoch: 0047 train_loss= 0.46049 time= 0.00300\n",
      "Epoch: 0048 train_loss= 0.45855 time= 0.00299\n",
      "Epoch: 0049 train_loss= 0.45967 time= 0.00300\n",
      "Epoch: 0050 train_loss= 0.45857 time= 0.00299\n",
      "Epoch: 0051 train_loss= 0.45940 time= 0.00302\n",
      "Epoch: 0052 train_loss= 0.45579 time= 0.00299\n",
      "Epoch: 0053 train_loss= 0.45705 time= 0.00300\n",
      "Epoch: 0054 train_loss= 0.45827 time= 0.00300\n",
      "Epoch: 0055 train_loss= 0.45363 time= 0.00300\n",
      "Epoch: 0056 train_loss= 0.45689 time= 0.00299\n",
      "Epoch: 0057 train_loss= 0.46625 time= 0.00300\n",
      "Epoch: 0058 train_loss= 0.45566 time= 0.00300\n",
      "Epoch: 0059 train_loss= 0.45414 time= 0.00300\n",
      "Epoch: 0060 train_loss= 0.45281 time= 0.00301\n",
      "Epoch: 0061 train_loss= 0.45477 time= 0.00300\n",
      "Epoch: 0062 train_loss= 0.46014 time= 0.00298\n",
      "Epoch: 0063 train_loss= 0.45480 time= 0.00299\n",
      "Epoch: 0064 train_loss= 0.45054 time= 0.00302\n",
      "Epoch: 0065 train_loss= 0.45066 time= 0.00299\n",
      "Epoch: 0066 train_loss= 0.45144 time= 0.00299\n",
      "Epoch: 0067 train_loss= 0.44938 time= 0.00402\n",
      "Epoch: 0068 train_loss= 0.44945 time= 0.00398\n",
      "Epoch: 0069 train_loss= 0.44650 time= 0.00300\n",
      "Epoch: 0070 train_loss= 0.45508 time= 0.00300\n",
      "Epoch: 0071 train_loss= 0.45309 time= 0.00200\n",
      "Epoch: 0072 train_loss= 0.44537 time= 0.00299\n",
      "Epoch: 0073 train_loss= 0.44945 time= 0.00301\n",
      "Epoch: 0074 train_loss= 0.44917 time= 0.00300\n",
      "Epoch: 0075 train_loss= 0.45007 time= 0.00299\n",
      "Epoch: 0076 train_loss= 0.44644 time= 0.00300\n",
      "Epoch: 0077 train_loss= 0.45013 time= 0.00401\n",
      "Epoch: 0078 train_loss= 0.44340 time= 0.00199\n",
      "Epoch: 0079 train_loss= 0.44540 time= 0.00301\n",
      "Epoch: 0080 train_loss= 0.44812 time= 0.00299\n",
      "Epoch: 0081 train_loss= 0.44376 time= 0.00301\n",
      "Epoch: 0082 train_loss= 0.44205 time= 0.00301\n",
      "Epoch: 0083 train_loss= 0.44889 time= 0.00298\n",
      "Epoch: 0084 train_loss= 0.44271 time= 0.00300\n",
      "Epoch: 0085 train_loss= 0.45224 time= 0.00300\n",
      "Epoch: 0086 train_loss= 0.44114 time= 0.00300\n",
      "Epoch: 0087 train_loss= 0.44644 time= 0.00301\n",
      "Epoch: 0088 train_loss= 0.44045 time= 0.00300\n",
      "Epoch: 0089 train_loss= 0.44729 time= 0.00199\n",
      "Epoch: 0090 train_loss= 0.44848 time= 0.00211\n",
      "Epoch: 0091 train_loss= 0.44748 time= 0.00290\n",
      "Epoch: 0092 train_loss= 0.44150 time= 0.00299\n",
      "Epoch: 0093 train_loss= 0.43703 time= 0.00301\n",
      "Epoch: 0094 train_loss= 0.43874 time= 0.00300\n",
      "Epoch: 0095 train_loss= 0.45094 time= 0.00307\n",
      "Epoch: 0096 train_loss= 0.45000 time= 0.00293\n",
      "Epoch: 0097 train_loss= 0.44221 time= 0.00300\n",
      "Epoch: 0098 train_loss= 0.43861 time= 0.00299\n",
      "Epoch: 0099 train_loss= 0.44116 time= 0.00200\n",
      "Epoch: 0100 train_loss= 0.44151 time= 0.00301\n",
      "Epoch: 0101 train_loss= 0.43936 time= 0.00300\n",
      "Epoch: 0102 train_loss= 0.43894 time= 0.00256\n",
      "Epoch: 0103 train_loss= 0.44198 time= 0.00301\n",
      "Epoch: 0104 train_loss= 0.44785 time= 0.00300\n",
      "Epoch: 0105 train_loss= 0.44104 time= 0.00300\n",
      "Epoch: 0106 train_loss= 0.44628 time= 0.00301\n",
      "Epoch: 0107 train_loss= 0.43867 time= 0.00199\n",
      "Epoch: 0108 train_loss= 0.43876 time= 0.00288\n",
      "Epoch: 0109 train_loss= 0.44069 time= 0.00301\n",
      "Epoch: 0110 train_loss= 0.43669 time= 0.00301\n",
      "Epoch: 0111 train_loss= 0.43927 time= 0.00306\n",
      "Epoch: 0112 train_loss= 0.43770 time= 0.00294\n",
      "Epoch: 0113 train_loss= 0.43989 time= 0.00299\n",
      "Epoch: 0114 train_loss= 0.43405 time= 0.00300\n",
      "Epoch: 0115 train_loss= 0.44262 time= 0.00301\n",
      "Epoch: 0116 train_loss= 0.43337 time= 0.00307\n",
      "Epoch: 0117 train_loss= 0.43242 time= 0.00194\n",
      "Epoch: 0118 train_loss= 0.43356 time= 0.00305\n",
      "Epoch: 0119 train_loss= 0.43935 time= 0.00300\n",
      "Epoch: 0120 train_loss= 0.43919 time= 0.00198\n",
      "Epoch: 0121 train_loss= 0.44160 time= 0.00194\n",
      "Epoch: 0122 train_loss= 0.43549 time= 0.00200\n",
      "Epoch: 0123 train_loss= 0.44132 time= 0.00200\n",
      "Epoch: 0124 train_loss= 0.44034 time= 0.00300\n",
      "Epoch: 0125 train_loss= 0.43764 time= 0.00301\n",
      "Epoch: 0126 train_loss= 0.43602 time= 0.00300\n",
      "Epoch: 0127 train_loss= 0.43150 time= 0.00308\n",
      "Epoch: 0128 train_loss= 0.43212 time= 0.00292\n",
      "Epoch: 0129 train_loss= 0.43402 time= 0.00299\n",
      "Epoch: 0130 train_loss= 0.43291 time= 0.00401\n",
      "Epoch: 0131 train_loss= 0.43667 time= 0.00300\n",
      "Epoch: 0132 train_loss= 0.43513 time= 0.00300\n",
      "Epoch: 0133 train_loss= 0.43238 time= 0.00291\n",
      "Epoch: 0134 train_loss= 0.43709 time= 0.00295\n",
      "Epoch: 0135 train_loss= 0.44191 time= 0.00300\n",
      "Epoch: 0136 train_loss= 0.43719 time= 0.00300\n",
      "Epoch: 0137 train_loss= 0.43711 time= 0.00199\n",
      "Epoch: 0138 train_loss= 0.43474 time= 0.00300\n",
      "Epoch: 0139 train_loss= 0.43178 time= 0.00300\n",
      "Epoch: 0140 train_loss= 0.43076 time= 0.00301\n",
      "Epoch: 0141 train_loss= 0.43408 time= 0.00399\n",
      "Epoch: 0142 train_loss= 0.43136 time= 0.00300\n",
      "Epoch: 0143 train_loss= 0.43350 time= 0.00400\n",
      "Epoch: 0144 train_loss= 0.43136 time= 0.00401\n",
      "Epoch: 0145 train_loss= 0.43161 time= 0.00299\n",
      "Epoch: 0146 train_loss= 0.42944 time= 0.00301\n",
      "Epoch: 0147 train_loss= 0.43168 time= 0.00299\n",
      "Epoch: 0148 train_loss= 0.43315 time= 0.00300\n",
      "Epoch: 0149 train_loss= 0.43046 time= 0.00400\n",
      "Epoch: 0150 train_loss= 0.43415 time= 0.00300\n",
      "Epoch: 0151 train_loss= 0.43268 time= 0.00300\n",
      "Epoch: 0152 train_loss= 0.42726 time= 0.00300\n",
      "Epoch: 0153 train_loss= 0.42608 time= 0.00300\n",
      "Epoch: 0154 train_loss= 0.43214 time= 0.00300\n",
      "Epoch: 0155 train_loss= 0.42938 time= 0.00300\n",
      "Epoch: 0156 train_loss= 0.43482 time= 0.00300\n",
      "Epoch: 0157 train_loss= 0.42688 time= 0.00300\n",
      "Epoch: 0158 train_loss= 0.43203 time= 0.00300\n",
      "Epoch: 0159 train_loss= 0.42741 time= 0.00300\n",
      "Epoch: 0160 train_loss= 0.43326 time= 0.00200\n",
      "Epoch: 0161 train_loss= 0.43247 time= 0.00201\n",
      "Epoch: 0162 train_loss= 0.42851 time= 0.00200\n",
      "Epoch: 0163 train_loss= 0.43104 time= 0.00200\n",
      "Epoch: 0164 train_loss= 0.42535 time= 0.00201\n",
      "Epoch: 0165 train_loss= 0.42708 time= 0.00200\n",
      "Epoch: 0166 train_loss= 0.42895 time= 0.00200\n",
      "Epoch: 0167 train_loss= 0.43645 time= 0.00200\n",
      "Epoch: 0168 train_loss= 0.42659 time= 0.00300\n",
      "Epoch: 0169 train_loss= 0.43336 time= 0.00301\n",
      "Epoch: 0170 train_loss= 0.43906 time= 0.00199\n",
      "Epoch: 0171 train_loss= 0.43149 time= 0.00200\n",
      "Epoch: 0172 train_loss= 0.43022 time= 0.00200\n",
      "Epoch: 0173 train_loss= 0.43930 time= 0.00301\n",
      "Epoch: 0174 train_loss= 0.43620 time= 0.00300\n",
      "Epoch: 0175 train_loss= 0.43643 time= 0.00299\n",
      "Epoch: 0176 train_loss= 0.43859 time= 0.00300\n",
      "Epoch: 0177 train_loss= 0.43072 time= 0.00200\n",
      "Epoch: 0178 train_loss= 0.42563 time= 0.00200\n",
      "Epoch: 0179 train_loss= 0.43192 time= 0.00201\n",
      "Epoch: 0180 train_loss= 0.43075 time= 0.00301\n",
      "Epoch: 0181 train_loss= 0.43004 time= 0.00199\n",
      "Epoch: 0182 train_loss= 0.42687 time= 0.00312\n",
      "Epoch: 0183 train_loss= 0.43032 time= 0.00307\n",
      "Epoch: 0184 train_loss= 0.43049 time= 0.00300\n",
      "Epoch: 0185 train_loss= 0.42199 time= 0.00300\n",
      "Epoch: 0186 train_loss= 0.42574 time= 0.00300\n",
      "Epoch: 0187 train_loss= 0.43188 time= 0.00299\n",
      "Epoch: 0188 train_loss= 0.43165 time= 0.00300\n",
      "Epoch: 0189 train_loss= 0.43382 time= 0.00200\n",
      "Epoch: 0190 train_loss= 0.42269 time= 0.00200\n",
      "Epoch: 0191 train_loss= 0.42887 time= 0.00200\n",
      "Epoch: 0192 train_loss= 0.42742 time= 0.00301\n",
      "Epoch: 0193 train_loss= 0.43080 time= 0.00300\n",
      "Epoch: 0194 train_loss= 0.43343 time= 0.00300\n",
      "Epoch: 0195 train_loss= 0.43413 time= 0.00407\n",
      "Epoch: 0196 train_loss= 0.43240 time= 0.00400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0197 train_loss= 0.43030 time= 0.00301\n",
      "Epoch: 0198 train_loss= 0.42684 time= 0.00301\n",
      "Epoch: 0199 train_loss= 0.42412 time= 0.00301\n",
      "Epoch: 0200 train_loss= 0.42822 time= 0.00299\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.58152 time= 0.09306\n",
      "Epoch: 0002 train_loss= 1.30586 time= 0.00331\n",
      "Epoch: 0003 train_loss= 0.99652 time= 0.00306\n",
      "Epoch: 0004 train_loss= 0.71997 time= 0.00298\n",
      "Epoch: 0005 train_loss= 0.87104 time= 0.00298\n",
      "Epoch: 0006 train_loss= 0.81017 time= 0.00304\n",
      "Epoch: 0007 train_loss= 0.70376 time= 0.00302\n",
      "Epoch: 0008 train_loss= 0.61613 time= 0.00293\n",
      "Epoch: 0009 train_loss= 0.60406 time= 0.00301\n",
      "Epoch: 0010 train_loss= 0.61843 time= 0.00299\n",
      "Epoch: 0011 train_loss= 0.64492 time= 0.00300\n",
      "Epoch: 0012 train_loss= 0.64029 time= 0.00301\n",
      "Epoch: 0013 train_loss= 0.61810 time= 0.00299\n",
      "Epoch: 0014 train_loss= 0.57462 time= 0.00300\n",
      "Epoch: 0015 train_loss= 0.56518 time= 0.00314\n",
      "Epoch: 0016 train_loss= 0.55313 time= 0.00301\n",
      "Epoch: 0017 train_loss= 0.55095 time= 0.00300\n",
      "Epoch: 0018 train_loss= 0.55603 time= 0.00300\n",
      "Epoch: 0019 train_loss= 0.55097 time= 0.00299\n",
      "Epoch: 0020 train_loss= 0.54652 time= 0.00301\n",
      "Epoch: 0021 train_loss= 0.53392 time= 0.00300\n",
      "Epoch: 0022 train_loss= 0.52503 time= 0.00300\n",
      "Epoch: 0023 train_loss= 0.51773 time= 0.00300\n",
      "Epoch: 0024 train_loss= 0.51778 time= 0.00300\n",
      "Epoch: 0025 train_loss= 0.51268 time= 0.00614\n",
      "Epoch: 0026 train_loss= 0.50850 time= 0.00262\n",
      "Epoch: 0027 train_loss= 0.50988 time= 0.00201\n",
      "Epoch: 0028 train_loss= 0.49986 time= 0.00300\n",
      "Epoch: 0029 train_loss= 0.49446 time= 0.00301\n",
      "Epoch: 0030 train_loss= 0.49239 time= 0.00300\n",
      "Epoch: 0031 train_loss= 0.49107 time= 0.00299\n",
      "Epoch: 0032 train_loss= 0.48970 time= 0.00301\n",
      "Epoch: 0033 train_loss= 0.48497 time= 0.00200\n",
      "Epoch: 0034 train_loss= 0.48491 time= 0.00199\n",
      "Epoch: 0035 train_loss= 0.47972 time= 0.00400\n",
      "Epoch: 0036 train_loss= 0.48907 time= 0.00301\n",
      "Epoch: 0037 train_loss= 0.47519 time= 0.00300\n",
      "Epoch: 0038 train_loss= 0.47927 time= 0.00301\n",
      "Epoch: 0039 train_loss= 0.47442 time= 0.00301\n",
      "Epoch: 0040 train_loss= 0.46988 time= 0.00298\n",
      "Epoch: 0041 train_loss= 0.47148 time= 0.00318\n",
      "Epoch: 0042 train_loss= 0.47382 time= 0.00282\n",
      "Epoch: 0043 train_loss= 0.46980 time= 0.00300\n",
      "Epoch: 0044 train_loss= 0.46779 time= 0.00300\n",
      "Epoch: 0045 train_loss= 0.46723 time= 0.00302\n",
      "Epoch: 0046 train_loss= 0.46892 time= 0.00301\n",
      "Epoch: 0047 train_loss= 0.45951 time= 0.00298\n",
      "Epoch: 0048 train_loss= 0.46200 time= 0.00301\n",
      "Epoch: 0049 train_loss= 0.47610 time= 0.00300\n",
      "Epoch: 0050 train_loss= 0.47084 time= 0.00301\n",
      "Epoch: 0051 train_loss= 0.46314 time= 0.00300\n",
      "Epoch: 0052 train_loss= 0.46001 time= 0.00298\n",
      "Epoch: 0053 train_loss= 0.46754 time= 0.00200\n",
      "Epoch: 0054 train_loss= 0.45853 time= 0.00200\n",
      "Epoch: 0055 train_loss= 0.46660 time= 0.00300\n",
      "Epoch: 0056 train_loss= 0.45282 time= 0.00302\n",
      "Epoch: 0057 train_loss= 0.46027 time= 0.00299\n",
      "Epoch: 0058 train_loss= 0.46466 time= 0.00300\n",
      "Epoch: 0059 train_loss= 0.45521 time= 0.00300\n",
      "Epoch: 0060 train_loss= 0.46320 time= 0.00301\n",
      "Epoch: 0061 train_loss= 0.45317 time= 0.00301\n",
      "Epoch: 0062 train_loss= 0.45759 time= 0.00300\n",
      "Epoch: 0063 train_loss= 0.45797 time= 0.00298\n",
      "Epoch: 0064 train_loss= 0.45002 time= 0.00200\n",
      "Epoch: 0065 train_loss= 0.45118 time= 0.00300\n",
      "Epoch: 0066 train_loss= 0.45122 time= 0.00311\n",
      "Epoch: 0067 train_loss= 0.44836 time= 0.00294\n",
      "Epoch: 0068 train_loss= 0.45591 time= 0.00295\n",
      "Epoch: 0069 train_loss= 0.45443 time= 0.00206\n",
      "Epoch: 0070 train_loss= 0.46322 time= 0.00300\n",
      "Epoch: 0071 train_loss= 0.44983 time= 0.00301\n",
      "Epoch: 0072 train_loss= 0.45436 time= 0.00301\n",
      "Epoch: 0073 train_loss= 0.45481 time= 0.00299\n",
      "Epoch: 0074 train_loss= 0.44738 time= 0.00301\n",
      "Epoch: 0075 train_loss= 0.44736 time= 0.00298\n",
      "Epoch: 0076 train_loss= 0.44641 time= 0.00200\n",
      "Epoch: 0077 train_loss= 0.44842 time= 0.00300\n",
      "Epoch: 0078 train_loss= 0.44803 time= 0.00301\n",
      "Epoch: 0079 train_loss= 0.44765 time= 0.00300\n",
      "Epoch: 0080 train_loss= 0.45777 time= 0.00299\n",
      "Epoch: 0081 train_loss= 0.45015 time= 0.00301\n",
      "Epoch: 0082 train_loss= 0.44345 time= 0.00300\n",
      "Epoch: 0083 train_loss= 0.44387 time= 0.00301\n",
      "Epoch: 0084 train_loss= 0.45352 time= 0.00298\n",
      "Epoch: 0085 train_loss= 0.45065 time= 0.00299\n",
      "Epoch: 0086 train_loss= 0.44825 time= 0.00300\n",
      "Epoch: 0087 train_loss= 0.44905 time= 0.00301\n",
      "Epoch: 0088 train_loss= 0.44169 time= 0.00300\n",
      "Epoch: 0089 train_loss= 0.44638 time= 0.00301\n",
      "Epoch: 0090 train_loss= 0.44586 time= 0.00300\n",
      "Epoch: 0091 train_loss= 0.45173 time= 0.00301\n",
      "Epoch: 0092 train_loss= 0.44549 time= 0.00301\n",
      "Epoch: 0093 train_loss= 0.44040 time= 0.00299\n",
      "Epoch: 0094 train_loss= 0.45526 time= 0.00326\n",
      "Epoch: 0095 train_loss= 0.44545 time= 0.00274\n",
      "Epoch: 0096 train_loss= 0.44588 time= 0.00199\n",
      "Epoch: 0097 train_loss= 0.45027 time= 0.00301\n",
      "Epoch: 0098 train_loss= 0.43877 time= 0.00300\n",
      "Epoch: 0099 train_loss= 0.44446 time= 0.00301\n",
      "Epoch: 0100 train_loss= 0.44152 time= 0.00299\n",
      "Epoch: 0101 train_loss= 0.44465 time= 0.00299\n",
      "Epoch: 0102 train_loss= 0.44738 time= 0.00201\n",
      "Epoch: 0103 train_loss= 0.44710 time= 0.00202\n",
      "Epoch: 0104 train_loss= 0.43996 time= 0.00199\n",
      "Epoch: 0105 train_loss= 0.44750 time= 0.00200\n",
      "Epoch: 0106 train_loss= 0.44499 time= 0.00200\n",
      "Epoch: 0107 train_loss= 0.44890 time= 0.00300\n",
      "Epoch: 0108 train_loss= 0.44117 time= 0.00300\n",
      "Epoch: 0109 train_loss= 0.44341 time= 0.00301\n",
      "Epoch: 0110 train_loss= 0.44749 time= 0.00300\n",
      "Epoch: 0111 train_loss= 0.44917 time= 0.00400\n",
      "Epoch: 0112 train_loss= 0.44815 time= 0.00300\n",
      "Epoch: 0113 train_loss= 0.43542 time= 0.00200\n",
      "Epoch: 0114 train_loss= 0.43762 time= 0.00200\n",
      "Epoch: 0115 train_loss= 0.43484 time= 0.00321\n",
      "Epoch: 0116 train_loss= 0.44025 time= 0.00379\n",
      "Epoch: 0117 train_loss= 0.44375 time= 0.00200\n",
      "Epoch: 0118 train_loss= 0.43650 time= 0.00301\n",
      "Epoch: 0119 train_loss= 0.43778 time= 0.00299\n",
      "Epoch: 0120 train_loss= 0.43395 time= 0.00302\n",
      "Epoch: 0121 train_loss= 0.43897 time= 0.00298\n",
      "Epoch: 0122 train_loss= 0.43591 time= 0.00300\n",
      "Epoch: 0123 train_loss= 0.44011 time= 0.00300\n",
      "Epoch: 0124 train_loss= 0.43687 time= 0.00200\n",
      "Epoch: 0125 train_loss= 0.43747 time= 0.00301\n",
      "Epoch: 0126 train_loss= 0.44224 time= 0.00300\n",
      "Epoch: 0127 train_loss= 0.44211 time= 0.00298\n",
      "Epoch: 0128 train_loss= 0.43671 time= 0.00302\n",
      "Epoch: 0129 train_loss= 0.44831 time= 0.00300\n",
      "Epoch: 0130 train_loss= 0.43425 time= 0.00299\n",
      "Epoch: 0131 train_loss= 0.43412 time= 0.00399\n",
      "Epoch: 0132 train_loss= 0.43944 time= 0.00401\n",
      "Epoch: 0133 train_loss= 0.43841 time= 0.00302\n",
      "Epoch: 0134 train_loss= 0.44081 time= 0.00299\n",
      "Epoch: 0135 train_loss= 0.44493 time= 0.00299\n",
      "Epoch: 0136 train_loss= 0.43028 time= 0.00400\n",
      "Epoch: 0137 train_loss= 0.43888 time= 0.00301\n",
      "Epoch: 0138 train_loss= 0.43144 time= 0.00300\n",
      "Epoch: 0139 train_loss= 0.43757 time= 0.00300\n",
      "Epoch: 0140 train_loss= 0.43603 time= 0.00299\n",
      "Epoch: 0141 train_loss= 0.42805 time= 0.00300\n",
      "Epoch: 0142 train_loss= 0.43646 time= 0.00300\n",
      "Epoch: 0143 train_loss= 0.44259 time= 0.00299\n",
      "Epoch: 0144 train_loss= 0.44197 time= 0.00400\n",
      "Epoch: 0145 train_loss= 0.44159 time= 0.00300\n",
      "Epoch: 0146 train_loss= 0.43595 time= 0.00300\n",
      "Epoch: 0147 train_loss= 0.44039 time= 0.00308\n",
      "Epoch: 0148 train_loss= 0.43617 time= 0.00298\n",
      "Epoch: 0149 train_loss= 0.44428 time= 0.00298\n",
      "Epoch: 0150 train_loss= 0.43576 time= 0.00301\n",
      "Epoch: 0151 train_loss= 0.44292 time= 0.00294\n",
      "Epoch: 0152 train_loss= 0.43624 time= 0.00305\n",
      "Epoch: 0153 train_loss= 0.43418 time= 0.00298\n",
      "Epoch: 0154 train_loss= 0.43971 time= 0.00301\n",
      "Epoch: 0155 train_loss= 0.43031 time= 0.00294\n",
      "Epoch: 0156 train_loss= 0.43455 time= 0.00406\n",
      "Epoch: 0157 train_loss= 0.44053 time= 0.00306\n",
      "Epoch: 0158 train_loss= 0.43318 time= 0.00288\n",
      "Epoch: 0159 train_loss= 0.43702 time= 0.00301\n",
      "Epoch: 0160 train_loss= 0.43826 time= 0.00299\n",
      "Epoch: 0161 train_loss= 0.42822 time= 0.00299\n",
      "Epoch: 0162 train_loss= 0.43421 time= 0.00303\n",
      "Epoch: 0163 train_loss= 0.43371 time= 0.00299\n",
      "Epoch: 0164 train_loss= 0.42878 time= 0.00299\n",
      "Epoch: 0165 train_loss= 0.43037 time= 0.00299\n",
      "Epoch: 0166 train_loss= 0.44331 time= 0.00299\n",
      "Epoch: 0167 train_loss= 0.43117 time= 0.00301\n",
      "Epoch: 0168 train_loss= 0.42649 time= 0.00300\n",
      "Epoch: 0169 train_loss= 0.43087 time= 0.00300\n",
      "Epoch: 0170 train_loss= 0.43149 time= 0.00300\n",
      "Epoch: 0171 train_loss= 0.43406 time= 0.00300\n",
      "Epoch: 0172 train_loss= 0.43092 time= 0.00301\n",
      "Epoch: 0173 train_loss= 0.44086 time= 0.00308\n",
      "Epoch: 0174 train_loss= 0.44117 time= 0.00299\n",
      "Epoch: 0175 train_loss= 0.43127 time= 0.00303\n",
      "Epoch: 0176 train_loss= 0.42851 time= 0.00298\n",
      "Epoch: 0177 train_loss= 0.44520 time= 0.00297\n",
      "Epoch: 0178 train_loss= 0.43387 time= 0.00306\n",
      "Epoch: 0179 train_loss= 0.43489 time= 0.00202\n",
      "Epoch: 0180 train_loss= 0.43583 time= 0.00200\n",
      "Epoch: 0181 train_loss= 0.43350 time= 0.00301\n",
      "Epoch: 0182 train_loss= 0.43066 time= 0.00300\n",
      "Epoch: 0183 train_loss= 0.43687 time= 0.00299\n",
      "Epoch: 0184 train_loss= 0.43138 time= 0.00300\n",
      "Epoch: 0185 train_loss= 0.43138 time= 0.00302\n",
      "Epoch: 0186 train_loss= 0.43112 time= 0.00307\n",
      "Epoch: 0187 train_loss= 0.43077 time= 0.00293\n",
      "Epoch: 0188 train_loss= 0.43318 time= 0.00300\n",
      "Epoch: 0189 train_loss= 0.43189 time= 0.00301\n",
      "Epoch: 0190 train_loss= 0.43340 time= 0.00303\n",
      "Epoch: 0191 train_loss= 0.43346 time= 0.00295\n",
      "Epoch: 0192 train_loss= 0.42867 time= 0.00309\n",
      "Epoch: 0193 train_loss= 0.43053 time= 0.00301\n",
      "Epoch: 0194 train_loss= 0.43076 time= 0.00194\n",
      "Epoch: 0195 train_loss= 0.43177 time= 0.00299\n",
      "Epoch: 0196 train_loss= 0.42703 time= 0.00308\n",
      "Epoch: 0197 train_loss= 0.42920 time= 0.00294\n",
      "Epoch: 0198 train_loss= 0.42792 time= 0.00409\n",
      "Epoch: 0199 train_loss= 0.42689 time= 0.00301\n",
      "Epoch: 0200 train_loss= 0.43402 time= 0.00303\n",
      "Testing model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.59607 time= 0.10042\n",
      "Epoch: 0002 train_loss= 1.38605 time= 0.00300\n",
      "Epoch: 0003 train_loss= 1.15893 time= 0.00399\n",
      "Epoch: 0004 train_loss= 0.78985 time= 0.00300\n",
      "Epoch: 0005 train_loss= 0.80228 time= 0.00301\n",
      "Epoch: 0006 train_loss= 0.86779 time= 0.00299\n",
      "Epoch: 0007 train_loss= 0.78103 time= 0.00299\n",
      "Epoch: 0008 train_loss= 0.68302 time= 0.00301\n",
      "Epoch: 0009 train_loss= 0.60818 time= 0.00300\n",
      "Epoch: 0010 train_loss= 0.61371 time= 0.00200\n",
      "Epoch: 0011 train_loss= 0.61472 time= 0.00300\n",
      "Epoch: 0012 train_loss= 0.65605 time= 0.00301\n",
      "Epoch: 0013 train_loss= 0.64178 time= 0.00301\n",
      "Epoch: 0014 train_loss= 0.63041 time= 0.00299\n",
      "Epoch: 0015 train_loss= 0.59382 time= 0.00299\n",
      "Epoch: 0016 train_loss= 0.57775 time= 0.00301\n",
      "Epoch: 0017 train_loss= 0.56032 time= 0.00300\n",
      "Epoch: 0018 train_loss= 0.54705 time= 0.00301\n",
      "Epoch: 0019 train_loss= 0.55233 time= 0.00299\n",
      "Epoch: 0020 train_loss= 0.54948 time= 0.00300\n",
      "Epoch: 0021 train_loss= 0.54967 time= 0.00343\n",
      "Epoch: 0022 train_loss= 0.53825 time= 0.00300\n",
      "Epoch: 0023 train_loss= 0.53036 time= 0.00300\n",
      "Epoch: 0024 train_loss= 0.52053 time= 0.00300\n",
      "Epoch: 0025 train_loss= 0.52293 time= 0.00301\n",
      "Epoch: 0026 train_loss= 0.51110 time= 0.00301\n",
      "Epoch: 0027 train_loss= 0.52687 time= 0.00399\n",
      "Epoch: 0028 train_loss= 0.50445 time= 0.00400\n",
      "Epoch: 0029 train_loss= 0.50599 time= 0.00399\n",
      "Epoch: 0030 train_loss= 0.50467 time= 0.00402\n",
      "Epoch: 0031 train_loss= 0.50165 time= 0.00398\n",
      "Epoch: 0032 train_loss= 0.48718 time= 0.00301\n",
      "Epoch: 0033 train_loss= 0.49018 time= 0.00300\n",
      "Epoch: 0034 train_loss= 0.48757 time= 0.00199\n",
      "Epoch: 0035 train_loss= 0.49240 time= 0.00301\n",
      "Epoch: 0036 train_loss= 0.48273 time= 0.00300\n",
      "Epoch: 0037 train_loss= 0.48887 time= 0.00300\n",
      "Epoch: 0038 train_loss= 0.48642 time= 0.00299\n",
      "Epoch: 0039 train_loss= 0.47496 time= 0.00300\n",
      "Epoch: 0040 train_loss= 0.47310 time= 0.00200\n",
      "Epoch: 0041 train_loss= 0.47553 time= 0.00400\n",
      "Epoch: 0042 train_loss= 0.48298 time= 0.00300\n",
      "Epoch: 0043 train_loss= 0.47259 time= 0.00301\n",
      "Epoch: 0044 train_loss= 0.47802 time= 0.00299\n",
      "Epoch: 0045 train_loss= 0.47541 time= 0.00301\n",
      "Epoch: 0046 train_loss= 0.47191 time= 0.00300\n",
      "Epoch: 0047 train_loss= 0.46450 time= 0.00300\n",
      "Epoch: 0048 train_loss= 0.46107 time= 0.00302\n",
      "Epoch: 0049 train_loss= 0.46785 time= 0.00201\n",
      "Epoch: 0050 train_loss= 0.46783 time= 0.00199\n",
      "Epoch: 0051 train_loss= 0.46487 time= 0.00302\n",
      "Epoch: 0052 train_loss= 0.46459 time= 0.00300\n",
      "Epoch: 0053 train_loss= 0.46430 time= 0.00200\n",
      "Epoch: 0054 train_loss= 0.46459 time= 0.00200\n",
      "Epoch: 0055 train_loss= 0.46524 time= 0.00200\n",
      "Epoch: 0056 train_loss= 0.45815 time= 0.00200\n",
      "Epoch: 0057 train_loss= 0.46306 time= 0.00300\n",
      "Epoch: 0058 train_loss= 0.46176 time= 0.00301\n",
      "Epoch: 0059 train_loss= 0.46161 time= 0.00299\n",
      "Epoch: 0060 train_loss= 0.45487 time= 0.00301\n",
      "Epoch: 0061 train_loss= 0.45923 time= 0.00313\n",
      "Epoch: 0062 train_loss= 0.45122 time= 0.00287\n",
      "Epoch: 0063 train_loss= 0.44909 time= 0.00294\n",
      "Epoch: 0064 train_loss= 0.45326 time= 0.00299\n",
      "Epoch: 0065 train_loss= 0.45263 time= 0.00299\n",
      "Epoch: 0066 train_loss= 0.45173 time= 0.00281\n",
      "Epoch: 0067 train_loss= 0.45515 time= 0.00300\n",
      "Epoch: 0068 train_loss= 0.45196 time= 0.00304\n",
      "Epoch: 0069 train_loss= 0.45249 time= 0.00193\n",
      "Epoch: 0070 train_loss= 0.45531 time= 0.00310\n",
      "Epoch: 0071 train_loss= 0.45731 time= 0.00296\n",
      "Epoch: 0072 train_loss= 0.44576 time= 0.00294\n",
      "Epoch: 0073 train_loss= 0.44829 time= 0.00300\n",
      "Epoch: 0074 train_loss= 0.44545 time= 0.00301\n",
      "Epoch: 0075 train_loss= 0.44749 time= 0.00301\n",
      "Epoch: 0076 train_loss= 0.45014 time= 0.00198\n",
      "Epoch: 0077 train_loss= 0.45011 time= 0.00301\n",
      "Epoch: 0078 train_loss= 0.44327 time= 0.00299\n",
      "Epoch: 0079 train_loss= 0.45124 time= 0.00200\n",
      "Epoch: 0080 train_loss= 0.44762 time= 0.00200\n",
      "Epoch: 0081 train_loss= 0.45081 time= 0.00300\n",
      "Epoch: 0082 train_loss= 0.45372 time= 0.00300\n",
      "Epoch: 0083 train_loss= 0.43928 time= 0.00299\n",
      "Epoch: 0084 train_loss= 0.44524 time= 0.00299\n",
      "Epoch: 0085 train_loss= 0.45368 time= 0.00200\n",
      "Epoch: 0086 train_loss= 0.44892 time= 0.00301\n",
      "Epoch: 0087 train_loss= 0.44592 time= 0.00300\n",
      "Epoch: 0088 train_loss= 0.44044 time= 0.00301\n",
      "Epoch: 0089 train_loss= 0.44280 time= 0.00200\n",
      "Epoch: 0090 train_loss= 0.44499 time= 0.00199\n",
      "Epoch: 0091 train_loss= 0.44023 time= 0.00200\n",
      "Epoch: 0092 train_loss= 0.44295 time= 0.00302\n",
      "Epoch: 0093 train_loss= 0.43777 time= 0.00300\n",
      "Epoch: 0094 train_loss= 0.44638 time= 0.00299\n",
      "Epoch: 0095 train_loss= 0.43974 time= 0.00299\n",
      "Epoch: 0096 train_loss= 0.44272 time= 0.00300\n",
      "Epoch: 0097 train_loss= 0.43998 time= 0.00300\n",
      "Epoch: 0098 train_loss= 0.44840 time= 0.00301\n",
      "Epoch: 0099 train_loss= 0.43943 time= 0.00300\n",
      "Epoch: 0100 train_loss= 0.44360 time= 0.00300\n",
      "Epoch: 0101 train_loss= 0.44129 time= 0.00300\n",
      "Epoch: 0102 train_loss= 0.44377 time= 0.00301\n",
      "Epoch: 0103 train_loss= 0.44080 time= 0.00298\n",
      "Epoch: 0104 train_loss= 0.44205 time= 0.00301\n",
      "Epoch: 0105 train_loss= 0.44076 time= 0.00300\n",
      "Epoch: 0106 train_loss= 0.44370 time= 0.00308\n",
      "Epoch: 0107 train_loss= 0.43834 time= 0.00292\n",
      "Epoch: 0108 train_loss= 0.44220 time= 0.00201\n",
      "Epoch: 0109 train_loss= 0.43913 time= 0.00199\n",
      "Epoch: 0110 train_loss= 0.43661 time= 0.00301\n",
      "Epoch: 0111 train_loss= 0.43799 time= 0.00198\n",
      "Epoch: 0112 train_loss= 0.44054 time= 0.00200\n",
      "Epoch: 0113 train_loss= 0.44005 time= 0.00301\n",
      "Epoch: 0114 train_loss= 0.43896 time= 0.00300\n",
      "Epoch: 0115 train_loss= 0.44229 time= 0.00301\n",
      "Epoch: 0116 train_loss= 0.43800 time= 0.00299\n",
      "Epoch: 0117 train_loss= 0.43723 time= 0.00199\n",
      "Epoch: 0118 train_loss= 0.43810 time= 0.00300\n",
      "Epoch: 0119 train_loss= 0.44147 time= 0.00201\n",
      "Epoch: 0120 train_loss= 0.45015 time= 0.00200\n",
      "Epoch: 0121 train_loss= 0.43702 time= 0.00201\n",
      "Epoch: 0122 train_loss= 0.43672 time= 0.00201\n",
      "Epoch: 0123 train_loss= 0.43818 time= 0.00300\n",
      "Epoch: 0124 train_loss= 0.43953 time= 0.00200\n",
      "Epoch: 0125 train_loss= 0.44183 time= 0.00201\n",
      "Epoch: 0126 train_loss= 0.44252 time= 0.00301\n",
      "Epoch: 0127 train_loss= 0.43475 time= 0.00301\n",
      "Epoch: 0128 train_loss= 0.43913 time= 0.00307\n",
      "Epoch: 0129 train_loss= 0.43852 time= 0.00298\n",
      "Epoch: 0130 train_loss= 0.43203 time= 0.00306\n",
      "Epoch: 0131 train_loss= 0.43704 time= 0.00190\n",
      "Epoch: 0132 train_loss= 0.43899 time= 0.00299\n",
      "Epoch: 0133 train_loss= 0.43419 time= 0.00200\n",
      "Epoch: 0134 train_loss= 0.43712 time= 0.00200\n",
      "Epoch: 0135 train_loss= 0.43652 time= 0.00200\n",
      "Epoch: 0136 train_loss= 0.43339 time= 0.00200\n",
      "Epoch: 0137 train_loss= 0.44139 time= 0.00196\n",
      "Epoch: 0138 train_loss= 0.43770 time= 0.00200\n",
      "Epoch: 0139 train_loss= 0.43398 time= 0.00200\n",
      "Epoch: 0140 train_loss= 0.43888 time= 0.00200\n",
      "Epoch: 0141 train_loss= 0.43739 time= 0.00199\n",
      "Epoch: 0142 train_loss= 0.43123 time= 0.00200\n",
      "Epoch: 0143 train_loss= 0.43395 time= 0.00200\n",
      "Epoch: 0144 train_loss= 0.44378 time= 0.00200\n",
      "Epoch: 0145 train_loss= 0.43427 time= 0.00200\n",
      "Epoch: 0146 train_loss= 0.43288 time= 0.00302\n",
      "Epoch: 0147 train_loss= 0.43152 time= 0.00298\n",
      "Epoch: 0148 train_loss= 0.43460 time= 0.00300\n",
      "Epoch: 0149 train_loss= 0.43567 time= 0.00300\n",
      "Epoch: 0150 train_loss= 0.43368 time= 0.00300\n",
      "Epoch: 0151 train_loss= 0.42749 time= 0.00302\n",
      "Epoch: 0152 train_loss= 0.43524 time= 0.00298\n",
      "Epoch: 0153 train_loss= 0.43306 time= 0.00200\n",
      "Epoch: 0154 train_loss= 0.43308 time= 0.00200\n",
      "Epoch: 0155 train_loss= 0.43292 time= 0.00300\n",
      "Epoch: 0156 train_loss= 0.42879 time= 0.00239\n",
      "Epoch: 0157 train_loss= 0.43782 time= 0.00201\n",
      "Epoch: 0158 train_loss= 0.43349 time= 0.00301\n",
      "Epoch: 0159 train_loss= 0.43975 time= 0.00298\n",
      "Epoch: 0160 train_loss= 0.43009 time= 0.00300\n",
      "Epoch: 0161 train_loss= 0.43256 time= 0.00221\n",
      "Epoch: 0162 train_loss= 0.43128 time= 0.00344\n",
      "Epoch: 0163 train_loss= 0.43674 time= 0.00301\n",
      "Epoch: 0164 train_loss= 0.43632 time= 0.00298\n",
      "Epoch: 0165 train_loss= 0.43408 time= 0.00201\n",
      "Epoch: 0166 train_loss= 0.43040 time= 0.00299\n",
      "Epoch: 0167 train_loss= 0.42835 time= 0.00307\n",
      "Epoch: 0168 train_loss= 0.43261 time= 0.00292\n",
      "Epoch: 0169 train_loss= 0.43135 time= 0.00200\n",
      "Epoch: 0170 train_loss= 0.43079 time= 0.00200\n",
      "Epoch: 0171 train_loss= 0.43222 time= 0.00201\n",
      "Epoch: 0172 train_loss= 0.43104 time= 0.00300\n",
      "Epoch: 0173 train_loss= 0.42441 time= 0.00300\n",
      "Epoch: 0174 train_loss= 0.43058 time= 0.00300\n",
      "Epoch: 0175 train_loss= 0.43424 time= 0.00307\n",
      "Epoch: 0176 train_loss= 0.43331 time= 0.00300\n",
      "Epoch: 0177 train_loss= 0.43009 time= 0.00294\n",
      "Epoch: 0178 train_loss= 0.43316 time= 0.00300\n",
      "Epoch: 0179 train_loss= 0.42558 time= 0.00200\n",
      "Epoch: 0180 train_loss= 0.43027 time= 0.00301\n",
      "Epoch: 0181 train_loss= 0.43387 time= 0.00200\n",
      "Epoch: 0182 train_loss= 0.43002 time= 0.00187\n",
      "Epoch: 0183 train_loss= 0.42560 time= 0.00200\n",
      "Epoch: 0184 train_loss= 0.42812 time= 0.00200\n",
      "Epoch: 0185 train_loss= 0.42526 time= 0.00200\n",
      "Epoch: 0186 train_loss= 0.42888 time= 0.00200\n",
      "Epoch: 0187 train_loss= 0.42359 time= 0.00199\n",
      "Epoch: 0188 train_loss= 0.43593 time= 0.00200\n",
      "Epoch: 0189 train_loss= 0.43316 time= 0.00200\n",
      "Epoch: 0190 train_loss= 0.42853 time= 0.00200\n",
      "Epoch: 0191 train_loss= 0.42962 time= 0.00200\n",
      "Epoch: 0192 train_loss= 0.43259 time= 0.00201\n",
      "Epoch: 0193 train_loss= 0.42936 time= 0.00301\n",
      "Epoch: 0194 train_loss= 0.42881 time= 0.00309\n",
      "Epoch: 0195 train_loss= 0.43216 time= 0.00297\n",
      "Epoch: 0196 train_loss= 0.43579 time= 0.00304\n",
      "Epoch: 0197 train_loss= 0.42647 time= 0.00299\n",
      "Epoch: 0198 train_loss= 0.42772 time= 0.00303\n",
      "Epoch: 0199 train_loss= 0.43114 time= 0.00304\n",
      "Epoch: 0200 train_loss= 0.42770 time= 0.00303\n",
      "Testing model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.68699 time= 0.11588\n",
      "Epoch: 0002 train_loss= 1.28636 time= 0.00418\n",
      "Epoch: 0003 train_loss= 0.92472 time= 0.00434\n",
      "Epoch: 0004 train_loss= 0.73324 time= 0.00406\n",
      "Epoch: 0005 train_loss= 0.87455 time= 0.00495\n",
      "Epoch: 0006 train_loss= 0.80025 time= 0.00500\n",
      "Epoch: 0007 train_loss= 0.66475 time= 0.00300\n",
      "Epoch: 0008 train_loss= 0.61587 time= 0.00299\n",
      "Epoch: 0009 train_loss= 0.62519 time= 0.00400\n",
      "Epoch: 0010 train_loss= 0.64517 time= 0.00511\n",
      "Epoch: 0011 train_loss= 0.65781 time= 0.00289\n",
      "Epoch: 0012 train_loss= 0.63177 time= 0.00299\n",
      "Epoch: 0013 train_loss= 0.59374 time= 0.00408\n",
      "Epoch: 0014 train_loss= 0.56874 time= 0.00395\n",
      "Epoch: 0015 train_loss= 0.55329 time= 0.00309\n",
      "Epoch: 0016 train_loss= 0.54819 time= 0.00394\n",
      "Epoch: 0017 train_loss= 0.56310 time= 0.00399\n",
      "Epoch: 0018 train_loss= 0.55547 time= 0.00400\n",
      "Epoch: 0019 train_loss= 0.55606 time= 0.00400\n",
      "Epoch: 0020 train_loss= 0.54626 time= 0.00301\n",
      "Epoch: 0021 train_loss= 0.53303 time= 0.00400\n",
      "Epoch: 0022 train_loss= 0.52229 time= 0.00500\n",
      "Epoch: 0023 train_loss= 0.51909 time= 0.00500\n",
      "Epoch: 0024 train_loss= 0.52177 time= 0.00500\n",
      "Epoch: 0025 train_loss= 0.52568 time= 0.00400\n",
      "Epoch: 0026 train_loss= 0.50988 time= 0.00299\n",
      "Epoch: 0027 train_loss= 0.50856 time= 0.00400\n",
      "Epoch: 0028 train_loss= 0.49275 time= 0.00500\n",
      "Epoch: 0029 train_loss= 0.49263 time= 0.00301\n",
      "Epoch: 0030 train_loss= 0.49055 time= 0.00300\n",
      "Epoch: 0031 train_loss= 0.48224 time= 0.00400\n",
      "Epoch: 0032 train_loss= 0.48292 time= 0.00400\n",
      "Epoch: 0033 train_loss= 0.48522 time= 0.00300\n",
      "Epoch: 0034 train_loss= 0.47752 time= 0.00299\n",
      "Epoch: 0035 train_loss= 0.47799 time= 0.00300\n",
      "Epoch: 0036 train_loss= 0.48066 time= 0.00301\n",
      "Epoch: 0037 train_loss= 0.47438 time= 0.00399\n",
      "Epoch: 0038 train_loss= 0.47989 time= 0.00300\n",
      "Epoch: 0039 train_loss= 0.47755 time= 0.00300\n",
      "Epoch: 0040 train_loss= 0.46843 time= 0.00300\n",
      "Epoch: 0041 train_loss= 0.46945 time= 0.00400\n",
      "Epoch: 0042 train_loss= 0.46844 time= 0.00400\n",
      "Epoch: 0043 train_loss= 0.47049 time= 0.00300\n",
      "Epoch: 0044 train_loss= 0.47207 time= 0.00300\n",
      "Epoch: 0045 train_loss= 0.46602 time= 0.00300\n",
      "Epoch: 0046 train_loss= 0.46245 time= 0.00300\n",
      "Epoch: 0047 train_loss= 0.46713 time= 0.00400\n",
      "Epoch: 0048 train_loss= 0.46138 time= 0.00299\n",
      "Epoch: 0049 train_loss= 0.46448 time= 0.00400\n",
      "Epoch: 0050 train_loss= 0.45964 time= 0.00300\n",
      "Epoch: 0051 train_loss= 0.46085 time= 0.00301\n",
      "Epoch: 0052 train_loss= 0.45630 time= 0.00299\n",
      "Epoch: 0053 train_loss= 0.45525 time= 0.00400\n",
      "Epoch: 0054 train_loss= 0.45091 time= 0.00300\n",
      "Epoch: 0055 train_loss= 0.45974 time= 0.00400\n",
      "Epoch: 0056 train_loss= 0.45765 time= 0.00300\n",
      "Epoch: 0057 train_loss= 0.44843 time= 0.00400\n",
      "Epoch: 0058 train_loss= 0.45208 time= 0.00400\n",
      "Epoch: 0059 train_loss= 0.45218 time= 0.00300\n",
      "Epoch: 0060 train_loss= 0.45897 time= 0.00400\n",
      "Epoch: 0061 train_loss= 0.44743 time= 0.00400\n",
      "Epoch: 0062 train_loss= 0.44599 time= 0.00301\n",
      "Epoch: 0063 train_loss= 0.45429 time= 0.00399\n",
      "Epoch: 0064 train_loss= 0.44616 time= 0.00402\n",
      "Epoch: 0065 train_loss= 0.44619 time= 0.00298\n",
      "Epoch: 0066 train_loss= 0.45189 time= 0.00300\n",
      "Epoch: 0067 train_loss= 0.44833 time= 0.00344\n",
      "Epoch: 0068 train_loss= 0.46101 time= 0.00256\n",
      "Epoch: 0069 train_loss= 0.45080 time= 0.00400\n",
      "Epoch: 0070 train_loss= 0.45152 time= 0.00300\n",
      "Epoch: 0071 train_loss= 0.44660 time= 0.00300\n",
      "Epoch: 0072 train_loss= 0.44337 time= 0.00200\n",
      "Epoch: 0073 train_loss= 0.45160 time= 0.00400\n",
      "Epoch: 0074 train_loss= 0.44110 time= 0.00301\n",
      "Epoch: 0075 train_loss= 0.44461 time= 0.00300\n",
      "Epoch: 0076 train_loss= 0.44815 time= 0.00300\n",
      "Epoch: 0077 train_loss= 0.44950 time= 0.00323\n",
      "Epoch: 0078 train_loss= 0.44722 time= 0.00277\n",
      "Epoch: 0079 train_loss= 0.44326 time= 0.00401\n",
      "Epoch: 0080 train_loss= 0.44921 time= 0.00299\n",
      "Epoch: 0081 train_loss= 0.44319 time= 0.00300\n",
      "Epoch: 0082 train_loss= 0.45039 time= 0.00299\n",
      "Epoch: 0083 train_loss= 0.44380 time= 0.00302\n",
      "Epoch: 0084 train_loss= 0.44033 time= 0.00299\n",
      "Epoch: 0085 train_loss= 0.43938 time= 0.00300\n",
      "Epoch: 0086 train_loss= 0.44013 time= 0.00301\n",
      "Epoch: 0087 train_loss= 0.44699 time= 0.00298\n",
      "Epoch: 0088 train_loss= 0.43895 time= 0.00201\n",
      "Epoch: 0089 train_loss= 0.43912 time= 0.00399\n",
      "Epoch: 0090 train_loss= 0.44352 time= 0.00301\n",
      "Epoch: 0091 train_loss= 0.44215 time= 0.00300\n",
      "Epoch: 0092 train_loss= 0.43762 time= 0.00300\n",
      "Epoch: 0093 train_loss= 0.44014 time= 0.00201\n",
      "Epoch: 0094 train_loss= 0.43461 time= 0.00309\n",
      "Epoch: 0095 train_loss= 0.43895 time= 0.00292\n",
      "Epoch: 0096 train_loss= 0.43803 time= 0.00301\n",
      "Epoch: 0097 train_loss= 0.44007 time= 0.00302\n",
      "Epoch: 0098 train_loss= 0.44102 time= 0.00402\n",
      "Epoch: 0099 train_loss= 0.43838 time= 0.00299\n",
      "Epoch: 0100 train_loss= 0.43869 time= 0.00308\n",
      "Epoch: 0101 train_loss= 0.44778 time= 0.00297\n",
      "Epoch: 0102 train_loss= 0.43638 time= 0.00305\n",
      "Epoch: 0103 train_loss= 0.44184 time= 0.00438\n",
      "Epoch: 0104 train_loss= 0.43611 time= 0.00357\n",
      "Epoch: 0105 train_loss= 0.44346 time= 0.00299\n",
      "Epoch: 0106 train_loss= 0.44264 time= 0.00302\n",
      "Epoch: 0107 train_loss= 0.44012 time= 0.00302\n",
      "Epoch: 0108 train_loss= 0.43612 time= 0.00403\n",
      "Epoch: 0109 train_loss= 0.43694 time= 0.00393\n",
      "Epoch: 0110 train_loss= 0.45044 time= 0.00416\n",
      "Epoch: 0111 train_loss= 0.43861 time= 0.00287\n",
      "Epoch: 0112 train_loss= 0.43709 time= 0.00401\n",
      "Epoch: 0113 train_loss= 0.43733 time= 0.00507\n",
      "Epoch: 0114 train_loss= 0.43558 time= 0.00293\n",
      "Epoch: 0115 train_loss= 0.43901 time= 0.00302\n",
      "Epoch: 0116 train_loss= 0.43553 time= 0.00402\n",
      "Epoch: 0117 train_loss= 0.43675 time= 0.00504\n",
      "Epoch: 0118 train_loss= 0.43887 time= 0.00396\n",
      "Epoch: 0119 train_loss= 0.43966 time= 0.00296\n",
      "Epoch: 0120 train_loss= 0.43907 time= 0.00405\n",
      "Epoch: 0121 train_loss= 0.43675 time= 0.00304\n",
      "Epoch: 0122 train_loss= 0.43062 time= 0.00306\n",
      "Epoch: 0123 train_loss= 0.43672 time= 0.00301\n",
      "Epoch: 0124 train_loss= 0.43139 time= 0.00301\n",
      "Epoch: 0125 train_loss= 0.43087 time= 0.00406\n",
      "Epoch: 0126 train_loss= 0.43940 time= 0.00406\n",
      "Epoch: 0127 train_loss= 0.43302 time= 0.00308\n",
      "Epoch: 0128 train_loss= 0.44574 time= 0.00397\n",
      "Epoch: 0129 train_loss= 0.44030 time= 0.00394\n",
      "Epoch: 0130 train_loss= 0.43749 time= 0.00401\n",
      "Epoch: 0131 train_loss= 0.43012 time= 0.00303\n",
      "Epoch: 0132 train_loss= 0.44125 time= 0.00340\n",
      "Epoch: 0133 train_loss= 0.43374 time= 0.00447\n",
      "Epoch: 0134 train_loss= 0.42869 time= 0.00305\n",
      "Epoch: 0135 train_loss= 0.43021 time= 0.00295\n",
      "Epoch: 0136 train_loss= 0.43092 time= 0.00404\n",
      "Epoch: 0137 train_loss= 0.43464 time= 0.00197\n",
      "Epoch: 0138 train_loss= 0.43075 time= 0.00304\n",
      "Epoch: 0139 train_loss= 0.43512 time= 0.00447\n",
      "Epoch: 0140 train_loss= 0.43166 time= 0.00313\n",
      "Epoch: 0141 train_loss= 0.43863 time= 0.00306\n",
      "Epoch: 0142 train_loss= 0.44539 time= 0.00390\n",
      "Epoch: 0143 train_loss= 0.42945 time= 0.00310\n",
      "Epoch: 0144 train_loss= 0.43220 time= 0.00384\n",
      "Epoch: 0145 train_loss= 0.42854 time= 0.00452\n",
      "Epoch: 0146 train_loss= 0.42695 time= 0.00304\n",
      "Epoch: 0147 train_loss= 0.43092 time= 0.00308\n",
      "Epoch: 0148 train_loss= 0.44075 time= 0.00289\n",
      "Epoch: 0149 train_loss= 0.42737 time= 0.00506\n",
      "Epoch: 0150 train_loss= 0.43300 time= 0.00399\n",
      "Epoch: 0151 train_loss= 0.43711 time= 0.00397\n",
      "Epoch: 0152 train_loss= 0.43577 time= 0.00305\n",
      "Epoch: 0153 train_loss= 0.43342 time= 0.00297\n",
      "Epoch: 0154 train_loss= 0.43068 time= 0.00411\n",
      "Epoch: 0155 train_loss= 0.43784 time= 0.00287\n",
      "Epoch: 0156 train_loss= 0.42757 time= 0.00308\n",
      "Epoch: 0157 train_loss= 0.42988 time= 0.00302\n",
      "Epoch: 0158 train_loss= 0.43181 time= 0.00299\n",
      "Epoch: 0159 train_loss= 0.42898 time= 0.00306\n",
      "Epoch: 0160 train_loss= 0.43435 time= 0.00298\n",
      "Epoch: 0161 train_loss= 0.42681 time= 0.00201\n",
      "Epoch: 0162 train_loss= 0.43515 time= 0.00305\n",
      "Epoch: 0163 train_loss= 0.43415 time= 0.00299\n",
      "Epoch: 0164 train_loss= 0.43088 time= 0.00396\n",
      "Epoch: 0165 train_loss= 0.43263 time= 0.00310\n",
      "Epoch: 0166 train_loss= 0.42981 time= 0.00196\n",
      "Epoch: 0167 train_loss= 0.43246 time= 0.00301\n",
      "Epoch: 0168 train_loss= 0.43063 time= 0.00306\n",
      "Epoch: 0169 train_loss= 0.43042 time= 0.00298\n",
      "Epoch: 0170 train_loss= 0.42960 time= 0.00294\n",
      "Epoch: 0171 train_loss= 0.42714 time= 0.00352\n",
      "Epoch: 0172 train_loss= 0.42914 time= 0.00246\n",
      "Epoch: 0173 train_loss= 0.43151 time= 0.00306\n",
      "Epoch: 0174 train_loss= 0.42639 time= 0.00197\n",
      "Epoch: 0175 train_loss= 0.42966 time= 0.00305\n",
      "Epoch: 0176 train_loss= 0.42641 time= 0.00324\n",
      "Epoch: 0177 train_loss= 0.43324 time= 0.00278\n",
      "Epoch: 0178 train_loss= 0.42899 time= 0.00297\n",
      "Epoch: 0179 train_loss= 0.43619 time= 0.00301\n",
      "Epoch: 0180 train_loss= 0.42710 time= 0.00300\n",
      "Epoch: 0181 train_loss= 0.42920 time= 0.00303\n",
      "Epoch: 0182 train_loss= 0.42638 time= 0.00348\n",
      "Epoch: 0183 train_loss= 0.42302 time= 0.00316\n",
      "Epoch: 0184 train_loss= 0.42743 time= 0.00305\n",
      "Epoch: 0185 train_loss= 0.43368 time= 0.00291\n",
      "Epoch: 0186 train_loss= 0.42296 time= 0.00399\n",
      "Epoch: 0187 train_loss= 0.42490 time= 0.00300\n",
      "Epoch: 0188 train_loss= 0.42458 time= 0.00305\n",
      "Epoch: 0189 train_loss= 0.42572 time= 0.00295\n",
      "Epoch: 0190 train_loss= 0.42404 time= 0.00308\n",
      "Epoch: 0191 train_loss= 0.42752 time= 0.00291\n",
      "Epoch: 0192 train_loss= 0.42655 time= 0.00402\n",
      "Epoch: 0193 train_loss= 0.42295 time= 0.00341\n",
      "Epoch: 0194 train_loss= 0.42190 time= 0.00400\n",
      "Epoch: 0195 train_loss= 0.42429 time= 0.00301\n",
      "Epoch: 0196 train_loss= 0.42902 time= 0.00300\n",
      "Epoch: 0197 train_loss= 0.42195 time= 0.00400\n",
      "Epoch: 0198 train_loss= 0.42328 time= 0.00304\n",
      "Epoch: 0199 train_loss= 0.41952 time= 0.00305\n",
      "Epoch: 0200 train_loss= 0.42221 time= 0.00309\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch: 0001 train_loss= 1.51760 time= 0.12460\n",
      "Epoch: 0002 train_loss= 1.41377 time= 0.00300\n",
      "Epoch: 0003 train_loss= 1.16447 time= 0.00400\n",
      "Epoch: 0004 train_loss= 0.87641 time= 0.00318\n",
      "Epoch: 0005 train_loss= 0.78936 time= 0.00305\n",
      "Epoch: 0006 train_loss= 0.85485 time= 0.00399\n",
      "Epoch: 0007 train_loss= 0.76617 time= 0.00299\n",
      "Epoch: 0008 train_loss= 0.66507 time= 0.00308\n",
      "Epoch: 0009 train_loss= 0.60615 time= 0.00299\n",
      "Epoch: 0010 train_loss= 0.60866 time= 0.00310\n",
      "Epoch: 0011 train_loss= 0.63247 time= 0.00397\n",
      "Epoch: 0012 train_loss= 0.64178 time= 0.00293\n",
      "Epoch: 0013 train_loss= 0.63672 time= 0.00454\n",
      "Epoch: 0014 train_loss= 0.61438 time= 0.00251\n",
      "Epoch: 0015 train_loss= 0.58048 time= 0.00295\n",
      "Epoch: 0016 train_loss= 0.56864 time= 0.00295\n",
      "Epoch: 0017 train_loss= 0.55019 time= 0.00411\n",
      "Epoch: 0018 train_loss= 0.54895 time= 0.00294\n",
      "Epoch: 0019 train_loss= 0.55216 time= 0.00304\n",
      "Epoch: 0020 train_loss= 0.54323 time= 0.00402\n",
      "Epoch: 0021 train_loss= 0.53919 time= 0.00293\n",
      "Epoch: 0022 train_loss= 0.52861 time= 0.00303\n",
      "Epoch: 0023 train_loss= 0.51567 time= 0.00298\n",
      "Epoch: 0024 train_loss= 0.51720 time= 0.00200\n",
      "Epoch: 0025 train_loss= 0.50895 time= 0.00300\n",
      "Epoch: 0026 train_loss= 0.50790 time= 0.00300\n",
      "Epoch: 0027 train_loss= 0.51481 time= 0.00309\n",
      "Epoch: 0028 train_loss= 0.50648 time= 0.00299\n",
      "Epoch: 0029 train_loss= 0.51152 time= 0.00427\n",
      "Epoch: 0030 train_loss= 0.49289 time= 0.00271\n",
      "Epoch: 0031 train_loss= 0.50433 time= 0.00402\n",
      "Epoch: 0032 train_loss= 0.50321 time= 0.00299\n",
      "Epoch: 0033 train_loss= 0.50382 time= 0.00393\n",
      "Epoch: 0034 train_loss= 0.48879 time= 0.00306\n",
      "Epoch: 0035 train_loss= 0.48597 time= 0.00294\n",
      "Epoch: 0036 train_loss= 0.48545 time= 0.00200\n",
      "Epoch: 0037 train_loss= 0.48621 time= 0.00306\n",
      "Epoch: 0038 train_loss= 0.49295 time= 0.00207\n",
      "Epoch: 0039 train_loss= 0.47542 time= 0.00294\n",
      "Epoch: 0040 train_loss= 0.48329 time= 0.00306\n",
      "Epoch: 0041 train_loss= 0.47757 time= 0.00297\n",
      "Epoch: 0042 train_loss= 0.48279 time= 0.00304\n",
      "Epoch: 0043 train_loss= 0.47925 time= 0.00299\n",
      "Epoch: 0044 train_loss= 0.47324 time= 0.00325\n",
      "Epoch: 0045 train_loss= 0.47121 time= 0.00467\n",
      "Epoch: 0046 train_loss= 0.47542 time= 0.00306\n",
      "Epoch: 0047 train_loss= 0.47641 time= 0.00301\n",
      "Epoch: 0048 train_loss= 0.46709 time= 0.00293\n",
      "Epoch: 0049 train_loss= 0.46503 time= 0.00307\n",
      "Epoch: 0050 train_loss= 0.47390 time= 0.00200\n",
      "Epoch: 0051 train_loss= 0.46208 time= 0.00303\n",
      "Epoch: 0052 train_loss= 0.46726 time= 0.00302\n",
      "Epoch: 0053 train_loss= 0.46240 time= 0.00300\n",
      "Epoch: 0054 train_loss= 0.47467 time= 0.00307\n",
      "Epoch: 0055 train_loss= 0.45982 time= 0.00295\n",
      "Epoch: 0056 train_loss= 0.45356 time= 0.00305\n",
      "Epoch: 0057 train_loss= 0.46531 time= 0.00195\n",
      "Epoch: 0058 train_loss= 0.45413 time= 0.00205\n",
      "Epoch: 0059 train_loss= 0.46384 time= 0.00305\n",
      "Epoch: 0060 train_loss= 0.45151 time= 0.00302\n",
      "Epoch: 0061 train_loss= 0.46130 time= 0.00196\n",
      "Epoch: 0062 train_loss= 0.45732 time= 0.00209\n",
      "Epoch: 0063 train_loss= 0.45820 time= 0.00304\n",
      "Epoch: 0064 train_loss= 0.45584 time= 0.00296\n",
      "Epoch: 0065 train_loss= 0.45634 time= 0.00306\n",
      "Epoch: 0066 train_loss= 0.45804 time= 0.00302\n",
      "Epoch: 0067 train_loss= 0.45810 time= 0.00298\n",
      "Epoch: 0068 train_loss= 0.45784 time= 0.00306\n",
      "Epoch: 0069 train_loss= 0.45236 time= 0.00205\n",
      "Epoch: 0070 train_loss= 0.45196 time= 0.00201\n",
      "Epoch: 0071 train_loss= 0.44883 time= 0.00300\n",
      "Epoch: 0072 train_loss= 0.46041 time= 0.00303\n",
      "Epoch: 0073 train_loss= 0.45677 time= 0.00298\n",
      "Epoch: 0074 train_loss= 0.45116 time= 0.00306\n",
      "Epoch: 0075 train_loss= 0.45113 time= 0.00296\n",
      "Epoch: 0076 train_loss= 0.45051 time= 0.00404\n",
      "Epoch: 0077 train_loss= 0.44603 time= 0.00297\n",
      "Epoch: 0078 train_loss= 0.44734 time= 0.00302\n",
      "Epoch: 0079 train_loss= 0.46192 time= 0.00297\n",
      "Epoch: 0080 train_loss= 0.45567 time= 0.00306\n",
      "Epoch: 0081 train_loss= 0.44554 time= 0.00389\n",
      "Epoch: 0082 train_loss= 0.45393 time= 0.00310\n",
      "Epoch: 0083 train_loss= 0.45774 time= 0.00304\n",
      "Epoch: 0084 train_loss= 0.45356 time= 0.00400\n",
      "Epoch: 0085 train_loss= 0.44835 time= 0.00313\n",
      "Epoch: 0086 train_loss= 0.45321 time= 0.00451\n",
      "Epoch: 0087 train_loss= 0.45339 time= 0.00233\n",
      "Epoch: 0088 train_loss= 0.44570 time= 0.00199\n",
      "Epoch: 0089 train_loss= 0.45587 time= 0.00304\n",
      "Epoch: 0090 train_loss= 0.44503 time= 0.00296\n",
      "Epoch: 0091 train_loss= 0.45447 time= 0.00310\n",
      "Epoch: 0092 train_loss= 0.45219 time= 0.00318\n",
      "Epoch: 0093 train_loss= 0.44993 time= 0.00303\n",
      "Epoch: 0094 train_loss= 0.44697 time= 0.00397\n",
      "Epoch: 0095 train_loss= 0.44998 time= 0.00307\n",
      "Epoch: 0096 train_loss= 0.45105 time= 0.00396\n",
      "Epoch: 0097 train_loss= 0.44825 time= 0.00302\n",
      "Epoch: 0098 train_loss= 0.44604 time= 0.00307\n",
      "Epoch: 0099 train_loss= 0.44413 time= 0.00302\n",
      "Epoch: 0100 train_loss= 0.44461 time= 0.00425\n",
      "Epoch: 0101 train_loss= 0.44392 time= 0.00304\n",
      "Epoch: 0102 train_loss= 0.44105 time= 0.00412\n",
      "Epoch: 0103 train_loss= 0.44741 time= 0.00295\n",
      "Epoch: 0104 train_loss= 0.44857 time= 0.00199\n",
      "Epoch: 0105 train_loss= 0.44321 time= 0.00306\n",
      "Epoch: 0106 train_loss= 0.45326 time= 0.00300\n",
      "Epoch: 0107 train_loss= 0.44996 time= 0.00306\n",
      "Epoch: 0108 train_loss= 0.44149 time= 0.00413\n",
      "Epoch: 0109 train_loss= 0.45425 time= 0.00400\n",
      "Epoch: 0110 train_loss= 0.44310 time= 0.00298\n",
      "Epoch: 0111 train_loss= 0.44610 time= 0.00294\n",
      "Epoch: 0112 train_loss= 0.44466 time= 0.00318\n",
      "Epoch: 0113 train_loss= 0.44856 time= 0.00311\n",
      "Epoch: 0114 train_loss= 0.44141 time= 0.00197\n",
      "Epoch: 0115 train_loss= 0.44027 time= 0.00405\n",
      "Epoch: 0116 train_loss= 0.44556 time= 0.00318\n",
      "Epoch: 0117 train_loss= 0.44530 time= 0.00306\n",
      "Epoch: 0118 train_loss= 0.44731 time= 0.00303\n",
      "Epoch: 0119 train_loss= 0.44284 time= 0.00300\n",
      "Epoch: 0120 train_loss= 0.44531 time= 0.00406\n",
      "Epoch: 0121 train_loss= 0.43911 time= 0.00399\n",
      "Epoch: 0122 train_loss= 0.43700 time= 0.00344\n",
      "Epoch: 0123 train_loss= 0.44247 time= 0.00300\n",
      "Epoch: 0124 train_loss= 0.44945 time= 0.00305\n",
      "Epoch: 0125 train_loss= 0.45330 time= 0.00301\n",
      "Epoch: 0126 train_loss= 0.43801 time= 0.00315\n",
      "Epoch: 0127 train_loss= 0.45745 time= 0.00304\n",
      "Epoch: 0128 train_loss= 0.44222 time= 0.00400\n",
      "Epoch: 0129 train_loss= 0.45311 time= 0.00296\n",
      "Epoch: 0130 train_loss= 0.44070 time= 0.00404\n",
      "Epoch: 0131 train_loss= 0.45041 time= 0.00306\n",
      "Epoch: 0132 train_loss= 0.44629 time= 0.00292\n",
      "Epoch: 0133 train_loss= 0.44281 time= 0.00411\n",
      "Epoch: 0134 train_loss= 0.44741 time= 0.00286\n",
      "Epoch: 0135 train_loss= 0.44149 time= 0.00402\n",
      "Epoch: 0136 train_loss= 0.44021 time= 0.00295\n",
      "Epoch: 0137 train_loss= 0.44605 time= 0.00304\n",
      "Epoch: 0138 train_loss= 0.43979 time= 0.00405\n",
      "Epoch: 0139 train_loss= 0.43935 time= 0.00453\n",
      "Epoch: 0140 train_loss= 0.45036 time= 0.00438\n",
      "Epoch: 0141 train_loss= 0.43933 time= 0.00310\n",
      "Epoch: 0142 train_loss= 0.44089 time= 0.00335\n",
      "Epoch: 0143 train_loss= 0.44245 time= 0.00351\n",
      "Epoch: 0144 train_loss= 0.43925 time= 0.00300\n",
      "Epoch: 0145 train_loss= 0.43548 time= 0.00307\n",
      "Epoch: 0146 train_loss= 0.43456 time= 0.00345\n",
      "Epoch: 0147 train_loss= 0.44348 time= 0.00304\n",
      "Epoch: 0148 train_loss= 0.43935 time= 0.00330\n",
      "Epoch: 0149 train_loss= 0.43951 time= 0.00309\n",
      "Epoch: 0150 train_loss= 0.43247 time= 0.00300\n",
      "Epoch: 0151 train_loss= 0.44113 time= 0.00301\n",
      "Epoch: 0152 train_loss= 0.44207 time= 0.00399\n",
      "Epoch: 0153 train_loss= 0.43999 time= 0.00344\n",
      "Epoch: 0154 train_loss= 0.43868 time= 0.00294\n",
      "Epoch: 0155 train_loss= 0.43928 time= 0.00305\n",
      "Epoch: 0156 train_loss= 0.43772 time= 0.00347\n",
      "Epoch: 0157 train_loss= 0.43861 time= 0.00405\n",
      "Epoch: 0158 train_loss= 0.43248 time= 0.00406\n",
      "Epoch: 0159 train_loss= 0.43170 time= 0.00305\n",
      "Epoch: 0160 train_loss= 0.43405 time= 0.00307\n",
      "Epoch: 0161 train_loss= 0.44050 time= 0.00306\n",
      "Epoch: 0162 train_loss= 0.43248 time= 0.00382\n",
      "Epoch: 0163 train_loss= 0.43061 time= 0.00199\n",
      "Epoch: 0164 train_loss= 0.43698 time= 0.00304\n",
      "Epoch: 0165 train_loss= 0.43814 time= 0.00398\n",
      "Epoch: 0166 train_loss= 0.43606 time= 0.00310\n",
      "Epoch: 0167 train_loss= 0.43753 time= 0.00305\n",
      "Epoch: 0168 train_loss= 0.43947 time= 0.00298\n",
      "Epoch: 0169 train_loss= 0.43077 time= 0.00303\n",
      "Epoch: 0170 train_loss= 0.43197 time= 0.00301\n",
      "Epoch: 0171 train_loss= 0.43262 time= 0.00299\n",
      "Epoch: 0172 train_loss= 0.43098 time= 0.00403\n",
      "Epoch: 0173 train_loss= 0.43698 time= 0.00427\n",
      "Epoch: 0174 train_loss= 0.43049 time= 0.00430\n",
      "Epoch: 0175 train_loss= 0.43470 time= 0.00383\n",
      "Epoch: 0176 train_loss= 0.43086 time= 0.00292\n",
      "Epoch: 0177 train_loss= 0.43041 time= 0.00300\n",
      "Epoch: 0178 train_loss= 0.43221 time= 0.00303\n",
      "Epoch: 0179 train_loss= 0.43291 time= 0.00434\n",
      "Epoch: 0180 train_loss= 0.43331 time= 0.00261\n",
      "Epoch: 0181 train_loss= 0.42924 time= 0.00397\n",
      "Epoch: 0182 train_loss= 0.44067 time= 0.00317\n",
      "Epoch: 0183 train_loss= 0.44560 time= 0.00201\n",
      "Epoch: 0184 train_loss= 0.43307 time= 0.00200\n",
      "Epoch: 0185 train_loss= 0.43383 time= 0.00335\n",
      "Epoch: 0186 train_loss= 0.43242 time= 0.00309\n",
      "Epoch: 0187 train_loss= 0.43313 time= 0.00301\n",
      "Epoch: 0188 train_loss= 0.43004 time= 0.00317\n",
      "Epoch: 0189 train_loss= 0.43723 time= 0.00299\n",
      "Epoch: 0190 train_loss= 0.43518 time= 0.00406\n",
      "Epoch: 0191 train_loss= 0.42829 time= 0.00300\n",
      "Epoch: 0192 train_loss= 0.43063 time= 0.00300\n",
      "Epoch: 0193 train_loss= 0.42727 time= 0.00298\n",
      "Epoch: 0194 train_loss= 0.43286 time= 0.00303\n",
      "Epoch: 0195 train_loss= 0.42929 time= 0.00399\n",
      "Epoch: 0196 train_loss= 0.43718 time= 0.00307\n",
      "Epoch: 0197 train_loss= 0.43368 time= 0.00290\n",
      "Epoch: 0198 train_loss= 0.43532 time= 0.00304\n",
      "Epoch: 0199 train_loss= 0.42798 time= 0.00302\n",
      "Epoch: 0200 train_loss= 0.42712 time= 0.00309\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch: 0001 train_loss= 1.62947 time= 0.12710\n",
      "Epoch: 0002 train_loss= 1.29253 time= 0.00301\n",
      "Epoch: 0003 train_loss= 1.06365 time= 0.00305\n",
      "Epoch: 0004 train_loss= 0.75374 time= 0.00297\n",
      "Epoch: 0005 train_loss= 0.84632 time= 0.00399\n",
      "Epoch: 0006 train_loss= 0.84061 time= 0.00404\n",
      "Epoch: 0007 train_loss= 0.71546 time= 0.00296\n",
      "Epoch: 0008 train_loss= 0.62641 time= 0.00400\n",
      "Epoch: 0009 train_loss= 0.63635 time= 0.00409\n",
      "Epoch: 0010 train_loss= 0.64532 time= 0.00295\n",
      "Epoch: 0011 train_loss= 0.65795 time= 0.00403\n",
      "Epoch: 0012 train_loss= 0.65293 time= 0.00398\n",
      "Epoch: 0013 train_loss= 0.61341 time= 0.00304\n",
      "Epoch: 0014 train_loss= 0.59269 time= 0.00295\n",
      "Epoch: 0015 train_loss= 0.57388 time= 0.00506\n",
      "Epoch: 0016 train_loss= 0.56820 time= 0.00397\n",
      "Epoch: 0017 train_loss= 0.56219 time= 0.00304\n",
      "Epoch: 0018 train_loss= 0.56684 time= 0.00406\n",
      "Epoch: 0019 train_loss= 0.55965 time= 0.00395\n",
      "Epoch: 0020 train_loss= 0.54398 time= 0.00306\n",
      "Epoch: 0021 train_loss= 0.54279 time= 0.00300\n",
      "Epoch: 0022 train_loss= 0.53064 time= 0.00296\n",
      "Epoch: 0023 train_loss= 0.52988 time= 0.00305\n",
      "Epoch: 0024 train_loss= 0.53295 time= 0.00400\n",
      "Epoch: 0025 train_loss= 0.52195 time= 0.00302\n",
      "Epoch: 0026 train_loss= 0.52029 time= 0.00436\n",
      "Epoch: 0027 train_loss= 0.52244 time= 0.00373\n",
      "Epoch: 0028 train_loss= 0.50695 time= 0.00388\n",
      "Epoch: 0029 train_loss= 0.50955 time= 0.00293\n",
      "Epoch: 0030 train_loss= 0.50042 time= 0.00301\n",
      "Epoch: 0031 train_loss= 0.49620 time= 0.00311\n",
      "Epoch: 0032 train_loss= 0.49463 time= 0.00410\n",
      "Epoch: 0033 train_loss= 0.49320 time= 0.00296\n",
      "Epoch: 0034 train_loss= 0.48899 time= 0.00308\n",
      "Epoch: 0035 train_loss= 0.49132 time= 0.00296\n",
      "Epoch: 0036 train_loss= 0.48023 time= 0.00312\n",
      "Epoch: 0037 train_loss= 0.48529 time= 0.00394\n",
      "Epoch: 0038 train_loss= 0.47504 time= 0.00393\n",
      "Epoch: 0039 train_loss= 0.47765 time= 0.00305\n",
      "Epoch: 0040 train_loss= 0.47752 time= 0.00495\n",
      "Epoch: 0041 train_loss= 0.47528 time= 0.00308\n",
      "Epoch: 0042 train_loss= 0.48178 time= 0.00305\n",
      "Epoch: 0043 train_loss= 0.47287 time= 0.00301\n",
      "Epoch: 0044 train_loss= 0.47267 time= 0.00304\n",
      "Epoch: 0045 train_loss= 0.46951 time= 0.00307\n",
      "Epoch: 0046 train_loss= 0.47097 time= 0.00500\n",
      "Epoch: 0047 train_loss= 0.46509 time= 0.00289\n",
      "Epoch: 0048 train_loss= 0.47189 time= 0.00300\n",
      "Epoch: 0049 train_loss= 0.47478 time= 0.00300\n",
      "Epoch: 0050 train_loss= 0.45970 time= 0.00407\n",
      "Epoch: 0051 train_loss= 0.47481 time= 0.00301\n",
      "Epoch: 0052 train_loss= 0.46301 time= 0.00391\n",
      "Epoch: 0053 train_loss= 0.45948 time= 0.00310\n",
      "Epoch: 0054 train_loss= 0.45995 time= 0.00295\n",
      "Epoch: 0055 train_loss= 0.45996 time= 0.00500\n",
      "Epoch: 0056 train_loss= 0.45828 time= 0.00504\n",
      "Epoch: 0057 train_loss= 0.46450 time= 0.00400\n",
      "Epoch: 0058 train_loss= 0.45783 time= 0.00397\n",
      "Epoch: 0059 train_loss= 0.46149 time= 0.00300\n",
      "Epoch: 0060 train_loss= 0.46786 time= 0.00295\n",
      "Epoch: 0061 train_loss= 0.45323 time= 0.00307\n",
      "Epoch: 0062 train_loss= 0.46307 time= 0.00394\n",
      "Epoch: 0063 train_loss= 0.45572 time= 0.00315\n",
      "Epoch: 0064 train_loss= 0.46667 time= 0.00293\n",
      "Epoch: 0065 train_loss= 0.46074 time= 0.00292\n",
      "Epoch: 0066 train_loss= 0.45746 time= 0.00304\n",
      "Epoch: 0067 train_loss= 0.45447 time= 0.00403\n",
      "Epoch: 0068 train_loss= 0.45846 time= 0.00397\n",
      "Epoch: 0069 train_loss= 0.44959 time= 0.00400\n",
      "Epoch: 0070 train_loss= 0.46114 time= 0.00300\n",
      "Epoch: 0071 train_loss= 0.45476 time= 0.00301\n",
      "Epoch: 0072 train_loss= 0.45841 time= 0.00394\n",
      "Epoch: 0073 train_loss= 0.44833 time= 0.00400\n",
      "Epoch: 0074 train_loss= 0.44762 time= 0.00301\n",
      "Epoch: 0075 train_loss= 0.45493 time= 0.00399\n",
      "Epoch: 0076 train_loss= 0.45102 time= 0.00308\n",
      "Epoch: 0077 train_loss= 0.45283 time= 0.00393\n",
      "Epoch: 0078 train_loss= 0.45034 time= 0.00314\n",
      "Epoch: 0079 train_loss= 0.45430 time= 0.00196\n",
      "Epoch: 0080 train_loss= 0.45013 time= 0.00200\n",
      "Epoch: 0081 train_loss= 0.45251 time= 0.00402\n",
      "Epoch: 0082 train_loss= 0.45428 time= 0.00401\n",
      "Epoch: 0083 train_loss= 0.45025 time= 0.00300\n",
      "Epoch: 0084 train_loss= 0.44622 time= 0.00293\n",
      "Epoch: 0085 train_loss= 0.45368 time= 0.00198\n",
      "Epoch: 0086 train_loss= 0.44930 time= 0.00608\n",
      "Epoch: 0087 train_loss= 0.44411 time= 0.00492\n",
      "Epoch: 0088 train_loss= 0.45138 time= 0.00306\n",
      "Epoch: 0089 train_loss= 0.44779 time= 0.00394\n",
      "Epoch: 0090 train_loss= 0.44746 time= 0.00405\n",
      "Epoch: 0091 train_loss= 0.45365 time= 0.00295\n",
      "Epoch: 0092 train_loss= 0.44449 time= 0.00302\n",
      "Epoch: 0093 train_loss= 0.44408 time= 0.00304\n",
      "Epoch: 0094 train_loss= 0.44734 time= 0.00434\n",
      "Epoch: 0095 train_loss= 0.44905 time= 0.00303\n",
      "Epoch: 0096 train_loss= 0.44290 time= 0.00398\n",
      "Epoch: 0097 train_loss= 0.44582 time= 0.00715\n",
      "Epoch: 0098 train_loss= 0.44323 time= 0.00358\n",
      "Epoch: 0099 train_loss= 0.44589 time= 0.00400\n",
      "Epoch: 0100 train_loss= 0.44086 time= 0.00300\n",
      "Epoch: 0101 train_loss= 0.44305 time= 0.00300\n",
      "Epoch: 0102 train_loss= 0.44419 time= 0.00399\n",
      "Epoch: 0103 train_loss= 0.44516 time= 0.00310\n",
      "Epoch: 0104 train_loss= 0.44571 time= 0.00297\n",
      "Epoch: 0105 train_loss= 0.44264 time= 0.00301\n",
      "Epoch: 0106 train_loss= 0.44242 time= 0.00311\n",
      "Epoch: 0107 train_loss= 0.44410 time= 0.00298\n",
      "Epoch: 0108 train_loss= 0.45080 time= 0.00391\n",
      "Epoch: 0109 train_loss= 0.44699 time= 0.00303\n",
      "Epoch: 0110 train_loss= 0.44893 time= 0.00305\n",
      "Epoch: 0111 train_loss= 0.45089 time= 0.00292\n",
      "Epoch: 0112 train_loss= 0.44493 time= 0.00408\n",
      "Epoch: 0113 train_loss= 0.44553 time= 0.00299\n",
      "Epoch: 0114 train_loss= 0.44801 time= 0.00194\n",
      "Epoch: 0115 train_loss= 0.44117 time= 0.00304\n",
      "Epoch: 0116 train_loss= 0.44711 time= 0.00297\n",
      "Epoch: 0117 train_loss= 0.44245 time= 0.00404\n",
      "Epoch: 0118 train_loss= 0.44596 time= 0.00301\n",
      "Epoch: 0119 train_loss= 0.44363 time= 0.00302\n",
      "Epoch: 0120 train_loss= 0.44405 time= 0.00297\n",
      "Epoch: 0121 train_loss= 0.43981 time= 0.00304\n",
      "Epoch: 0122 train_loss= 0.44456 time= 0.00292\n",
      "Epoch: 0123 train_loss= 0.44383 time= 0.00304\n",
      "Epoch: 0124 train_loss= 0.44226 time= 0.00399\n",
      "Epoch: 0125 train_loss= 0.43783 time= 0.00300\n",
      "Epoch: 0126 train_loss= 0.44730 time= 0.00296\n",
      "Epoch: 0127 train_loss= 0.44471 time= 0.00400\n",
      "Epoch: 0128 train_loss= 0.44879 time= 0.00309\n",
      "Epoch: 0129 train_loss= 0.44036 time= 0.00296\n",
      "Epoch: 0130 train_loss= 0.43719 time= 0.00414\n",
      "Epoch: 0131 train_loss= 0.44013 time= 0.00485\n",
      "Epoch: 0132 train_loss= 0.44148 time= 0.00397\n",
      "Epoch: 0133 train_loss= 0.43963 time= 0.00305\n",
      "Epoch: 0134 train_loss= 0.44185 time= 0.00305\n",
      "Epoch: 0135 train_loss= 0.44131 time= 0.00300\n",
      "Epoch: 0136 train_loss= 0.44153 time= 0.00300\n",
      "Epoch: 0137 train_loss= 0.43381 time= 0.00307\n",
      "Epoch: 0138 train_loss= 0.44238 time= 0.00299\n",
      "Epoch: 0139 train_loss= 0.43439 time= 0.00397\n",
      "Epoch: 0140 train_loss= 0.43387 time= 0.00304\n",
      "Epoch: 0141 train_loss= 0.43716 time= 0.00296\n",
      "Epoch: 0142 train_loss= 0.44877 time= 0.00399\n",
      "Epoch: 0143 train_loss= 0.44010 time= 0.00303\n",
      "Epoch: 0144 train_loss= 0.43606 time= 0.00404\n",
      "Epoch: 0145 train_loss= 0.43679 time= 0.00300\n",
      "Epoch: 0146 train_loss= 0.43577 time= 0.00501\n",
      "Epoch: 0147 train_loss= 0.43198 time= 0.00299\n",
      "Epoch: 0148 train_loss= 0.44140 time= 0.00298\n",
      "Epoch: 0149 train_loss= 0.43716 time= 0.00296\n",
      "Epoch: 0150 train_loss= 0.43880 time= 0.00207\n",
      "Epoch: 0151 train_loss= 0.43354 time= 0.00393\n",
      "Epoch: 0152 train_loss= 0.43951 time= 0.00304\n",
      "Epoch: 0153 train_loss= 0.43493 time= 0.00404\n",
      "Epoch: 0154 train_loss= 0.45579 time= 0.00366\n",
      "Epoch: 0155 train_loss= 0.43608 time= 0.00400\n",
      "Epoch: 0156 train_loss= 0.43507 time= 0.00303\n",
      "Epoch: 0157 train_loss= 0.43686 time= 0.00300\n",
      "Epoch: 0158 train_loss= 0.43169 time= 0.00304\n",
      "Epoch: 0159 train_loss= 0.44155 time= 0.00406\n",
      "Epoch: 0160 train_loss= 0.44149 time= 0.00299\n",
      "Epoch: 0161 train_loss= 0.44084 time= 0.00403\n",
      "Epoch: 0162 train_loss= 0.43622 time= 0.00298\n",
      "Epoch: 0163 train_loss= 0.44115 time= 0.00403\n",
      "Epoch: 0164 train_loss= 0.43114 time= 0.00306\n",
      "Epoch: 0165 train_loss= 0.44068 time= 0.00302\n",
      "Epoch: 0166 train_loss= 0.43599 time= 0.00293\n",
      "Epoch: 0167 train_loss= 0.43220 time= 0.00401\n",
      "Epoch: 0168 train_loss= 0.44281 time= 0.00399\n",
      "Epoch: 0169 train_loss= 0.43439 time= 0.00406\n",
      "Epoch: 0170 train_loss= 0.43760 time= 0.00299\n",
      "Epoch: 0171 train_loss= 0.43197 time= 0.00302\n",
      "Epoch: 0172 train_loss= 0.43434 time= 0.00302\n",
      "Epoch: 0173 train_loss= 0.43802 time= 0.00296\n",
      "Epoch: 0174 train_loss= 0.43609 time= 0.00301\n",
      "Epoch: 0175 train_loss= 0.43831 time= 0.00300\n",
      "Epoch: 0176 train_loss= 0.43334 time= 0.00306\n",
      "Epoch: 0177 train_loss= 0.43984 time= 0.00302\n",
      "Epoch: 0178 train_loss= 0.42968 time= 0.00304\n",
      "Epoch: 0179 train_loss= 0.43422 time= 0.00400\n",
      "Epoch: 0180 train_loss= 0.43608 time= 0.00296\n",
      "Epoch: 0181 train_loss= 0.44127 time= 0.00500\n",
      "Epoch: 0182 train_loss= 0.43777 time= 0.00300\n",
      "Epoch: 0183 train_loss= 0.43017 time= 0.00314\n",
      "Epoch: 0184 train_loss= 0.43649 time= 0.00491\n",
      "Epoch: 0185 train_loss= 0.43115 time= 0.00395\n",
      "Epoch: 0186 train_loss= 0.43226 time= 0.00291\n",
      "Epoch: 0187 train_loss= 0.43241 time= 0.00200\n",
      "Epoch: 0188 train_loss= 0.43467 time= 0.00401\n",
      "Epoch: 0189 train_loss= 0.43244 time= 0.00406\n",
      "Epoch: 0190 train_loss= 0.43608 time= 0.00499\n",
      "Epoch: 0191 train_loss= 0.43603 time= 0.00399\n",
      "Epoch: 0192 train_loss= 0.43141 time= 0.00304\n",
      "Epoch: 0193 train_loss= 0.43348 time= 0.00292\n",
      "Epoch: 0194 train_loss= 0.43214 time= 0.00407\n",
      "Epoch: 0195 train_loss= 0.43417 time= 0.00399\n",
      "Epoch: 0196 train_loss= 0.43037 time= 0.00303\n",
      "Epoch: 0197 train_loss= 0.43302 time= 0.00308\n",
      "Epoch: 0198 train_loss= 0.43388 time= 0.00310\n",
      "Epoch: 0199 train_loss= 0.43321 time= 0.00394\n",
      "Epoch: 0200 train_loss= 0.43294 time= 0.00302\n",
      "Testing model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.68340 time= 0.15049\n",
      "Epoch: 0002 train_loss= 1.33188 time= 0.00311\n",
      "Epoch: 0003 train_loss= 1.14847 time= 0.00309\n",
      "Epoch: 0004 train_loss= 0.77610 time= 0.00304\n",
      "Epoch: 0005 train_loss= 0.81364 time= 0.00503\n",
      "Epoch: 0006 train_loss= 0.83417 time= 0.00399\n",
      "Epoch: 0007 train_loss= 0.73340 time= 0.00394\n",
      "Epoch: 0008 train_loss= 0.63932 time= 0.00403\n",
      "Epoch: 0009 train_loss= 0.61766 time= 0.00402\n",
      "Epoch: 0010 train_loss= 0.63840 time= 0.00403\n",
      "Epoch: 0011 train_loss= 0.63934 time= 0.00393\n",
      "Epoch: 0012 train_loss= 0.65290 time= 0.00297\n",
      "Epoch: 0013 train_loss= 0.61936 time= 0.00303\n",
      "Epoch: 0014 train_loss= 0.60279 time= 0.00297\n",
      "Epoch: 0015 train_loss= 0.58342 time= 0.00299\n",
      "Epoch: 0016 train_loss= 0.56514 time= 0.00300\n",
      "Epoch: 0017 train_loss= 0.56220 time= 0.00405\n",
      "Epoch: 0018 train_loss= 0.56119 time= 0.00292\n",
      "Epoch: 0019 train_loss= 0.55972 time= 0.00348\n",
      "Epoch: 0020 train_loss= 0.55242 time= 0.00306\n",
      "Epoch: 0021 train_loss= 0.55299 time= 0.00302\n",
      "Epoch: 0022 train_loss= 0.53023 time= 0.00403\n",
      "Epoch: 0023 train_loss= 0.52108 time= 0.00296\n",
      "Epoch: 0024 train_loss= 0.51008 time= 0.00296\n",
      "Epoch: 0025 train_loss= 0.51457 time= 0.00405\n",
      "Epoch: 0026 train_loss= 0.52121 time= 0.00300\n",
      "Epoch: 0027 train_loss= 0.51501 time= 0.00400\n",
      "Epoch: 0028 train_loss= 0.52166 time= 0.00401\n",
      "Epoch: 0029 train_loss= 0.50179 time= 0.00303\n",
      "Epoch: 0030 train_loss= 0.49593 time= 0.00399\n",
      "Epoch: 0031 train_loss= 0.49183 time= 0.00308\n",
      "Epoch: 0032 train_loss= 0.49273 time= 0.00436\n",
      "Epoch: 0033 train_loss= 0.49677 time= 0.00360\n",
      "Epoch: 0034 train_loss= 0.49050 time= 0.00300\n",
      "Epoch: 0035 train_loss= 0.48540 time= 0.00401\n",
      "Epoch: 0036 train_loss= 0.48485 time= 0.00398\n",
      "Epoch: 0037 train_loss= 0.47600 time= 0.00297\n",
      "Epoch: 0038 train_loss= 0.48210 time= 0.00303\n",
      "Epoch: 0039 train_loss= 0.47734 time= 0.00400\n",
      "Epoch: 0040 train_loss= 0.47367 time= 0.00409\n",
      "Epoch: 0041 train_loss= 0.48230 time= 0.00392\n",
      "Epoch: 0042 train_loss= 0.47842 time= 0.00400\n",
      "Epoch: 0043 train_loss= 0.46983 time= 0.00413\n",
      "Epoch: 0044 train_loss= 0.47418 time= 0.00389\n",
      "Epoch: 0045 train_loss= 0.46903 time= 0.00499\n",
      "Epoch: 0046 train_loss= 0.47991 time= 0.00302\n",
      "Epoch: 0047 train_loss= 0.46567 time= 0.00494\n",
      "Epoch: 0048 train_loss= 0.46527 time= 0.00306\n",
      "Epoch: 0049 train_loss= 0.46557 time= 0.00294\n",
      "Epoch: 0050 train_loss= 0.47117 time= 0.00304\n",
      "Epoch: 0051 train_loss= 0.47212 time= 0.00400\n",
      "Epoch: 0052 train_loss= 0.46405 time= 0.00300\n",
      "Epoch: 0053 train_loss= 0.46307 time= 0.00405\n",
      "Epoch: 0054 train_loss= 0.46003 time= 0.00402\n",
      "Epoch: 0055 train_loss= 0.45949 time= 0.00397\n",
      "Epoch: 0056 train_loss= 0.45639 time= 0.00401\n",
      "Epoch: 0057 train_loss= 0.46497 time= 0.00399\n",
      "Epoch: 0058 train_loss= 0.46230 time= 0.00300\n",
      "Epoch: 0059 train_loss= 0.46472 time= 0.00296\n",
      "Epoch: 0060 train_loss= 0.46758 time= 0.00399\n",
      "Epoch: 0061 train_loss= 0.45518 time= 0.00400\n",
      "Epoch: 0062 train_loss= 0.45987 time= 0.00200\n",
      "Epoch: 0063 train_loss= 0.45197 time= 0.00304\n",
      "Epoch: 0064 train_loss= 0.46201 time= 0.00302\n",
      "Epoch: 0065 train_loss= 0.45281 time= 0.00494\n",
      "Epoch: 0066 train_loss= 0.45708 time= 0.00305\n",
      "Epoch: 0067 train_loss= 0.46301 time= 0.00403\n",
      "Epoch: 0068 train_loss= 0.46363 time= 0.00296\n",
      "Epoch: 0069 train_loss= 0.45759 time= 0.00304\n",
      "Epoch: 0070 train_loss= 0.45722 time= 0.00531\n",
      "Epoch: 0071 train_loss= 0.46187 time= 0.00298\n",
      "Epoch: 0072 train_loss= 0.46047 time= 0.00300\n",
      "Epoch: 0073 train_loss= 0.45613 time= 0.00403\n",
      "Epoch: 0074 train_loss= 0.46515 time= 0.00410\n",
      "Epoch: 0075 train_loss= 0.45926 time= 0.00287\n",
      "Epoch: 0076 train_loss= 0.45135 time= 0.00396\n",
      "Epoch: 0077 train_loss= 0.44956 time= 0.00305\n",
      "Epoch: 0078 train_loss= 0.45407 time= 0.00396\n",
      "Epoch: 0079 train_loss= 0.45085 time= 0.00405\n",
      "Epoch: 0080 train_loss= 0.45197 time= 0.00396\n",
      "Epoch: 0081 train_loss= 0.45264 time= 0.00299\n",
      "Epoch: 0082 train_loss= 0.45522 time= 0.00402\n",
      "Epoch: 0083 train_loss= 0.44737 time= 0.00297\n",
      "Epoch: 0084 train_loss= 0.45412 time= 0.00399\n",
      "Epoch: 0085 train_loss= 0.45036 time= 0.00295\n",
      "Epoch: 0086 train_loss= 0.45817 time= 0.00308\n",
      "Epoch: 0087 train_loss= 0.45227 time= 0.00407\n",
      "Epoch: 0088 train_loss= 0.45875 time= 0.00397\n",
      "Epoch: 0089 train_loss= 0.45200 time= 0.00400\n",
      "Epoch: 0090 train_loss= 0.45123 time= 0.00301\n",
      "Epoch: 0091 train_loss= 0.45227 time= 0.00304\n",
      "Epoch: 0092 train_loss= 0.44930 time= 0.00400\n",
      "Epoch: 0093 train_loss= 0.45340 time= 0.00307\n",
      "Epoch: 0094 train_loss= 0.44869 time= 0.00299\n",
      "Epoch: 0095 train_loss= 0.44340 time= 0.00307\n",
      "Epoch: 0096 train_loss= 0.44681 time= 0.00500\n",
      "Epoch: 0097 train_loss= 0.44695 time= 0.00294\n",
      "Epoch: 0098 train_loss= 0.45122 time= 0.00399\n",
      "Epoch: 0099 train_loss= 0.45244 time= 0.00400\n",
      "Epoch: 0100 train_loss= 0.44294 time= 0.00307\n",
      "Epoch: 0101 train_loss= 0.44474 time= 0.00302\n",
      "Epoch: 0102 train_loss= 0.45669 time= 0.00299\n",
      "Epoch: 0103 train_loss= 0.44474 time= 0.00195\n",
      "Epoch: 0104 train_loss= 0.44170 time= 0.00304\n",
      "Epoch: 0105 train_loss= 0.44154 time= 0.00506\n",
      "Epoch: 0106 train_loss= 0.44149 time= 0.00292\n",
      "Epoch: 0107 train_loss= 0.44277 time= 0.00302\n",
      "Epoch: 0108 train_loss= 0.44813 time= 0.00395\n",
      "Epoch: 0109 train_loss= 0.44299 time= 0.00305\n",
      "Epoch: 0110 train_loss= 0.44914 time= 0.00299\n",
      "Epoch: 0111 train_loss= 0.45385 time= 0.00403\n",
      "Epoch: 0112 train_loss= 0.45460 time= 0.00297\n",
      "Epoch: 0113 train_loss= 0.44406 time= 0.00403\n",
      "Epoch: 0114 train_loss= 0.44628 time= 0.00402\n",
      "Epoch: 0115 train_loss= 0.44255 time= 0.00292\n",
      "Epoch: 0116 train_loss= 0.43832 time= 0.00408\n",
      "Epoch: 0117 train_loss= 0.43484 time= 0.00305\n",
      "Epoch: 0118 train_loss= 0.43877 time= 0.00392\n",
      "Epoch: 0119 train_loss= 0.43956 time= 0.00295\n",
      "Epoch: 0120 train_loss= 0.44148 time= 0.00303\n",
      "Epoch: 0121 train_loss= 0.44744 time= 0.00302\n",
      "Epoch: 0122 train_loss= 0.44052 time= 0.00313\n",
      "Epoch: 0123 train_loss= 0.44140 time= 0.00302\n",
      "Epoch: 0124 train_loss= 0.43619 time= 0.00303\n",
      "Epoch: 0125 train_loss= 0.44544 time= 0.00299\n",
      "Epoch: 0126 train_loss= 0.44330 time= 0.00300\n",
      "Epoch: 0127 train_loss= 0.43824 time= 0.00292\n",
      "Epoch: 0128 train_loss= 0.43795 time= 0.00402\n",
      "Epoch: 0129 train_loss= 0.44164 time= 0.00397\n",
      "Epoch: 0130 train_loss= 0.44377 time= 0.00306\n",
      "Epoch: 0131 train_loss= 0.43480 time= 0.00201\n",
      "Epoch: 0132 train_loss= 0.43359 time= 0.00201\n",
      "Epoch: 0133 train_loss= 0.44070 time= 0.00344\n",
      "Epoch: 0134 train_loss= 0.43653 time= 0.00263\n",
      "Epoch: 0135 train_loss= 0.43540 time= 0.00305\n",
      "Epoch: 0136 train_loss= 0.43521 time= 0.00405\n",
      "Epoch: 0137 train_loss= 0.43807 time= 0.00306\n",
      "Epoch: 0138 train_loss= 0.43130 time= 0.00301\n",
      "Epoch: 0139 train_loss= 0.43714 time= 0.00291\n",
      "Epoch: 0140 train_loss= 0.43206 time= 0.00301\n",
      "Epoch: 0141 train_loss= 0.44087 time= 0.00301\n",
      "Epoch: 0142 train_loss= 0.42996 time= 0.00445\n",
      "Epoch: 0143 train_loss= 0.44006 time= 0.00196\n",
      "Epoch: 0144 train_loss= 0.45024 time= 0.00402\n",
      "Epoch: 0145 train_loss= 0.43653 time= 0.00398\n",
      "Epoch: 0146 train_loss= 0.43687 time= 0.00401\n",
      "Epoch: 0147 train_loss= 0.43596 time= 0.00300\n",
      "Epoch: 0148 train_loss= 0.43337 time= 0.00359\n",
      "Epoch: 0149 train_loss= 0.43317 time= 0.00237\n",
      "Epoch: 0150 train_loss= 0.43654 time= 0.00301\n",
      "Epoch: 0151 train_loss= 0.44476 time= 0.00402\n",
      "Epoch: 0152 train_loss= 0.43011 time= 0.00300\n",
      "Epoch: 0153 train_loss= 0.43722 time= 0.00304\n",
      "Epoch: 0154 train_loss= 0.43488 time= 0.00392\n",
      "Epoch: 0155 train_loss= 0.44135 time= 0.00301\n",
      "Epoch: 0156 train_loss= 0.43335 time= 0.00398\n",
      "Epoch: 0157 train_loss= 0.44206 time= 0.00509\n",
      "Epoch: 0158 train_loss= 0.43949 time= 0.00289\n",
      "Epoch: 0159 train_loss= 0.43427 time= 0.00304\n",
      "Epoch: 0160 train_loss= 0.43518 time= 0.00400\n",
      "Epoch: 0161 train_loss= 0.43794 time= 0.00309\n",
      "Epoch: 0162 train_loss= 0.43381 time= 0.00299\n",
      "Epoch: 0163 train_loss= 0.44141 time= 0.00297\n",
      "Epoch: 0164 train_loss= 0.43447 time= 0.00299\n",
      "Epoch: 0165 train_loss= 0.43595 time= 0.00400\n",
      "Epoch: 0166 train_loss= 0.43562 time= 0.00395\n",
      "Epoch: 0167 train_loss= 0.43374 time= 0.00301\n",
      "Epoch: 0168 train_loss= 0.43548 time= 0.00303\n",
      "Epoch: 0169 train_loss= 0.43298 time= 0.00301\n",
      "Epoch: 0170 train_loss= 0.43809 time= 0.00302\n",
      "Epoch: 0171 train_loss= 0.42671 time= 0.00404\n",
      "Epoch: 0172 train_loss= 0.43466 time= 0.00298\n",
      "Epoch: 0173 train_loss= 0.43334 time= 0.00291\n",
      "Epoch: 0174 train_loss= 0.43770 time= 0.00400\n",
      "Epoch: 0175 train_loss= 0.43326 time= 0.00306\n",
      "Epoch: 0176 train_loss= 0.43267 time= 0.00398\n",
      "Epoch: 0177 train_loss= 0.43727 time= 0.00300\n",
      "Epoch: 0178 train_loss= 0.43443 time= 0.00301\n",
      "Epoch: 0179 train_loss= 0.43984 time= 0.00299\n",
      "Epoch: 0180 train_loss= 0.43227 time= 0.00302\n",
      "Epoch: 0181 train_loss= 0.43600 time= 0.00303\n",
      "Epoch: 0182 train_loss= 0.43084 time= 0.00301\n",
      "Epoch: 0183 train_loss= 0.44168 time= 0.00500\n",
      "Epoch: 0184 train_loss= 0.43425 time= 0.00310\n",
      "Epoch: 0185 train_loss= 0.43437 time= 0.00294\n",
      "Epoch: 0186 train_loss= 0.43319 time= 0.00301\n",
      "Epoch: 0187 train_loss= 0.43470 time= 0.00307\n",
      "Epoch: 0188 train_loss= 0.42757 time= 0.00298\n",
      "Epoch: 0189 train_loss= 0.43361 time= 0.00301\n",
      "Epoch: 0190 train_loss= 0.43513 time= 0.00397\n",
      "Epoch: 0191 train_loss= 0.42911 time= 0.00429\n",
      "Epoch: 0192 train_loss= 0.43012 time= 0.00269\n",
      "Epoch: 0193 train_loss= 0.43257 time= 0.00405\n",
      "Epoch: 0194 train_loss= 0.43921 time= 0.00294\n",
      "Epoch: 0195 train_loss= 0.43082 time= 0.00296\n",
      "Epoch: 0196 train_loss= 0.43005 time= 0.00300\n",
      "Epoch: 0197 train_loss= 0.43376 time= 0.00301\n",
      "Epoch: 0198 train_loss= 0.43234 time= 0.00299\n",
      "Epoch: 0199 train_loss= 0.43567 time= 0.00304\n",
      "Epoch: 0200 train_loss= 0.43635 time= 0.00306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.45425 time= 0.15260\n",
      "Epoch: 0002 train_loss= 1.36122 time= 0.00493\n",
      "Epoch: 0003 train_loss= 0.97948 time= 0.00300\n",
      "Epoch: 0004 train_loss= 0.74741 time= 0.00401\n",
      "Epoch: 0005 train_loss= 0.86445 time= 0.00300\n",
      "Epoch: 0006 train_loss= 0.77712 time= 0.00499\n",
      "Epoch: 0007 train_loss= 0.66990 time= 0.00309\n",
      "Epoch: 0008 train_loss= 0.60203 time= 0.00305\n",
      "Epoch: 0009 train_loss= 0.60736 time= 0.00294\n",
      "Epoch: 0010 train_loss= 0.63511 time= 0.00311\n",
      "Epoch: 0011 train_loss= 0.64567 time= 0.00400\n",
      "Epoch: 0012 train_loss= 0.63282 time= 0.00395\n",
      "Epoch: 0013 train_loss= 0.60502 time= 0.00301\n",
      "Epoch: 0014 train_loss= 0.57293 time= 0.00305\n",
      "Epoch: 0015 train_loss= 0.56489 time= 0.00295\n",
      "Epoch: 0016 train_loss= 0.55496 time= 0.00201\n",
      "Epoch: 0017 train_loss= 0.55608 time= 0.00305\n",
      "Epoch: 0018 train_loss= 0.55931 time= 0.00306\n",
      "Epoch: 0019 train_loss= 0.55168 time= 0.00203\n",
      "Epoch: 0020 train_loss= 0.53650 time= 0.00305\n",
      "Epoch: 0021 train_loss= 0.52850 time= 0.00297\n",
      "Epoch: 0022 train_loss= 0.52507 time= 0.00310\n",
      "Epoch: 0023 train_loss= 0.51590 time= 0.00294\n",
      "Epoch: 0024 train_loss= 0.51860 time= 0.00300\n",
      "Epoch: 0025 train_loss= 0.51672 time= 0.00295\n",
      "Epoch: 0026 train_loss= 0.51811 time= 0.00305\n",
      "Epoch: 0027 train_loss= 0.50378 time= 0.00299\n",
      "Epoch: 0028 train_loss= 0.49230 time= 0.00300\n",
      "Epoch: 0029 train_loss= 0.49088 time= 0.00300\n",
      "Epoch: 0030 train_loss= 0.49823 time= 0.00294\n",
      "Epoch: 0031 train_loss= 0.49397 time= 0.00309\n",
      "Epoch: 0032 train_loss= 0.48689 time= 0.00299\n",
      "Epoch: 0033 train_loss= 0.48593 time= 0.00205\n",
      "Epoch: 0034 train_loss= 0.48131 time= 0.00307\n",
      "Epoch: 0035 train_loss= 0.48041 time= 0.00299\n",
      "Epoch: 0036 train_loss= 0.47785 time= 0.00299\n",
      "Epoch: 0037 train_loss= 0.47810 time= 0.00302\n",
      "Epoch: 0038 train_loss= 0.47610 time= 0.00303\n",
      "Epoch: 0039 train_loss= 0.47803 time= 0.00400\n",
      "Epoch: 0040 train_loss= 0.47218 time= 0.00305\n",
      "Epoch: 0041 train_loss= 0.47190 time= 0.00296\n",
      "Epoch: 0042 train_loss= 0.46366 time= 0.00303\n",
      "Epoch: 0043 train_loss= 0.46490 time= 0.00305\n",
      "Epoch: 0044 train_loss= 0.46689 time= 0.00299\n",
      "Epoch: 0045 train_loss= 0.46903 time= 0.00396\n",
      "Epoch: 0046 train_loss= 0.46405 time= 0.00400\n",
      "Epoch: 0047 train_loss= 0.46615 time= 0.00295\n",
      "Epoch: 0048 train_loss= 0.46931 time= 0.00198\n",
      "Epoch: 0049 train_loss= 0.46244 time= 0.00303\n",
      "Epoch: 0050 train_loss= 0.46024 time= 0.00406\n",
      "Epoch: 0051 train_loss= 0.46343 time= 0.00298\n",
      "Epoch: 0052 train_loss= 0.45840 time= 0.00302\n",
      "Epoch: 0053 train_loss= 0.45086 time= 0.00289\n",
      "Epoch: 0054 train_loss= 0.46520 time= 0.00305\n",
      "Epoch: 0055 train_loss= 0.45669 time= 0.00391\n",
      "Epoch: 0056 train_loss= 0.45575 time= 0.00305\n",
      "Epoch: 0057 train_loss= 0.45654 time= 0.00299\n",
      "Epoch: 0058 train_loss= 0.46211 time= 0.00203\n",
      "Epoch: 0059 train_loss= 0.45850 time= 0.00406\n",
      "Epoch: 0060 train_loss= 0.45217 time= 0.00294\n",
      "Epoch: 0061 train_loss= 0.46478 time= 0.00305\n",
      "Epoch: 0062 train_loss= 0.45348 time= 0.00298\n",
      "Epoch: 0063 train_loss= 0.44933 time= 0.00304\n",
      "Epoch: 0064 train_loss= 0.46277 time= 0.00309\n",
      "Epoch: 0065 train_loss= 0.45437 time= 0.00300\n",
      "Epoch: 0066 train_loss= 0.45240 time= 0.00396\n",
      "Epoch: 0067 train_loss= 0.45487 time= 0.00400\n",
      "Epoch: 0068 train_loss= 0.46159 time= 0.00342\n",
      "Epoch: 0069 train_loss= 0.45832 time= 0.00300\n",
      "Epoch: 0070 train_loss= 0.45937 time= 0.00305\n",
      "Epoch: 0071 train_loss= 0.45144 time= 0.00304\n",
      "Epoch: 0072 train_loss= 0.45303 time= 0.00498\n",
      "Epoch: 0073 train_loss= 0.44996 time= 0.00300\n",
      "Epoch: 0074 train_loss= 0.44781 time= 0.00297\n",
      "Epoch: 0075 train_loss= 0.44495 time= 0.00400\n",
      "Epoch: 0076 train_loss= 0.46135 time= 0.00302\n",
      "Epoch: 0077 train_loss= 0.45016 time= 0.00302\n",
      "Epoch: 0078 train_loss= 0.44474 time= 0.00293\n",
      "Epoch: 0079 train_loss= 0.45375 time= 0.00305\n",
      "Epoch: 0080 train_loss= 0.44863 time= 0.00298\n",
      "Epoch: 0081 train_loss= 0.45132 time= 0.00304\n",
      "Epoch: 0082 train_loss= 0.44375 time= 0.00393\n",
      "Epoch: 0083 train_loss= 0.45258 time= 0.00305\n",
      "Epoch: 0084 train_loss= 0.44733 time= 0.00303\n",
      "Epoch: 0085 train_loss= 0.44437 time= 0.00299\n",
      "Epoch: 0086 train_loss= 0.43984 time= 0.00401\n",
      "Epoch: 0087 train_loss= 0.44451 time= 0.00397\n",
      "Epoch: 0088 train_loss= 0.44445 time= 0.00298\n",
      "Epoch: 0089 train_loss= 0.44160 time= 0.00401\n",
      "Epoch: 0090 train_loss= 0.44655 time= 0.00293\n",
      "Epoch: 0091 train_loss= 0.44934 time= 0.00406\n",
      "Epoch: 0092 train_loss= 0.44778 time= 0.00298\n",
      "Epoch: 0093 train_loss= 0.44545 time= 0.00401\n",
      "Epoch: 0094 train_loss= 0.44016 time= 0.00196\n",
      "Epoch: 0095 train_loss= 0.45047 time= 0.00310\n",
      "Epoch: 0096 train_loss= 0.43989 time= 0.00390\n",
      "Epoch: 0097 train_loss= 0.44790 time= 0.00300\n",
      "Epoch: 0098 train_loss= 0.44043 time= 0.00305\n",
      "Epoch: 0099 train_loss= 0.44065 time= 0.00302\n",
      "Epoch: 0100 train_loss= 0.44682 time= 0.00204\n",
      "Epoch: 0101 train_loss= 0.43921 time= 0.00305\n",
      "Epoch: 0102 train_loss= 0.44327 time= 0.00295\n",
      "Epoch: 0103 train_loss= 0.45248 time= 0.00420\n",
      "Epoch: 0104 train_loss= 0.43893 time= 0.00292\n",
      "Epoch: 0105 train_loss= 0.44249 time= 0.00300\n",
      "Epoch: 0106 train_loss= 0.43765 time= 0.00288\n",
      "Epoch: 0107 train_loss= 0.43546 time= 0.00305\n",
      "Epoch: 0108 train_loss= 0.44189 time= 0.00301\n",
      "Epoch: 0109 train_loss= 0.44355 time= 0.00303\n",
      "Epoch: 0110 train_loss= 0.43820 time= 0.00300\n",
      "Epoch: 0111 train_loss= 0.43911 time= 0.00308\n",
      "Epoch: 0112 train_loss= 0.44277 time= 0.00293\n",
      "Epoch: 0113 train_loss= 0.44315 time= 0.00310\n",
      "Epoch: 0114 train_loss= 0.43900 time= 0.00291\n",
      "Epoch: 0115 train_loss= 0.44181 time= 0.00201\n",
      "Epoch: 0116 train_loss= 0.44608 time= 0.00300\n",
      "Epoch: 0117 train_loss= 0.44111 time= 0.00306\n",
      "Epoch: 0118 train_loss= 0.44005 time= 0.00299\n",
      "Epoch: 0119 train_loss= 0.45126 time= 0.00402\n",
      "Epoch: 0120 train_loss= 0.44477 time= 0.00297\n",
      "Epoch: 0121 train_loss= 0.43781 time= 0.00401\n",
      "Epoch: 0122 train_loss= 0.44184 time= 0.00305\n",
      "Epoch: 0123 train_loss= 0.43501 time= 0.00288\n",
      "Epoch: 0124 train_loss= 0.43645 time= 0.00301\n",
      "Epoch: 0125 train_loss= 0.43469 time= 0.00324\n",
      "Epoch: 0126 train_loss= 0.43787 time= 0.00380\n",
      "Epoch: 0127 train_loss= 0.44257 time= 0.00395\n",
      "Epoch: 0128 train_loss= 0.43492 time= 0.00297\n",
      "Epoch: 0129 train_loss= 0.44078 time= 0.00305\n",
      "Epoch: 0130 train_loss= 0.43897 time= 0.00333\n",
      "Epoch: 0131 train_loss= 0.43354 time= 0.00188\n",
      "Epoch: 0132 train_loss= 0.43733 time= 0.00306\n",
      "Epoch: 0133 train_loss= 0.44340 time= 0.00397\n",
      "Epoch: 0134 train_loss= 0.43703 time= 0.00399\n",
      "Epoch: 0135 train_loss= 0.43751 time= 0.00297\n",
      "Epoch: 0136 train_loss= 0.44382 time= 0.00301\n",
      "Epoch: 0137 train_loss= 0.44010 time= 0.00201\n",
      "Epoch: 0138 train_loss= 0.44500 time= 0.00300\n",
      "Epoch: 0139 train_loss= 0.44026 time= 0.00415\n",
      "Epoch: 0140 train_loss= 0.44210 time= 0.00206\n",
      "Epoch: 0141 train_loss= 0.43566 time= 0.00305\n",
      "Epoch: 0142 train_loss= 0.43412 time= 0.00338\n",
      "Epoch: 0143 train_loss= 0.43398 time= 0.00303\n",
      "Epoch: 0144 train_loss= 0.43300 time= 0.00397\n",
      "Epoch: 0145 train_loss= 0.43625 time= 0.00408\n",
      "Epoch: 0146 train_loss= 0.43472 time= 0.00292\n",
      "Epoch: 0147 train_loss= 0.44286 time= 0.00307\n",
      "Epoch: 0148 train_loss= 0.43551 time= 0.00395\n",
      "Epoch: 0149 train_loss= 0.43200 time= 0.00300\n",
      "Epoch: 0150 train_loss= 0.43642 time= 0.00318\n",
      "Epoch: 0151 train_loss= 0.43019 time= 0.00395\n",
      "Epoch: 0152 train_loss= 0.43785 time= 0.00338\n",
      "Epoch: 0153 train_loss= 0.43599 time= 0.00304\n",
      "Epoch: 0154 train_loss= 0.43295 time= 0.00300\n",
      "Epoch: 0155 train_loss= 0.43084 time= 0.00301\n",
      "Epoch: 0156 train_loss= 0.42959 time= 0.00306\n",
      "Epoch: 0157 train_loss= 0.43369 time= 0.00293\n",
      "Epoch: 0158 train_loss= 0.43420 time= 0.00444\n",
      "Epoch: 0159 train_loss= 0.43172 time= 0.00309\n",
      "Epoch: 0160 train_loss= 0.44221 time= 0.00315\n",
      "Epoch: 0161 train_loss= 0.43678 time= 0.00299\n",
      "Epoch: 0162 train_loss= 0.43694 time= 0.00302\n",
      "Epoch: 0163 train_loss= 0.42872 time= 0.00338\n",
      "Epoch: 0164 train_loss= 0.42725 time= 0.00345\n",
      "Epoch: 0165 train_loss= 0.43314 time= 0.00394\n",
      "Epoch: 0166 train_loss= 0.43241 time= 0.00495\n",
      "Epoch: 0167 train_loss= 0.43385 time= 0.00305\n",
      "Epoch: 0168 train_loss= 0.42804 time= 0.00359\n",
      "Epoch: 0169 train_loss= 0.43020 time= 0.00304\n",
      "Epoch: 0170 train_loss= 0.42604 time= 0.00302\n",
      "Epoch: 0171 train_loss= 0.42663 time= 0.00421\n",
      "Epoch: 0172 train_loss= 0.42823 time= 0.00387\n",
      "Epoch: 0173 train_loss= 0.42275 time= 0.00305\n",
      "Epoch: 0174 train_loss= 0.43436 time= 0.00294\n",
      "Epoch: 0175 train_loss= 0.43240 time= 0.00301\n",
      "Epoch: 0176 train_loss= 0.42978 time= 0.00398\n",
      "Epoch: 0177 train_loss= 0.43227 time= 0.00302\n",
      "Epoch: 0178 train_loss= 0.42983 time= 0.00299\n",
      "Epoch: 0179 train_loss= 0.42823 time= 0.00398\n",
      "Epoch: 0180 train_loss= 0.43554 time= 0.00299\n",
      "Epoch: 0181 train_loss= 0.42468 time= 0.00300\n",
      "Epoch: 0182 train_loss= 0.43312 time= 0.00317\n",
      "Epoch: 0183 train_loss= 0.43343 time= 0.00308\n",
      "Epoch: 0184 train_loss= 0.43276 time= 0.00395\n",
      "Epoch: 0185 train_loss= 0.43262 time= 0.00419\n",
      "Epoch: 0186 train_loss= 0.43126 time= 0.00367\n",
      "Epoch: 0187 train_loss= 0.42824 time= 0.00300\n",
      "Epoch: 0188 train_loss= 0.42571 time= 0.00305\n",
      "Epoch: 0189 train_loss= 0.43417 time= 0.00406\n",
      "Epoch: 0190 train_loss= 0.42689 time= 0.00292\n",
      "Epoch: 0191 train_loss= 0.43020 time= 0.00404\n",
      "Epoch: 0192 train_loss= 0.42725 time= 0.00300\n",
      "Epoch: 0193 train_loss= 0.42972 time= 0.00402\n",
      "Epoch: 0194 train_loss= 0.43438 time= 0.00298\n",
      "Epoch: 0195 train_loss= 0.42911 time= 0.00402\n",
      "Epoch: 0196 train_loss= 0.42856 time= 0.00306\n",
      "Epoch: 0197 train_loss= 0.43213 time= 0.00397\n",
      "Epoch: 0198 train_loss= 0.42818 time= 0.00314\n",
      "Epoch: 0199 train_loss= 0.42657 time= 0.00402\n",
      "Epoch: 0200 train_loss= 0.42923 time= 0.00308\n",
      "Testing model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.52390 time= 0.15359\n",
      "Epoch: 0002 train_loss= 1.34586 time= 0.00404\n",
      "Epoch: 0003 train_loss= 1.08682 time= 0.00300\n",
      "Epoch: 0004 train_loss= 0.73849 time= 0.00397\n",
      "Epoch: 0005 train_loss= 0.81256 time= 0.00412\n",
      "Epoch: 0006 train_loss= 0.84920 time= 0.00394\n",
      "Epoch: 0007 train_loss= 0.71805 time= 0.00398\n",
      "Epoch: 0008 train_loss= 0.62160 time= 0.00306\n",
      "Epoch: 0009 train_loss= 0.58757 time= 0.00507\n",
      "Epoch: 0010 train_loss= 0.61896 time= 0.00393\n",
      "Epoch: 0011 train_loss= 0.63421 time= 0.00399\n",
      "Epoch: 0012 train_loss= 0.64191 time= 0.00402\n",
      "Epoch: 0013 train_loss= 0.60870 time= 0.00411\n",
      "Epoch: 0014 train_loss= 0.59842 time= 0.00423\n",
      "Epoch: 0015 train_loss= 0.55563 time= 0.00332\n",
      "Epoch: 0016 train_loss= 0.54256 time= 0.00399\n",
      "Epoch: 0017 train_loss= 0.54011 time= 0.00300\n",
      "Epoch: 0018 train_loss= 0.53700 time= 0.00397\n",
      "Epoch: 0019 train_loss= 0.54112 time= 0.00303\n",
      "Epoch: 0020 train_loss= 0.53174 time= 0.00397\n",
      "Epoch: 0021 train_loss= 0.52224 time= 0.00400\n",
      "Epoch: 0022 train_loss= 0.51891 time= 0.00299\n",
      "Epoch: 0023 train_loss= 0.50917 time= 0.00395\n",
      "Epoch: 0024 train_loss= 0.50455 time= 0.00301\n",
      "Epoch: 0025 train_loss= 0.50137 time= 0.00304\n",
      "Epoch: 0026 train_loss= 0.50540 time= 0.00310\n",
      "Epoch: 0027 train_loss= 0.49899 time= 0.00291\n",
      "Epoch: 0028 train_loss= 0.49021 time= 0.00305\n",
      "Epoch: 0029 train_loss= 0.50392 time= 0.00401\n",
      "Epoch: 0030 train_loss= 0.48879 time= 0.00398\n",
      "Epoch: 0031 train_loss= 0.48355 time= 0.00300\n",
      "Epoch: 0032 train_loss= 0.48554 time= 0.00399\n",
      "Epoch: 0033 train_loss= 0.48550 time= 0.00302\n",
      "Epoch: 0034 train_loss= 0.48156 time= 0.00397\n",
      "Epoch: 0035 train_loss= 0.47764 time= 0.00302\n",
      "Epoch: 0036 train_loss= 0.47110 time= 0.00399\n",
      "Epoch: 0037 train_loss= 0.47480 time= 0.00308\n",
      "Epoch: 0038 train_loss= 0.46968 time= 0.00403\n",
      "Epoch: 0039 train_loss= 0.47208 time= 0.00298\n",
      "Epoch: 0040 train_loss= 0.48223 time= 0.00306\n",
      "Epoch: 0041 train_loss= 0.46486 time= 0.00411\n",
      "Epoch: 0042 train_loss= 0.47654 time= 0.00388\n",
      "Epoch: 0043 train_loss= 0.46449 time= 0.00302\n",
      "Epoch: 0044 train_loss= 0.46617 time= 0.00400\n",
      "Epoch: 0045 train_loss= 0.45991 time= 0.00409\n",
      "Epoch: 0046 train_loss= 0.46600 time= 0.00302\n",
      "Epoch: 0047 train_loss= 0.46445 time= 0.00404\n",
      "Epoch: 0048 train_loss= 0.45876 time= 0.00493\n",
      "Epoch: 0049 train_loss= 0.46412 time= 0.00409\n",
      "Epoch: 0050 train_loss= 0.45714 time= 0.00341\n",
      "Epoch: 0051 train_loss= 0.45772 time= 0.00259\n",
      "Epoch: 0052 train_loss= 0.47571 time= 0.00307\n",
      "Epoch: 0053 train_loss= 0.45986 time= 0.00499\n",
      "Epoch: 0054 train_loss= 0.45798 time= 0.00395\n",
      "Epoch: 0055 train_loss= 0.45895 time= 0.00304\n",
      "Epoch: 0056 train_loss= 0.45573 time= 0.00397\n",
      "Epoch: 0057 train_loss= 0.45575 time= 0.00406\n",
      "Epoch: 0058 train_loss= 0.45628 time= 0.00293\n",
      "Epoch: 0059 train_loss= 0.46068 time= 0.00308\n",
      "Epoch: 0060 train_loss= 0.45369 time= 0.00291\n",
      "Epoch: 0061 train_loss= 0.45781 time= 0.00307\n",
      "Epoch: 0062 train_loss= 0.45115 time= 0.00396\n",
      "Epoch: 0063 train_loss= 0.45095 time= 0.00402\n",
      "Epoch: 0064 train_loss= 0.44928 time= 0.00296\n",
      "Epoch: 0065 train_loss= 0.45474 time= 0.00496\n",
      "Epoch: 0066 train_loss= 0.45007 time= 0.00403\n",
      "Epoch: 0067 train_loss= 0.45325 time= 0.00305\n",
      "Epoch: 0068 train_loss= 0.45746 time= 0.00295\n",
      "Epoch: 0069 train_loss= 0.44469 time= 0.00412\n",
      "Epoch: 0070 train_loss= 0.45024 time= 0.00488\n",
      "Epoch: 0071 train_loss= 0.44758 time= 0.00312\n",
      "Epoch: 0072 train_loss= 0.44729 time= 0.00290\n",
      "Epoch: 0073 train_loss= 0.44719 time= 0.00405\n",
      "Epoch: 0074 train_loss= 0.44406 time= 0.00394\n",
      "Epoch: 0075 train_loss= 0.45358 time= 0.00504\n",
      "Epoch: 0076 train_loss= 0.45222 time= 0.00419\n",
      "Epoch: 0077 train_loss= 0.44418 time= 0.00405\n",
      "Epoch: 0078 train_loss= 0.45683 time= 0.00595\n",
      "Epoch: 0079 train_loss= 0.44578 time= 0.00403\n",
      "Epoch: 0080 train_loss= 0.44937 time= 0.00287\n",
      "Epoch: 0081 train_loss= 0.43992 time= 0.00400\n",
      "Epoch: 0082 train_loss= 0.44283 time= 0.00495\n",
      "Epoch: 0083 train_loss= 0.45411 time= 0.00401\n",
      "Epoch: 0084 train_loss= 0.44379 time= 0.00300\n",
      "Epoch: 0085 train_loss= 0.44934 time= 0.00401\n",
      "Epoch: 0086 train_loss= 0.45057 time= 0.00403\n",
      "Epoch: 0087 train_loss= 0.43847 time= 0.00306\n",
      "Epoch: 0088 train_loss= 0.44074 time= 0.00300\n",
      "Epoch: 0089 train_loss= 0.44515 time= 0.00394\n",
      "Epoch: 0090 train_loss= 0.44542 time= 0.00395\n",
      "Epoch: 0091 train_loss= 0.44580 time= 0.00306\n",
      "Epoch: 0092 train_loss= 0.44229 time= 0.00398\n",
      "Epoch: 0093 train_loss= 0.44117 time= 0.00303\n",
      "Epoch: 0094 train_loss= 0.44127 time= 0.00400\n",
      "Epoch: 0095 train_loss= 0.44137 time= 0.00405\n",
      "Epoch: 0096 train_loss= 0.44121 time= 0.00299\n",
      "Epoch: 0097 train_loss= 0.44061 time= 0.00300\n",
      "Epoch: 0098 train_loss= 0.44359 time= 0.00300\n",
      "Epoch: 0099 train_loss= 0.43958 time= 0.00300\n",
      "Epoch: 0100 train_loss= 0.44678 time= 0.00302\n",
      "Epoch: 0101 train_loss= 0.44122 time= 0.00401\n",
      "Epoch: 0102 train_loss= 0.43855 time= 0.00298\n",
      "Epoch: 0103 train_loss= 0.43875 time= 0.00305\n",
      "Epoch: 0104 train_loss= 0.44123 time= 0.00295\n",
      "Epoch: 0105 train_loss= 0.43988 time= 0.00299\n",
      "Epoch: 0106 train_loss= 0.43943 time= 0.00399\n",
      "Epoch: 0107 train_loss= 0.44105 time= 0.00296\n",
      "Epoch: 0108 train_loss= 0.43366 time= 0.00401\n",
      "Epoch: 0109 train_loss= 0.43716 time= 0.00405\n",
      "Epoch: 0110 train_loss= 0.43974 time= 0.00305\n",
      "Epoch: 0111 train_loss= 0.43741 time= 0.00195\n",
      "Epoch: 0112 train_loss= 0.43452 time= 0.00301\n",
      "Epoch: 0113 train_loss= 0.43997 time= 0.00299\n",
      "Epoch: 0114 train_loss= 0.44492 time= 0.00397\n",
      "Epoch: 0115 train_loss= 0.43333 time= 0.00404\n",
      "Epoch: 0116 train_loss= 0.44000 time= 0.00299\n",
      "Epoch: 0117 train_loss= 0.44175 time= 0.00310\n",
      "Epoch: 0118 train_loss= 0.45049 time= 0.00208\n",
      "Epoch: 0119 train_loss= 0.44389 time= 0.00310\n",
      "Epoch: 0120 train_loss= 0.43939 time= 0.00297\n",
      "Epoch: 0121 train_loss= 0.44345 time= 0.00301\n",
      "Epoch: 0122 train_loss= 0.43318 time= 0.00307\n",
      "Epoch: 0123 train_loss= 0.43841 time= 0.00393\n",
      "Epoch: 0124 train_loss= 0.43992 time= 0.00406\n",
      "Epoch: 0125 train_loss= 0.43754 time= 0.00293\n",
      "Epoch: 0126 train_loss= 0.44294 time= 0.00410\n",
      "Epoch: 0127 train_loss= 0.43176 time= 0.00355\n",
      "Epoch: 0128 train_loss= 0.43814 time= 0.00419\n",
      "Epoch: 0129 train_loss= 0.43769 time= 0.00276\n",
      "Epoch: 0130 train_loss= 0.43419 time= 0.00400\n",
      "Epoch: 0131 train_loss= 0.43081 time= 0.00301\n",
      "Epoch: 0132 train_loss= 0.44016 time= 0.00298\n",
      "Epoch: 0133 train_loss= 0.42912 time= 0.00295\n",
      "Epoch: 0134 train_loss= 0.43435 time= 0.00304\n",
      "Epoch: 0135 train_loss= 0.43651 time= 0.00400\n",
      "Epoch: 0136 train_loss= 0.44042 time= 0.00396\n",
      "Epoch: 0137 train_loss= 0.43398 time= 0.00304\n",
      "Epoch: 0138 train_loss= 0.43041 time= 0.00300\n",
      "Epoch: 0139 train_loss= 0.43865 time= 0.00299\n",
      "Epoch: 0140 train_loss= 0.43080 time= 0.00405\n",
      "Epoch: 0141 train_loss= 0.43522 time= 0.00299\n",
      "Epoch: 0142 train_loss= 0.43158 time= 0.00298\n",
      "Epoch: 0143 train_loss= 0.43421 time= 0.00402\n",
      "Epoch: 0144 train_loss= 0.43887 time= 0.00324\n",
      "Epoch: 0145 train_loss= 0.43112 time= 0.00306\n",
      "Epoch: 0146 train_loss= 0.42961 time= 0.00299\n",
      "Epoch: 0147 train_loss= 0.43202 time= 0.00200\n",
      "Epoch: 0148 train_loss= 0.42826 time= 0.00358\n",
      "Epoch: 0149 train_loss= 0.45325 time= 0.00240\n",
      "Epoch: 0150 train_loss= 0.42718 time= 0.00308\n",
      "Epoch: 0151 train_loss= 0.42784 time= 0.00395\n",
      "Epoch: 0152 train_loss= 0.42946 time= 0.00403\n",
      "Epoch: 0153 train_loss= 0.43185 time= 0.00300\n",
      "Epoch: 0154 train_loss= 0.43209 time= 0.00304\n",
      "Epoch: 0155 train_loss= 0.43007 time= 0.00412\n",
      "Epoch: 0156 train_loss= 0.42988 time= 0.00303\n",
      "Epoch: 0157 train_loss= 0.42854 time= 0.00307\n",
      "Epoch: 0158 train_loss= 0.43649 time= 0.00296\n",
      "Epoch: 0159 train_loss= 0.43745 time= 0.00408\n",
      "Epoch: 0160 train_loss= 0.42877 time= 0.00196\n",
      "Epoch: 0161 train_loss= 0.43115 time= 0.00405\n",
      "Epoch: 0162 train_loss= 0.42863 time= 0.00296\n",
      "Epoch: 0163 train_loss= 0.43573 time= 0.00409\n",
      "Epoch: 0164 train_loss= 0.42999 time= 0.00396\n",
      "Epoch: 0165 train_loss= 0.43107 time= 0.00299\n",
      "Epoch: 0166 train_loss= 0.43114 time= 0.00306\n",
      "Epoch: 0167 train_loss= 0.43205 time= 0.00293\n",
      "Epoch: 0168 train_loss= 0.43614 time= 0.00305\n",
      "Epoch: 0169 train_loss= 0.42843 time= 0.00300\n",
      "Epoch: 0170 train_loss= 0.43372 time= 0.00399\n",
      "Epoch: 0171 train_loss= 0.43591 time= 0.00403\n",
      "Epoch: 0172 train_loss= 0.43065 time= 0.00298\n",
      "Epoch: 0173 train_loss= 0.43246 time= 0.00299\n",
      "Epoch: 0174 train_loss= 0.43216 time= 0.00313\n",
      "Epoch: 0175 train_loss= 0.43506 time= 0.00432\n",
      "Epoch: 0176 train_loss= 0.43065 time= 0.00404\n",
      "Epoch: 0177 train_loss= 0.43601 time= 0.00304\n",
      "Epoch: 0178 train_loss= 0.43343 time= 0.00399\n",
      "Epoch: 0179 train_loss= 0.43060 time= 0.00397\n",
      "Epoch: 0180 train_loss= 0.43935 time= 0.00402\n",
      "Epoch: 0181 train_loss= 0.43217 time= 0.00305\n",
      "Epoch: 0182 train_loss= 0.43313 time= 0.00298\n",
      "Epoch: 0183 train_loss= 0.43185 time= 0.00311\n",
      "Epoch: 0184 train_loss= 0.43380 time= 0.00303\n",
      "Epoch: 0185 train_loss= 0.43086 time= 0.00300\n",
      "Epoch: 0186 train_loss= 0.43009 time= 0.00302\n",
      "Epoch: 0187 train_loss= 0.42722 time= 0.00396\n",
      "Epoch: 0188 train_loss= 0.43267 time= 0.00336\n",
      "Epoch: 0189 train_loss= 0.42895 time= 0.00406\n",
      "Epoch: 0190 train_loss= 0.42333 time= 0.00196\n",
      "Epoch: 0191 train_loss= 0.42817 time= 0.00305\n",
      "Epoch: 0192 train_loss= 0.43123 time= 0.00402\n",
      "Epoch: 0193 train_loss= 0.43149 time= 0.00298\n",
      "Epoch: 0194 train_loss= 0.42716 time= 0.00400\n",
      "Epoch: 0195 train_loss= 0.42690 time= 0.00300\n",
      "Epoch: 0196 train_loss= 0.42278 time= 0.00343\n",
      "Epoch: 0197 train_loss= 0.42677 time= 0.00401\n",
      "Epoch: 0198 train_loss= 0.43796 time= 0.00398\n",
      "Epoch: 0199 train_loss= 0.42545 time= 0.00302\n",
      "Epoch: 0200 train_loss= 0.43228 time= 0.00415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n",
      "Masking test edges...\n",
      "Number of bidirectional edges in the graph: 18.0\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.72104 time= 0.17272\n",
      "Epoch: 0002 train_loss= 1.35808 time= 0.00301\n",
      "Epoch: 0003 train_loss= 1.12387 time= 0.00296\n",
      "Epoch: 0004 train_loss= 0.82885 time= 0.00306\n",
      "Epoch: 0005 train_loss= 0.78368 time= 0.00398\n",
      "Epoch: 0006 train_loss= 0.83873 time= 0.00401\n",
      "Epoch: 0007 train_loss= 0.79116 time= 0.00399\n",
      "Epoch: 0008 train_loss= 0.68101 time= 0.00401\n",
      "Epoch: 0009 train_loss= 0.62577 time= 0.00403\n",
      "Epoch: 0010 train_loss= 0.62439 time= 0.00397\n",
      "Epoch: 0011 train_loss= 0.64143 time= 0.00296\n",
      "Epoch: 0012 train_loss= 0.65044 time= 0.00316\n",
      "Epoch: 0013 train_loss= 0.65496 time= 0.00288\n",
      "Epoch: 0014 train_loss= 0.63092 time= 0.00299\n",
      "Epoch: 0015 train_loss= 0.60504 time= 0.00303\n",
      "Epoch: 0016 train_loss= 0.58470 time= 0.00294\n",
      "Epoch: 0017 train_loss= 0.56901 time= 0.00301\n",
      "Epoch: 0018 train_loss= 0.56408 time= 0.00337\n",
      "Epoch: 0019 train_loss= 0.55813 time= 0.00314\n",
      "Epoch: 0020 train_loss= 0.55389 time= 0.00402\n",
      "Epoch: 0021 train_loss= 0.54803 time= 0.00301\n",
      "Epoch: 0022 train_loss= 0.53628 time= 0.00304\n",
      "Epoch: 0023 train_loss= 0.52777 time= 0.00306\n",
      "Epoch: 0024 train_loss= 0.53147 time= 0.00398\n",
      "Epoch: 0025 train_loss= 0.52296 time= 0.00394\n",
      "Epoch: 0026 train_loss= 0.51781 time= 0.00399\n",
      "Epoch: 0027 train_loss= 0.51175 time= 0.00303\n",
      "Epoch: 0028 train_loss= 0.51607 time= 0.00302\n",
      "Epoch: 0029 train_loss= 0.50055 time= 0.00342\n",
      "Epoch: 0030 train_loss= 0.49443 time= 0.00303\n",
      "Epoch: 0031 train_loss= 0.49821 time= 0.00303\n",
      "Epoch: 0032 train_loss= 0.50704 time= 0.00300\n",
      "Epoch: 0033 train_loss= 0.48950 time= 0.00408\n",
      "Epoch: 0034 train_loss= 0.48776 time= 0.00392\n",
      "Epoch: 0035 train_loss= 0.48644 time= 0.00315\n",
      "Epoch: 0036 train_loss= 0.48737 time= 0.00404\n",
      "Epoch: 0037 train_loss= 0.49501 time= 0.00296\n",
      "Epoch: 0038 train_loss= 0.48584 time= 0.00406\n",
      "Epoch: 0039 train_loss= 0.48668 time= 0.00493\n",
      "Epoch: 0040 train_loss= 0.47972 time= 0.00309\n",
      "Epoch: 0041 train_loss= 0.48918 time= 0.00306\n",
      "Epoch: 0042 train_loss= 0.48880 time= 0.00304\n",
      "Epoch: 0043 train_loss= 0.48269 time= 0.00398\n",
      "Epoch: 0044 train_loss= 0.47716 time= 0.00302\n",
      "Epoch: 0045 train_loss= 0.47350 time= 0.00299\n",
      "Epoch: 0046 train_loss= 0.47905 time= 0.00399\n",
      "Epoch: 0047 train_loss= 0.47752 time= 0.00297\n",
      "Epoch: 0048 train_loss= 0.47062 time= 0.00304\n",
      "Epoch: 0049 train_loss= 0.46908 time= 0.00304\n",
      "Epoch: 0050 train_loss= 0.47421 time= 0.00296\n",
      "Epoch: 0051 train_loss= 0.46727 time= 0.00404\n",
      "Epoch: 0052 train_loss= 0.47191 time= 0.00299\n",
      "Epoch: 0053 train_loss= 0.46823 time= 0.00403\n",
      "Epoch: 0054 train_loss= 0.46787 time= 0.00300\n",
      "Epoch: 0055 train_loss= 0.46478 time= 0.00400\n",
      "Epoch: 0056 train_loss= 0.46030 time= 0.00398\n",
      "Epoch: 0057 train_loss= 0.46525 time= 0.00406\n",
      "Epoch: 0058 train_loss= 0.46389 time= 0.00296\n",
      "Epoch: 0059 train_loss= 0.45998 time= 0.00496\n",
      "Epoch: 0060 train_loss= 0.46458 time= 0.00337\n",
      "Epoch: 0061 train_loss= 0.45908 time= 0.00300\n",
      "Epoch: 0062 train_loss= 0.45968 time= 0.00400\n",
      "Epoch: 0063 train_loss= 0.46322 time= 0.00400\n",
      "Epoch: 0064 train_loss= 0.45788 time= 0.00407\n",
      "Epoch: 0065 train_loss= 0.46431 time= 0.00404\n",
      "Epoch: 0066 train_loss= 0.46877 time= 0.00306\n",
      "Epoch: 0067 train_loss= 0.46195 time= 0.00293\n",
      "Epoch: 0068 train_loss= 0.45567 time= 0.00305\n",
      "Epoch: 0069 train_loss= 0.46276 time= 0.00299\n",
      "Epoch: 0070 train_loss= 0.45886 time= 0.00301\n",
      "Epoch: 0071 train_loss= 0.45721 time= 0.00399\n",
      "Epoch: 0072 train_loss= 0.46217 time= 0.00296\n",
      "Epoch: 0073 train_loss= 0.46164 time= 0.00400\n",
      "Epoch: 0074 train_loss= 0.45943 time= 0.00301\n",
      "Epoch: 0075 train_loss= 0.45324 time= 0.00305\n",
      "Epoch: 0076 train_loss= 0.45828 time= 0.00399\n",
      "Epoch: 0077 train_loss= 0.45328 time= 0.00400\n",
      "Epoch: 0078 train_loss= 0.46120 time= 0.00307\n",
      "Epoch: 0079 train_loss= 0.45895 time= 0.00292\n",
      "Epoch: 0080 train_loss= 0.46232 time= 0.00299\n",
      "Epoch: 0081 train_loss= 0.46079 time= 0.00315\n",
      "Epoch: 0082 train_loss= 0.45426 time= 0.00307\n",
      "Epoch: 0083 train_loss= 0.46261 time= 0.00398\n",
      "Epoch: 0084 train_loss= 0.45294 time= 0.00301\n",
      "Epoch: 0085 train_loss= 0.45960 time= 0.00301\n",
      "Epoch: 0086 train_loss= 0.45214 time= 0.00294\n",
      "Epoch: 0087 train_loss= 0.45649 time= 0.00304\n",
      "Epoch: 0088 train_loss= 0.44957 time= 0.00397\n",
      "Epoch: 0089 train_loss= 0.44748 time= 0.00453\n",
      "Epoch: 0090 train_loss= 0.45310 time= 0.00305\n",
      "Epoch: 0091 train_loss= 0.45017 time= 0.00412\n",
      "Epoch: 0092 train_loss= 0.45068 time= 0.00384\n",
      "Epoch: 0093 train_loss= 0.45087 time= 0.00400\n",
      "Epoch: 0094 train_loss= 0.45597 time= 0.00404\n",
      "Epoch: 0095 train_loss= 0.45710 time= 0.00301\n",
      "Epoch: 0096 train_loss= 0.45655 time= 0.00302\n",
      "Epoch: 0097 train_loss= 0.45741 time= 0.00290\n",
      "Epoch: 0098 train_loss= 0.45093 time= 0.00300\n",
      "Epoch: 0099 train_loss= 0.45132 time= 0.00300\n",
      "Epoch: 0100 train_loss= 0.45259 time= 0.00501\n",
      "Epoch: 0101 train_loss= 0.45227 time= 0.00395\n",
      "Epoch: 0102 train_loss= 0.44908 time= 0.00311\n",
      "Epoch: 0103 train_loss= 0.45458 time= 0.00380\n",
      "Epoch: 0104 train_loss= 0.45198 time= 0.00401\n",
      "Epoch: 0105 train_loss= 0.44490 time= 0.00407\n",
      "Epoch: 0106 train_loss= 0.44681 time= 0.00399\n",
      "Epoch: 0107 train_loss= 0.44475 time= 0.00464\n",
      "Epoch: 0108 train_loss= 0.44806 time= 0.00303\n",
      "Epoch: 0109 train_loss= 0.45014 time= 0.00300\n",
      "Epoch: 0110 train_loss= 0.44389 time= 0.00396\n",
      "Epoch: 0111 train_loss= 0.44922 time= 0.00303\n",
      "Epoch: 0112 train_loss= 0.45941 time= 0.00303\n",
      "Epoch: 0113 train_loss= 0.45099 time= 0.00402\n",
      "Epoch: 0114 train_loss= 0.44767 time= 0.00196\n",
      "Epoch: 0115 train_loss= 0.44518 time= 0.00406\n",
      "Epoch: 0116 train_loss= 0.44722 time= 0.00294\n",
      "Epoch: 0117 train_loss= 0.45577 time= 0.00307\n",
      "Epoch: 0118 train_loss= 0.44392 time= 0.00394\n",
      "Epoch: 0119 train_loss= 0.44657 time= 0.00404\n",
      "Epoch: 0120 train_loss= 0.44432 time= 0.00301\n",
      "Epoch: 0121 train_loss= 0.44130 time= 0.00295\n",
      "Epoch: 0122 train_loss= 0.44855 time= 0.00247\n",
      "Epoch: 0123 train_loss= 0.44615 time= 0.00308\n",
      "Epoch: 0124 train_loss= 0.44763 time= 0.00303\n",
      "Epoch: 0125 train_loss= 0.44818 time= 0.00326\n",
      "Epoch: 0126 train_loss= 0.44710 time= 0.00283\n",
      "Epoch: 0127 train_loss= 0.44938 time= 0.00405\n",
      "Epoch: 0128 train_loss= 0.44589 time= 0.00298\n",
      "Epoch: 0129 train_loss= 0.44601 time= 0.00404\n",
      "Epoch: 0130 train_loss= 0.44702 time= 0.00396\n",
      "Epoch: 0131 train_loss= 0.45551 time= 0.00303\n",
      "Epoch: 0132 train_loss= 0.44469 time= 0.00293\n",
      "Epoch: 0133 train_loss= 0.44220 time= 0.00506\n",
      "Epoch: 0134 train_loss= 0.43977 time= 0.00321\n",
      "Epoch: 0135 train_loss= 0.44807 time= 0.00295\n",
      "Epoch: 0136 train_loss= 0.44929 time= 0.00296\n",
      "Epoch: 0137 train_loss= 0.44591 time= 0.00407\n",
      "Epoch: 0138 train_loss= 0.44275 time= 0.00421\n",
      "Epoch: 0139 train_loss= 0.45566 time= 0.00304\n",
      "Epoch: 0140 train_loss= 0.45099 time= 0.00393\n",
      "Epoch: 0141 train_loss= 0.44881 time= 0.00305\n",
      "Epoch: 0142 train_loss= 0.44237 time= 0.00405\n",
      "Epoch: 0143 train_loss= 0.45256 time= 0.00501\n",
      "Epoch: 0144 train_loss= 0.44347 time= 0.00501\n",
      "Epoch: 0145 train_loss= 0.44886 time= 0.00388\n",
      "Epoch: 0146 train_loss= 0.44450 time= 0.00390\n",
      "Epoch: 0147 train_loss= 0.44450 time= 0.00400\n",
      "Epoch: 0148 train_loss= 0.44749 time= 0.00500\n",
      "Epoch: 0149 train_loss= 0.44718 time= 0.00301\n",
      "Epoch: 0150 train_loss= 0.44588 time= 0.00401\n",
      "Epoch: 0151 train_loss= 0.44769 time= 0.00401\n",
      "Epoch: 0152 train_loss= 0.44911 time= 0.00299\n",
      "Epoch: 0153 train_loss= 0.44242 time= 0.00405\n",
      "Epoch: 0154 train_loss= 0.43783 time= 0.00295\n",
      "Epoch: 0155 train_loss= 0.44537 time= 0.00438\n",
      "Epoch: 0156 train_loss= 0.44442 time= 0.00258\n",
      "Epoch: 0157 train_loss= 0.45228 time= 0.00409\n",
      "Epoch: 0158 train_loss= 0.44283 time= 0.00291\n",
      "Epoch: 0159 train_loss= 0.45009 time= 0.00407\n",
      "Epoch: 0160 train_loss= 0.43855 time= 0.00300\n",
      "Epoch: 0161 train_loss= 0.45070 time= 0.00310\n",
      "Epoch: 0162 train_loss= 0.45061 time= 0.00447\n",
      "Epoch: 0163 train_loss= 0.44540 time= 0.00250\n",
      "Epoch: 0164 train_loss= 0.44284 time= 0.00437\n",
      "Epoch: 0165 train_loss= 0.44022 time= 0.00260\n",
      "Epoch: 0166 train_loss= 0.44149 time= 0.00298\n",
      "Epoch: 0167 train_loss= 0.44851 time= 0.00305\n",
      "Epoch: 0168 train_loss= 0.44718 time= 0.00399\n",
      "Epoch: 0169 train_loss= 0.44055 time= 0.00455\n",
      "Epoch: 0170 train_loss= 0.44060 time= 0.00297\n",
      "Epoch: 0171 train_loss= 0.43951 time= 0.00406\n",
      "Epoch: 0172 train_loss= 0.43641 time= 0.00399\n",
      "Epoch: 0173 train_loss= 0.44488 time= 0.00402\n",
      "Epoch: 0174 train_loss= 0.44092 time= 0.00301\n",
      "Epoch: 0175 train_loss= 0.44190 time= 0.00301\n",
      "Epoch: 0176 train_loss= 0.44385 time= 0.00299\n",
      "Epoch: 0177 train_loss= 0.43728 time= 0.00400\n",
      "Epoch: 0178 train_loss= 0.44052 time= 0.00400\n",
      "Epoch: 0179 train_loss= 0.43580 time= 0.00400\n",
      "Epoch: 0180 train_loss= 0.43728 time= 0.00300\n",
      "Epoch: 0181 train_loss= 0.44856 time= 0.00399\n",
      "Epoch: 0182 train_loss= 0.44018 time= 0.00505\n",
      "Epoch: 0183 train_loss= 0.43768 time= 0.00400\n",
      "Epoch: 0184 train_loss= 0.44391 time= 0.00402\n",
      "Epoch: 0185 train_loss= 0.43723 time= 0.00404\n",
      "Epoch: 0186 train_loss= 0.43933 time= 0.00392\n",
      "Epoch: 0187 train_loss= 0.43889 time= 0.00299\n",
      "Epoch: 0188 train_loss= 0.43177 time= 0.00401\n",
      "Epoch: 0189 train_loss= 0.43735 time= 0.00307\n",
      "Epoch: 0190 train_loss= 0.43112 time= 0.00292\n",
      "Epoch: 0191 train_loss= 0.43943 time= 0.00202\n",
      "Epoch: 0192 train_loss= 0.43874 time= 0.00305\n",
      "Epoch: 0193 train_loss= 0.44208 time= 0.00407\n",
      "Epoch: 0194 train_loss= 0.44597 time= 0.00395\n",
      "Epoch: 0195 train_loss= 0.44474 time= 0.00406\n",
      "Epoch: 0196 train_loss= 0.44418 time= 0.00394\n",
      "Epoch: 0197 train_loss= 0.43917 time= 0.00304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0198 train_loss= 0.44113 time= 0.00304\n",
      "Epoch: 0199 train_loss= 0.44232 time= 0.00306\n",
      "Epoch: 0200 train_loss= 0.44267 time= 0.00197\n",
      "Testing model...\n",
      "\n",
      "Test results for gravity_gcn_vae model on Cornell on task_3 \n",
      " ___________________________________________________\n",
      "\n",
      "AUC scores\n",
      " [0.8055555555555556, 0.7098765432098766, 0.7746913580246914, 0.8209876543209876, 0.8179012345679012, 0.7006172839506173, 0.6697530864197531, 0.691358024691358, 0.8055555555555555, 0.7006172839506173]\n",
      "Mean AUC score:  0.7496913580246913 \n",
      "Std of AUC scores:  0.057268682778024584 \n",
      " \n",
      "\n",
      "AP scores \n",
      " [0.8569210558457871, 0.7639839592872267, 0.8306933062680188, 0.8205111181212715, 0.8477821920081983, 0.759795227490661, 0.6410619278898375, 0.7332849309485931, 0.8446154939121693, 0.6839844276625887]\n",
      "Mean AP score:  0.7782633639434351 \n",
      "Std of AP scores:  0.07087810766730737 \n",
      " \n",
      "\n",
      "Running times\n",
      " [0.7612240314483643, 0.7355003356933594, 0.7181615829467773, 0.8606541156768799, 0.8261828422546387, 0.8671460151672363, 0.8955450057983398, 0.8596856594085693, 0.9129290580749512, 0.9331314563751221]\n",
      "Mean running time:  0.8370160102844239 \n",
      "Std of running time:  0.07120441840294033 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lists to collect average results\n",
    "mean_roc = []\n",
    "mean_ap = []\n",
    "mean_time = []\n",
    "\n",
    "\n",
    "# Load graph dataset\n",
    "if FLAGS.verbose:\n",
    "    print(\"Loading data...\")\n",
    "adj_init, features = load_data(FLAGS.dataset)\n",
    "\n",
    "\n",
    "# The entire training process is repeated FLAGS.nb_run times\n",
    "for i in range(FLAGS.nb_run):\n",
    "\n",
    "    # Edge Masking: compute Train/Validation/Test set\n",
    "    if FLAGS.verbose:\n",
    "        print(\"Masking test edges...\")\n",
    "\n",
    "    if FLAGS.task == 'task_1':\n",
    "        # Edge masking for General Directed Link Prediction\n",
    "        adj, val_edges, val_edges_false, test_edges, test_edges_false = \\\n",
    "        mask_test_edges_general_link_prediction(adj_init, FLAGS.prop_test,\n",
    "                                                FLAGS.prop_val)\n",
    "    elif FLAGS.task == 'task_2':\n",
    "        # Edge masking for B.N.S. Directed Link Prediction\n",
    "        adj, val_edges, val_edges_false, test_edges, test_edges_false = \\\n",
    "        mask_test_edges_biased_negative_samples(adj_init, FLAGS.prop_test)\n",
    "    elif FLAGS.task == 'task_3':\n",
    "        # Edge masking for Bidirectionality Prediction\n",
    "        adj, val_edges, val_edges_false, test_edges, test_edges_false = \\\n",
    "        mask_test_edges_bidirectional_link_prediction(adj_init)\n",
    "    else:\n",
    "        raise ValueError('Undefined task!')\n",
    "\n",
    "    # Preprocessing and initialization\n",
    "    if FLAGS.verbose:\n",
    "        print(\"Preprocessing and Initializing...\")\n",
    "    # Compute number of nodes\n",
    "    num_nodes = adj.shape[0]\n",
    "    # If features are not used, replace feature matrix by identity matrix\n",
    "    if not FLAGS.features:\n",
    "        features = sp.identity(adj.shape[0])\n",
    "    # Preprocessing on node features\n",
    "    features = sparse_to_tuple(features)\n",
    "    num_features = features[2][1]\n",
    "    features_nonzero = features[1].shape[0]\n",
    "\n",
    "    # Define placeholders\n",
    "    placeholders = {\n",
    "        'features': tf.sparse_placeholder(tf.float32),\n",
    "        'adj': tf.sparse_placeholder(tf.float32),\n",
    "        'adj_orig': tf.sparse_placeholder(tf.float32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=())\n",
    "    }\n",
    "\n",
    "    # Create model\n",
    "    model = None\n",
    "    if FLAGS.model == 'gcn_ae':\n",
    "        # Standard Graph Autoencoder\n",
    "        model = GCNModelAE(placeholders, num_features, features_nonzero)\n",
    "    elif FLAGS.model == 'gcn_vae':\n",
    "        # Standard Graph Variational Autoencoder\n",
    "        model = GCNModelVAE(placeholders, num_features, num_nodes,\n",
    "                            features_nonzero)\n",
    "    elif FLAGS.model == 'source_target_gcn_ae':\n",
    "        # Source-Target Graph Autoencoder\n",
    "        if FLAGS.dimension % 2 != 0:\n",
    "            raise ValueError('Dimension must be even for Source-Target models')\n",
    "        model = SourceTargetGCNModelAE(placeholders, num_features,\n",
    "                                     features_nonzero)\n",
    "    elif FLAGS.model == 'source_target_gcn_vae':\n",
    "        # Source-Target Graph Variational Autoencoder\n",
    "        if FLAGS.dimension % 2 != 0:\n",
    "            raise ValueError('Dimension must be even for Source-Target models')\n",
    "        model = SourceTargetGCNModelVAE(placeholders, num_features,\n",
    "                                      num_nodes, features_nonzero)\n",
    "    elif FLAGS.model == 'gravity_gcn_ae':\n",
    "        # Gravity-Inspired Graph Autoencoder\n",
    "        model = GravityGCNModelAE(placeholders, num_features,\n",
    "                                  features_nonzero)\n",
    "    elif FLAGS.model == 'gravity_gcn_vae':\n",
    "        # Gravity-Inspired Graph Variational Autoencoder\n",
    "        model = GravityGCNModelVAE(placeholders, num_features, num_nodes,\n",
    "                                   features_nonzero)\n",
    "    else:\n",
    "        raise ValueError('Undefined model!')\n",
    "\n",
    "    # Optimizer (see tkipf/gae original GAE repository for details)\n",
    "    pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0]\n",
    "                                                - adj.sum()) * 2)\n",
    "    with tf.name_scope('optimizer'):\n",
    "        # Optimizer for Non-Variational Autoencoders\n",
    "        if FLAGS.model in ('gcn_ae', 'source_target_gcn_ae', 'gravity_gcn_ae'):\n",
    "            opt = OptimizerAE(preds = model.reconstructions,\n",
    "                              labels = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                            validate_indices = False), [-1]),\n",
    "                              pos_weight = pos_weight,\n",
    "                              norm = norm)\n",
    "        # Optimizer for Variational Autoencoders\n",
    "        elif FLAGS.model in ('gcn_vae', 'source_target_gcn_vae', 'gravity_gcn_vae'):\n",
    "            opt = OptimizerVAE(preds = model.reconstructions,\n",
    "                               labels = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                             validate_indices = False), [-1]),\n",
    "                               model = model,\n",
    "                               num_nodes = num_nodes,\n",
    "                               pos_weight = pos_weight,\n",
    "                               norm = norm)\n",
    "\n",
    "    # Normalization and preprocessing on adjacency matrix\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    adj_label = sparse_to_tuple(adj + sp.eye(adj.shape[0]))\n",
    "\n",
    "    # Initialize TF session\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Model training\n",
    "    if FLAGS.verbose:\n",
    "        print(\"Training...\")\n",
    "    # Flag to compute total running time\n",
    "    t_start = time.time()\n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        # Flag to compute running time for each epoch\n",
    "        t = time.time()\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = construct_feed_dict(adj_norm, adj_label, features,\n",
    "                                        placeholders)\n",
    "        feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "        # Weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.accuracy],\n",
    "                        feed_dict = feed_dict)\n",
    "        # Compute average loss\n",
    "        avg_cost = outs[1]\n",
    "        if FLAGS.verbose:\n",
    "            # Display epoch information\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
    "                  \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "            # Validation (implemented for Task 1 only)\n",
    "            if FLAGS.validation and FLAGS.task == 'task_1':\n",
    "                feed_dict.update({placeholders['dropout']: 0})\n",
    "                emb = sess.run(model.z_mean, feed_dict = feed_dict)\n",
    "                feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "                val_roc, val_ap = compute_scores(val_edges, val_edges_false, emb)\n",
    "                print(\"val_roc=\", \"{:.5f}\".format(val_roc), \"val_ap=\", \"{:.5f}\".format(val_ap))\n",
    "\n",
    "    # Compute total running time\n",
    "    mean_time.append(time.time() - t_start)\n",
    "\n",
    "    # Get embedding from model\n",
    "    emb = sess.run(model.z_mean, feed_dict = feed_dict)\n",
    "\n",
    "    # Test model\n",
    "    if FLAGS.verbose:\n",
    "        print(\"Testing model...\")\n",
    "    # Compute ROC and AP scores on test sets\n",
    "    roc_score, ap_score = compute_scores(test_edges, test_edges_false, emb)\n",
    "    # Append to list of scores over all runs\n",
    "    mean_roc.append(roc_score)\n",
    "    mean_ap.append(ap_score)\n",
    "\n",
    "# Report final results\n",
    "print(\"\\nTest results for\", FLAGS.model,\n",
    "      \"model on\", FLAGS.dataset, \"on\", FLAGS.task, \"\\n\",\n",
    "      \"___________________________________________________\\n\")\n",
    "\n",
    "print(\"AUC scores\\n\", mean_roc)\n",
    "print(\"Mean AUC score: \", np.mean(mean_roc),\n",
    "      \"\\nStd of AUC scores: \", np.std(mean_roc), \"\\n \\n\")\n",
    "\n",
    "print(\"AP scores \\n\", mean_ap)\n",
    "print(\"Mean AP score: \", np.mean(mean_ap),\n",
    "      \"\\nStd of AP scores: \", np.std(mean_ap), \"\\n \\n\")\n",
    "\n",
    "print(\"Running times\\n\", mean_time)\n",
    "print(\"Mean running time: \", np.mean(mean_time),\n",
    "      \"\\nStd of running time: \", np.std(mean_time), \"\\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3e0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.15",
   "language": "python",
   "name": "tf1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
