{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2938d46b",
   "metadata": {},
   "source": [
    "# 加载库函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c60c69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:33.003039Z",
     "start_time": "2022-10-16T05:34:28.188230Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "import networkx.algorithms.isomorphism as iso\n",
    "import itertools\n",
    "import os.path\n",
    "import subprocess\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import os\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import json\n",
    "import scipy.io as sio\n",
    "from torch.nn import Embedding\n",
    "#import scipy.sparse as spsparse\n",
    "from torch.nn import Parameter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1088d83",
   "metadata": {},
   "source": [
    "# 加载数据，数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "879b783f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:33.034620Z",
     "start_time": "2022-10-16T05:34:33.020755Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Disclaimer: functions defined from lines 15 to 36 in this file come from \n",
    "tkipf/gae original repository on Graph Autoencoders. Moreover, the\n",
    "mask_test_edges_general_link_prediction function is borrowed from \n",
    "philipjackson's mask_test_edges pull request on this same repository.\n",
    "\"\"\"\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7527502",
   "metadata": {},
   "source": [
    "# 任务一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcd14ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:33.082464Z",
     "start_time": "2022-10-16T05:34:33.053183Z"
    }
   },
   "outputs": [],
   "source": [
    "def mask_test_edges_general_link_prediction(adj, test_percent=10., val_percent=5.):\n",
    "    \"\"\"\n",
    "    Task 1: General Directed Link Prediction: get Train/Validation/Test\n",
    "\n",
    "    :param adj: complete sparse adjacency matrix of the graph\n",
    "    :param test_percent: percentage of edges in test set\n",
    "    :param val_percent: percentage of edges in validation set\n",
    "    :return: train incomplete adjacency matrix, validation and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove diagonal elements of adjacency matrix\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[None, :], [0]), shape = adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "    edges_positive, _, _ = sparse_to_tuple(adj)\n",
    "\n",
    "    # Number of positive (and negative) edges in test and val sets:\n",
    "    num_test = int(np.floor(edges_positive.shape[0] / (100. / test_percent)))\n",
    "    num_val = int(np.floor(edges_positive.shape[0] / (100. / val_percent)))\n",
    "\n",
    "    # Sample positive edges for test and val sets:\n",
    "    edges_positive_idx = np.arange(edges_positive.shape[0])\n",
    "    np.random.shuffle(edges_positive_idx)\n",
    "    val_edge_idx = edges_positive_idx[:num_val]\n",
    "    # positive val edges\n",
    "    val_edges = edges_positive[val_edge_idx]\n",
    "    test_edge_idx = edges_positive_idx[num_val:(num_val + num_test)]\n",
    "    # positive test edges\n",
    "    test_edges = edges_positive[test_edge_idx]\n",
    "    # positive train edges\n",
    "    train_edges = np.delete(edges_positive, np.hstack([test_edge_idx, val_edge_idx]), axis = 0)\n",
    "\n",
    "    # (Text from philipjackson)\n",
    "    # The above strategy for sampling without replacement will not work for sampling\n",
    "    # negative edges on large graphs, because the pool of negative edges\n",
    "    # is much much larger due to sparsity, therefore we'll use the following strategy:\n",
    "    # 1. sample random linear indices from adjacency matrix WITH REPLACEMENT\n",
    "    # (without replacement is super slow). sample more than we need so we'll probably\n",
    "    # have enough after all the filtering steps.\n",
    "    # 2. remove any edges that have already been added to the other edge lists\n",
    "    # 3. convert to (i,j) coordinates\n",
    "    # 4. remove any duplicate elements if there are any\n",
    "    # 5. remove any diagonal elements\n",
    "    # 6. if we don't have enough edges, repeat this process until we get enough\n",
    "    positive_idx, _, _ = sparse_to_tuple(adj) # [i,j] coord pairs for all true edges\n",
    "    positive_idx = positive_idx[:,0]*adj.shape[0] + positive_idx[:,1] # linear indices\n",
    "    # Test set\n",
    "    test_edges_false = np.empty((0,2),dtype='int64')\n",
    "    idx_test_edges_false = np.empty((0,),dtype='int64')\n",
    "    while len(test_edges_false) < len(test_edges):\n",
    "        # step 1:\n",
    "        idx = np.random.choice(adj.shape[0]**2, 2*(num_test - len(test_edges_false)), replace = True)\n",
    "        # step 2:\n",
    "        idx = idx[~np.in1d(idx, positive_idx, assume_unique = True)]\n",
    "        idx = idx[~np.in1d(idx, idx_test_edges_false, assume_unique = True)]\n",
    "        # step 3:\n",
    "        rowidx = idx // adj.shape[0]\n",
    "        colidx = idx % adj.shape[0]\n",
    "        coords = np.vstack((rowidx, colidx)).transpose()\n",
    "        # step 4:\n",
    "        coords = np.unique(coords, axis=0)\n",
    "        np.random.shuffle(coords)\n",
    "        # step 5:\n",
    "        coords = coords[coords[:,0] != coords[:,1]]\n",
    "        # step 6:\n",
    "        coords = coords[:min(num_test, len(idx))]\n",
    "        test_edges_false = np.append(test_edges_false, coords, axis = 0)\n",
    "        idx = idx[:min(num_test, len(idx))]\n",
    "        idx_test_edges_false = np.append(idx_test_edges_false, idx)\n",
    "\n",
    "    # Validation set\n",
    "    val_edges_false = np.empty((0,2), dtype = 'int64')\n",
    "    idx_val_edges_false = np.empty((0,), dtype = 'int64')\n",
    "    while len(val_edges_false) < len(val_edges):\n",
    "        # step 1:\n",
    "        idx = np.random.choice(adj.shape[0]**2, 2*(num_val - len(val_edges_false)), replace = True)\n",
    "        # step 2:\n",
    "        idx = idx[~np.in1d(idx, positive_idx, assume_unique = True)]\n",
    "        idx = idx[~np.in1d(idx, idx_test_edges_false, assume_unique = True)]\n",
    "        idx = idx[~np.in1d(idx, idx_val_edges_false, assume_unique = True)]\n",
    "        # step 3:\n",
    "        rowidx = idx // adj.shape[0]\n",
    "        colidx = idx % adj.shape[0]\n",
    "        coords = np.vstack((rowidx, colidx)).transpose()\n",
    "        # step 4:\n",
    "        coords = np.unique(coords, axis = 0)\n",
    "        np.random.shuffle(coords)\n",
    "        # step 5:\n",
    "        coords = coords[coords[:,0] != coords[:,1]]\n",
    "        # step 6:\n",
    "        coords = coords[:min(num_val, len(idx))]\n",
    "        val_edges_false = np.append(val_edges_false, coords, axis=0)\n",
    "        idx = idx[:min(num_val, len(idx))]\n",
    "        idx_val_edges_false = np.append(idx_val_edges_false, idx)\n",
    "\n",
    "    # Sanity checks:\n",
    "    train_edges_linear = train_edges[:,0]*adj.shape[0] + train_edges[:,1]\n",
    "    test_edges_linear = test_edges[:,0]*adj.shape[0] + test_edges[:,1]\n",
    "    assert not np.any(np.in1d(idx_test_edges_false, positive_idx))\n",
    "    assert not np.any(np.in1d(idx_val_edges_false, positive_idx))\n",
    "    assert not np.any(np.in1d(val_edges[:,0]*adj.shape[0] + val_edges[:,1], train_edges_linear))\n",
    "    assert not np.any(np.in1d(test_edges_linear, train_edges_linear))\n",
    "    assert not np.any(np.in1d(val_edges[:,0]*adj.shape[0] + val_edges[:,1], test_edges_linear))\n",
    "\n",
    "    # Re-build train adjacency matrix\n",
    "    #data = np.ones(train_edges.shape[0])\n",
    "    #adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape = adj.shape)\n",
    "\n",
    "    return train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef384c",
   "metadata": {},
   "source": [
    "# 任务二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a97e19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:33.113149Z",
     "start_time": "2022-10-16T05:34:33.098621Z"
    }
   },
   "outputs": [],
   "source": [
    "def mask_test_edges_biased_negative_samples(adj, test_percent=10.):\n",
    "    \"\"\"\n",
    "    Task 2: General Biased Negative Samples (B.N.S.) Directed Link\n",
    "    Prediction: get Train and Test sets\n",
    "\n",
    "    :param adj: complete sparse adjacency matrix of the graph\n",
    "    :param test_percent: percentage of edges in test set\n",
    "    :return: train incomplete adjacency matrix and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove diagonal elements of adjacency matrix\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[None, :], [0]), shape = adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "    val_edges, val_edges_false, test_edges, test_edges_false = None, None, None, None\n",
    "\n",
    "    ## Retrieve all unidirectional edges\n",
    "    adj_sym = (adj + adj.T).sign()\n",
    "    adj_tilde = (adj_sym - adj).T\n",
    "    adj_tilde.eliminate_zeros()\n",
    "    edges_positive, _, _ = sparse_to_tuple(adj_tilde)\n",
    "\n",
    "    # Number of positive (= to number of negative) test node pairs to sample\n",
    "    num_test = int(np.floor(edges_positive.shape[0] / (100. / test_percent)))\n",
    "\n",
    "    # Sampling of positive node pairs\n",
    "    edges_idx = np.arange(edges_positive.shape[0])\n",
    "    np.random.shuffle(edges_idx)\n",
    "    test_edges_idx = edges_idx[:num_test]\n",
    "    test_edges = edges_positive[test_edges_idx]\n",
    "\n",
    "    # In this setting, the reverse node pairs constitute negative samples\n",
    "    test_edges_false = np.fliplr(test_edges)\n",
    "\n",
    "    # Get training incomplete adjacency matrix\n",
    "    train_edges = np.delete(edges_positive, np.hstack([test_edges_idx]), axis = 0)\n",
    "    #data = np.ones(train_edges.shape[0])\n",
    "    #adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape = adj.shape)\n",
    "\n",
    "    # Validation set: not implemented for Task 2\n",
    "    # therefore, val_edges and val_edges_false are None\n",
    "    return train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a8882",
   "metadata": {},
   "source": [
    "# 任务三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5181a68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:33.143897Z",
     "start_time": "2022-10-16T05:34:33.130259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3 - Bidirectional Link Prediction\n",
    "def mask_test_edges_bidirectional_link_prediction(adj):\n",
    "    \"\"\"\n",
    "    Task 3: Bidirectionality Prediction: get Train and Test sets\n",
    "\n",
    "    :param adj: complete sparse adjacency matrix of the graph\n",
    "    :return: train incomplete adjacency matrix and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove diagonal elements\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[None, :], [0]), shape = adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "    val_edges, val_edges_false, test_edges, test_edges_false = None, None, None, None\n",
    "\n",
    "    ## Unidirectional edges\n",
    "    adj_sym = (adj + adj.T).sign()\n",
    "    adj_tilde = (adj_sym - adj).T\n",
    "    adj_tilde.eliminate_zeros()\n",
    "\n",
    "    ## Bidirectional edges (they usually are few, so they are all in test set)\n",
    "    adj_sym_ones = adj - adj_tilde\n",
    "    adj_sym_ones.eliminate_zeros()\n",
    "\n",
    "    # Positive node pairs in test set (bidirectional edges)\n",
    "    test_edges, _, _ = sparse_to_tuple(adj_sym_ones)\n",
    "    test_edges = test_edges[test_edges[:,1] > test_edges[:,0],:]\n",
    "\n",
    "    # Negative node pairs in test set (unidirectional edges)\n",
    "    test_edges_false, _, _ = sparse_to_tuple(adj_tilde)\n",
    "    test_edges_false = test_edges_false[test_edges_false[:,0] > test_edges_false[:,1],:]\n",
    "    test_edges_false = np.fliplr(test_edges_false)\n",
    "    # Sampling of negative node pairs\n",
    "    edges_negative_idx = np.arange(test_edges_false.shape[0])\n",
    "    np.random.shuffle(edges_negative_idx)\n",
    "    test_edges_false_idx = edges_negative_idx[:test_edges.shape[0]]\n",
    "    test_edges_false = test_edges_false[test_edges_false_idx]\n",
    "\n",
    "    # Get training incomplete adjacency matrix\n",
    "    # 1 of the 2 directions of each bidirectional edge is masked\n",
    "    adj_train = (adj - sp.triu(adj_sym_ones))\n",
    "\n",
    "    # Validation set: not implemented for Task 2\n",
    "    # val_edges and val_edges_false are None\n",
    "    return adj_train, val_edges, val_edges_false, test_edges, test_edges_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1ff001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:33.174289Z",
     "start_time": "2022-10-16T05:34:33.160254Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    \"\"\" Load datasets from text files\n",
    "\n",
    "    :param dataset: 'cora', 'citeseer' or 'google' graph dataset.\n",
    "    :return: n*n sparse adjacency matrix and n*f node-level feature matrix\n",
    "\n",
    "    Note: in this paper, all three datasets are assumed to be featureless.\n",
    "    As a consequence, the feature matrix is the identity matrix I_n.\n",
    "    \"\"\"\n",
    "    if dataset == 'cora':\n",
    "        adj = nx.adjacency_matrix(nx.read_edgelist(\"directed_data/cora.cites\",\n",
    "                                                   delimiter='\\t',\n",
    "                                                   create_using=nx.DiGraph()))\n",
    "        # Transpose the adjacency matrix, as Cora raw dataset comes with a\n",
    "        # <ID of cited paper> <ID of citing paper> edgelist format.\n",
    "        adj = adj.T\n",
    "        features = sp.identity(adj.shape[0])\n",
    "\n",
    "    elif dataset == 'citeseer':\n",
    "        adj = nx.adjacency_matrix(nx.read_edgelist(\"directed_data/citeseer.cites\",\n",
    "                                                   delimiter='\\t',\n",
    "                                                   create_using=nx.DiGraph()))\n",
    "        # Transpose the adjacency matrix, as Citeseer raw dataset comes with a\n",
    "        # <ID of cited paper> <ID of citing paper> edgelist format.\n",
    "        adj = adj.T\n",
    "        features = sp.identity(adj.shape[0])\n",
    "\n",
    "    elif dataset == 'google':\n",
    "        adj = nx.adjacency_matrix(nx.read_edgelist(\"directed_data/GoogleNw.txt\",\n",
    "                                                   delimiter='\\t',\n",
    "                                                   create_using=nx.DiGraph()))\n",
    "        features = sp.identity(adj.shape[0])\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Undefined dataset!')\n",
    "\n",
    "    return adj, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46111276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:33.205372Z",
     "start_time": "2022-10-16T05:34:33.191254Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_graph(DATASET='cora', task=1):\n",
    "    adj_init, features = load_data(DATASET)\n",
    "    if task==1:\n",
    "        train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges_general_link_prediction(adj_init, 10, 5)\n",
    "    elif task==2:\n",
    "        train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges_biased_negative_samples(adj_init)\n",
    "    else:\n",
    "        train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges_bidirectional_link_prediction(adj_init)\n",
    "    \n",
    "    all_negative_edges = np.argwhere(adj_init.toarray()==0)\n",
    "    \n",
    "    if task==2 or task==3:\n",
    "        all_train_edges_false = np.delete(all_negative_edges, test_edges_false, axis = 0)\n",
    "    else:\n",
    "        all_train_edges_false = np.delete(all_negative_edges, np.vstack([test_edges_false, val_edges_false]), axis = 0)\n",
    "    \n",
    "    if DATASET=='cora':\n",
    "        nodes_number = 2708\n",
    "    elif DATASET=='citeseer':\n",
    "        nodes_number = 3327\n",
    "    \n",
    "    ################## 处理测试集  #############################\n",
    "    test_posi_mask = [test_edges[i][0]*nodes_number+test_edges[i][1] for i in range(len(test_edges))]\n",
    "    test_false_mask = [test_edges_false[i][0]*nodes_number+test_edges_false[i][1] for i in range(len(test_edges_false))]\n",
    "    test_mask = test_posi_mask + test_false_mask\n",
    "    test_mask = torch.tensor(test_mask)\n",
    "    test_edge_true_or_false = torch.zeros(len(test_mask))\n",
    "    test_edge_true_or_false[:len(test_posi_mask)] = 1\n",
    "    \n",
    "    ############### 处理训练集  ################################\n",
    "    negative_index = np.random.choice(range(all_train_edges_false.shape[0]), train_edges.shape[0], replace=False)\n",
    "    train_edges_false = all_train_edges_false[negative_index]\n",
    "    train_posi_mask = [train_edges[i][0]*nodes_number+train_edges[i][1] for i in range(len(train_edges))]\n",
    "    train_false_mask = [train_edges_false[i][0]*nodes_number+train_edges_false[i][1] for i in range(len(train_edges_false))]\n",
    "    train_mask = train_posi_mask + train_false_mask\n",
    "    train_mask = torch.tensor(train_mask)\n",
    "    #train_mask = torch.tensor(train_posi_mask)\n",
    "    train_edge_true_or_false = torch.zeros(len(train_mask))\n",
    "    train_edge_true_or_false[:len(train_posi_mask)] = 1\n",
    "    \n",
    "    return train_edge_true_or_false, test_edge_true_or_false, train_mask.long(), test_mask.long(), nodes_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d97a2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:33.235771Z",
     "start_time": "2022-10-16T05:34:33.222256Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_edge, test_edge, train_mask, test_mask, nodes_number = get_graph(task=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e2789",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5dc8f52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:33.654656Z",
     "start_time": "2022-10-16T05:34:33.622292Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_acc(recons_edges, true_edges):\n",
    "    predict_graph = recons_edges\n",
    "    predict_edges = np.array(predict_graph)\n",
    "    ap = average_precision_score(true_edges, predict_edges)\n",
    "    auc = roc_auc_score(true_edges, predict_edges)\n",
    "    print(\"AP SCORE： \", ap)\n",
    "    print(\"AUC SCORE: \", auc)\n",
    "    return ap, auc\n",
    "\n",
    "################  更新节点内容  #######################################\n",
    "class reconstruction_graph(nn.Module):\n",
    "    \"\"\"给定类簇质心，更新节点嵌入\"\"\"\n",
    "    def __init__(self, context_embedding):\n",
    "        super(reconstruction_graph, self).__init__()\n",
    "        self.context_embedding = Parameter(context_embedding)\n",
    "        \n",
    "    def forward(self, importance_embedding):\n",
    "        power = float(ALPHA + 1) / 2    # 计算幂\n",
    "        \n",
    "        # 计算节点之间的距离 ： 值越小越有利于边的形成\n",
    "        nodes_distance = torch.norm(self.context_embedding[:, None]-self.context_embedding, dim=2, p=2)\n",
    "        nodes_distance = 1.0 + nodes_distance\n",
    "        \n",
    "        # 计算节点之间的重要性：值越大越有利于边的形成\n",
    "        norm_squared = torch.sum((self.context_embedding.unsqueeze(1) - importance_embedding)**2, 2)\n",
    "        nodes_importance = N / (1.0 + norm_squared) + 1.0\n",
    "        importance_prod = torch.mm(nodes_importance, nodes_importance.t())   # 分子\n",
    "        importance_norm = torch.norm(nodes_importance, p=2, dim=1).unsqueeze(0)   #分母(每行的长度)\n",
    "        importance_norm = importance_norm**2\n",
    "        importance_similar = importance_prod.div(importance_norm.t())\n",
    "        \n",
    "        # 计算边的形成概率\n",
    "        nodes_similar = torch.div(beta*importance_similar, nodes_distance)\n",
    "        #return 2*sigmoid_modle(nodes_similar)-1\n",
    "        return torch.exp(-nodes_similar)\n",
    "        \n",
    "    \n",
    "class update_nodes_embedding(nn.Module):\n",
    "    def __init__(self, context_embedding):\n",
    "        super(update_nodes_embedding, self).__init__()\n",
    "        self.reconstruction_module = reconstruction_graph(context_embedding)     # 更新节点嵌入\n",
    "        self.optimizer = torch.optim.SGD(params=self.reconstruction_module.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "        self.loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "        \n",
    "    def forward(self, train_edges, test_edges, edge_train_mask, edge_test_mask, importance_embedding):\n",
    "        self.reconstruction_module.train()\n",
    "        for epoch in range(EPOCH):\n",
    "            self.optimizer.zero_grad()\n",
    "            graph_reconstruction = self.reconstruction_module(importance_embedding)\n",
    "            graph_train = torch.take(graph_reconstruction, edge_train_mask)\n",
    "            loss = self.loss_function(train_edges, graph_train)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            print(f'Epoch: {epoch:02d}, Loss: {loss.item():.4f}')\n",
    "        recons_test_edges = torch.take(graph_reconstruction, edge_test_mask).detach()\n",
    "        ap, auc = predict_acc(recons_test_edges, test_edges)\n",
    "        return self.reconstruction_module.context_embedding.detach(), ap, auc\n",
    "\n",
    "####################  更新节点重要性  ######################################\n",
    "class reconstruction_graph_importance(nn.Module):\n",
    "    \"\"\"给定类簇质心，更新节点嵌入\"\"\"\n",
    "    def __init__(self, importance_embedding):\n",
    "        super(reconstruction_graph_importance, self).__init__()\n",
    "        self.importance_embedding = Parameter(importance_embedding)\n",
    "        \n",
    "    def forward(self, context_embedding):\n",
    "        power = float(ALPHA + 1) / 2    # 计算幂\n",
    "        \n",
    "        # 计算节点之间的距离 ： 值越小越有利于边的形成\n",
    "        nodes_distance = torch.norm(context_embedding[:, None]-context_embedding, dim=2, p=2)\n",
    "        nodes_distance = 1.0 + nodes_distance\n",
    "        \n",
    "        # 计算节点之间的重要性：值越大越有利于边的形成\n",
    "        norm_squared = torch.sum((context_embedding.unsqueeze(1) - self.importance_embedding)**2, 2)\n",
    "        nodes_importance = N / (1.0 + norm_squared) + 1.0\n",
    "        importance_prod = torch.mm(nodes_importance, nodes_importance.t())   # 分子\n",
    "        importance_norm = torch.norm(nodes_importance, p=2, dim=1).unsqueeze(0)   #分母(每行的长度)\n",
    "        importance_norm = importance_norm**2\n",
    "        importance_similar = importance_prod.div(importance_norm.t())\n",
    "        \n",
    "        # 计算边的形成概率\n",
    "        nodes_similar = torch.div(beta*importance_similar, nodes_distance)\n",
    "        #return 2*sigmoid_modle(nodes_similar)-1\n",
    "        return torch.exp(-nodes_similar)\n",
    "\n",
    "class update_nodes_embedding_importance(nn.Module):\n",
    "    def __init__(self, importance_embedding):\n",
    "        super(update_nodes_embedding_importance, self).__init__()\n",
    "        self.reconstruction_module = reconstruction_graph_importance(importance_embedding)     # 更新节点嵌入\n",
    "        self.optimizer = torch.optim.SGD(params=self.reconstruction_module.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "        self.loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "        \n",
    "    def forward(self, train_edges, test_edges, edge_train_mask, edge_test_mask, context_embedding):\n",
    "        self.reconstruction_module.train()\n",
    "        for epoch in range(EPOCH):\n",
    "            self.optimizer.zero_grad()\n",
    "            graph_reconstruction = self.reconstruction_module(context_embedding)\n",
    "            graph_train = torch.take(graph_reconstruction, edge_train_mask)\n",
    "            loss = self.loss_function(train_edges, graph_train)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            print(f'Epoch: {epoch:02d}, Loss: {loss.item():.4f}')\n",
    "        recons_test_edges = torch.take(graph_reconstruction, edge_test_mask).detach()\n",
    "        ap, auc = predict_acc(recons_test_edges, test_edges)\n",
    "        return self.reconstruction_module.importance_embedding.detach(), ap, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70d5c460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T05:34:34.075160Z",
     "start_time": "2022-10-16T05:34:34.068147Z"
    }
   },
   "outputs": [],
   "source": [
    "context_embedding_dim = 12\n",
    "importance_embedding_dim = 48\n",
    "beta = 5.0\n",
    "ALPHA = 1.0\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "EPOCH = 5\n",
    "N = 25.0    # 目前25最佳\n",
    "sigmoid_modle = torch.nn.Sigmoid()\n",
    "\n",
    "dataset = 'cora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd9c1eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T06:02:53.832461Z",
     "start_time": "2022-10-16T05:34:34.533142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### 模块循环 ： 0 ##########################\n",
      "Epoch: 00, Loss: 2453.3003\n",
      "Epoch: 01, Loss: 2442.0999\n",
      "Epoch: 02, Loss: 2421.7202\n",
      "Epoch: 03, Loss: 2394.8330\n",
      "Epoch: 04, Loss: 2364.2095\n",
      "AP SCORE：  0.5224825737713961\n",
      "AUC SCORE:  0.5347061157226562\n",
      "Epoch: 00, Loss: 2312.9524\n",
      "Epoch: 01, Loss: 2282.5803\n",
      "Epoch: 02, Loss: 2252.8315\n",
      "Epoch: 03, Loss: 2223.9336\n",
      "Epoch: 04, Loss: 2195.9570\n",
      "AP SCORE：  0.6043222231261123\n",
      "AUC SCORE:  0.5875587463378906\n",
      "######################### 模块循环 ： 1 ##########################\n",
      "Epoch: 00, Loss: 2168.9048\n",
      "Epoch: 01, Loss: 2165.6868\n",
      "Epoch: 02, Loss: 2159.6211\n",
      "Epoch: 03, Loss: 2151.0808\n",
      "Epoch: 04, Loss: 2140.4272\n",
      "AP SCORE：  0.6312418641043818\n",
      "AUC SCORE:  0.6079940795898438\n",
      "Epoch: 00, Loss: 2128.0027\n",
      "Epoch: 01, Loss: 2114.1240\n",
      "Epoch: 02, Loss: 2099.0789\n",
      "Epoch: 03, Loss: 2083.1208\n",
      "Epoch: 04, Loss: 2066.4731\n",
      "AP SCORE：  0.6638308060209772\n",
      "AUC SCORE:  0.6359024047851562\n",
      "######################### 模块循环 ： 2 ##########################\n",
      "Epoch: 00, Loss: 2049.3264\n",
      "Epoch: 01, Loss: 2046.9233\n",
      "Epoch: 02, Loss: 2042.3810\n",
      "Epoch: 03, Loss: 2035.9535\n",
      "Epoch: 04, Loss: 2027.8846\n",
      "AP SCORE：  0.6793045548021381\n",
      "AUC SCORE:  0.6501350402832031\n",
      "Epoch: 00, Loss: 2018.4027\n",
      "Epoch: 01, Loss: 2007.7189\n",
      "Epoch: 02, Loss: 1996.0266\n",
      "Epoch: 03, Loss: 1983.5001\n",
      "Epoch: 04, Loss: 1970.2958\n",
      "AP SCORE：  0.7008053126701632\n",
      "AUC SCORE:  0.6696701049804688\n",
      "######################### 模块循环 ： 3 ##########################\n",
      "Epoch: 00, Loss: 1956.5516\n",
      "Epoch: 01, Loss: 1954.5693\n",
      "Epoch: 02, Loss: 1950.8164\n",
      "Epoch: 03, Loss: 1945.4946\n",
      "Epoch: 04, Loss: 1938.7941\n",
      "AP SCORE：  0.7112161142600167\n",
      "AUC SCORE:  0.679290771484375\n",
      "Epoch: 00, Loss: 1930.8911\n",
      "Epoch: 01, Loss: 1921.9498\n",
      "Epoch: 02, Loss: 1912.1193\n",
      "Epoch: 03, Loss: 1901.5358\n",
      "Epoch: 04, Loss: 1890.3220\n",
      "AP SCORE：  0.7262607381021429\n",
      "AUC SCORE:  0.6935691833496094\n",
      "######################### 模块循环 ： 4 ##########################\n",
      "Epoch: 00, Loss: 1878.5875\n",
      "Epoch: 01, Loss: 1876.8698\n",
      "Epoch: 02, Loss: 1873.6154\n",
      "Epoch: 03, Loss: 1868.9946\n",
      "Epoch: 04, Loss: 1863.1664\n",
      "AP SCORE：  0.7340600829902058\n",
      "AUC SCORE:  0.7007598876953125\n",
      "Epoch: 00, Loss: 1856.2782\n",
      "Epoch: 01, Loss: 1848.4661\n",
      "Epoch: 02, Loss: 1839.8538\n",
      "Epoch: 03, Loss: 1830.5549\n",
      "Epoch: 04, Loss: 1820.6719\n",
      "AP SCORE：  0.7453456931484636\n",
      "AUC SCORE:  0.7115211486816406\n",
      "######################### 模块循环 ： 5 ##########################\n",
      "Epoch: 00, Loss: 1810.2966\n",
      "Epoch: 01, Loss: 1808.7644\n",
      "Epoch: 02, Loss: 1805.8600\n",
      "Epoch: 03, Loss: 1801.7324\n",
      "Epoch: 04, Loss: 1796.5210\n",
      "AP SCORE：  0.751464031445668\n",
      "AUC SCORE:  0.7174797058105469\n",
      "Epoch: 00, Loss: 1790.3533\n",
      "Epoch: 01, Loss: 1783.3470\n",
      "Epoch: 02, Loss: 1775.6104\n",
      "Epoch: 03, Loss: 1767.2411\n",
      "Epoch: 04, Loss: 1758.3276\n",
      "AP SCORE：  0.7605721952229887\n",
      "AUC SCORE:  0.7263107299804688\n",
      "######################### 模块循环 ： 6 ##########################\n",
      "Epoch: 00, Loss: 1748.9510\n",
      "Epoch: 01, Loss: 1747.5583\n",
      "Epoch: 02, Loss: 1744.9174\n",
      "Epoch: 03, Loss: 1741.1624\n",
      "Epoch: 04, Loss: 1736.4172\n",
      "AP SCORE：  0.7655873003368171\n",
      "AUC SCORE:  0.7311134338378906\n",
      "Epoch: 00, Loss: 1730.7966\n",
      "Epoch: 01, Loss: 1724.4050\n",
      "Epoch: 02, Loss: 1717.3386\n",
      "Epoch: 03, Loss: 1709.6848\n",
      "Epoch: 04, Loss: 1701.5221\n",
      "AP SCORE：  0.7730689275377425\n",
      "AUC SCORE:  0.7384071350097656\n",
      "######################### 模块循环 ： 7 ##########################\n",
      "Epoch: 00, Loss: 1692.9232\n",
      "Epoch: 01, Loss: 1691.6410\n",
      "Epoch: 02, Loss: 1689.2086\n",
      "Epoch: 03, Loss: 1685.7493\n",
      "Epoch: 04, Loss: 1681.3754\n",
      "AP SCORE：  0.7770641721248759\n",
      "AUC SCORE:  0.7423515319824219\n",
      "Epoch: 00, Loss: 1676.1913\n",
      "Epoch: 01, Loss: 1670.2919\n",
      "Epoch: 02, Loss: 1663.7639\n",
      "Epoch: 03, Loss: 1656.6870\n",
      "Epoch: 04, Loss: 1649.1326\n",
      "AP SCORE：  0.7829734441310466\n",
      "AUC SCORE:  0.7481002807617188\n",
      "######################### 模块循环 ： 8 ##########################\n",
      "Epoch: 00, Loss: 1641.1665\n",
      "Epoch: 01, Loss: 1639.9752\n",
      "Epoch: 02, Loss: 1637.7153\n",
      "Epoch: 03, Loss: 1634.5002\n",
      "Epoch: 04, Loss: 1630.4336\n",
      "AP SCORE：  0.785874451234544\n",
      "AUC SCORE:  0.750946044921875\n",
      "Epoch: 00, Loss: 1625.6116\n",
      "Epoch: 01, Loss: 1620.1215\n",
      "Epoch: 02, Loss: 1614.0428\n",
      "Epoch: 03, Loss: 1607.4490\n",
      "Epoch: 04, Loss: 1600.4054\n",
      "AP SCORE：  0.7909346851417567\n",
      "AUC SCORE:  0.7560615539550781\n",
      "######################### 模块循环 ： 9 ##########################\n",
      "Epoch: 00, Loss: 1592.9728\n",
      "Epoch: 01, Loss: 1591.8591\n",
      "Epoch: 02, Loss: 1589.7461\n",
      "Epoch: 03, Loss: 1586.7399\n",
      "Epoch: 04, Loss: 1582.9360\n",
      "AP SCORE：  0.7937233136977124\n",
      "AUC SCORE:  0.7588615417480469\n",
      "Epoch: 00, Loss: 1578.4244\n",
      "Epoch: 01, Loss: 1573.2855\n",
      "Epoch: 02, Loss: 1567.5936\n",
      "Epoch: 03, Loss: 1561.4165\n",
      "Epoch: 04, Loss: 1554.8156\n",
      "AP SCORE：  0.7980153698436567\n",
      "AUC SCORE:  0.7632331848144531\n",
      "######################### 模块循环 ： 10 ##########################\n",
      "Epoch: 00, Loss: 1547.8463\n",
      "Epoch: 01, Loss: 1546.8008\n",
      "Epoch: 02, Loss: 1544.8168\n",
      "Epoch: 03, Loss: 1541.9932\n",
      "Epoch: 04, Loss: 1538.4209\n",
      "AP SCORE：  0.8004630826809311\n",
      "AUC SCORE:  0.765625\n",
      "Epoch: 00, Loss: 1534.1821\n",
      "Epoch: 01, Loss: 1529.3534\n",
      "Epoch: 02, Loss: 1524.0035\n",
      "Epoch: 03, Loss: 1518.1959\n",
      "Epoch: 04, Loss: 1511.9880\n",
      "AP SCORE：  0.8042630798404038\n",
      "AUC SCORE:  0.7694282531738281\n",
      "######################### 模块循环 ： 11 ##########################\n",
      "Epoch: 00, Loss: 1505.4319\n",
      "Epoch: 01, Loss: 1504.4475\n",
      "Epoch: 02, Loss: 1502.5795\n",
      "Epoch: 03, Loss: 1499.9204\n",
      "Epoch: 04, Loss: 1496.5559\n",
      "AP SCORE：  0.8063970968299579\n",
      "AUC SCORE:  0.77130126953125\n",
      "Epoch: 00, Loss: 1492.5637\n",
      "Epoch: 01, Loss: 1488.0151\n",
      "Epoch: 02, Loss: 1482.9749\n",
      "Epoch: 03, Loss: 1477.5026\n",
      "Epoch: 04, Loss: 1471.6520\n",
      "AP SCORE：  0.8097844213681593\n",
      "AUC SCORE:  0.7746505737304688\n",
      "######################### 模块循环 ： 12 ##########################\n",
      "Epoch: 00, Loss: 1465.4722\n",
      "Epoch: 01, Loss: 1464.5439\n",
      "Epoch: 02, Loss: 1462.7820\n",
      "Epoch: 03, Loss: 1460.2745\n",
      "Epoch: 04, Loss: 1457.1011\n",
      "AP SCORE：  0.8116101347167268\n",
      "AUC SCORE:  0.7765579223632812\n",
      "Epoch: 00, Loss: 1453.3353\n",
      "Epoch: 01, Loss: 1449.0446\n",
      "Epoch: 02, Loss: 1444.2898\n",
      "Epoch: 03, Loss: 1439.1273\n",
      "Epoch: 04, Loss: 1433.6074\n",
      "AP SCORE：  0.8144791570793299\n",
      "AUC SCORE:  0.7796249389648438\n",
      "######################### 模块循环 ： 13 ##########################\n",
      "Epoch: 00, Loss: 1427.7769\n",
      "Epoch: 01, Loss: 1426.9006\n",
      "Epoch: 02, Loss: 1425.2379\n",
      "Epoch: 03, Loss: 1422.8713\n",
      "Epoch: 04, Loss: 1419.8765\n",
      "AP SCORE：  0.8161387447423268\n",
      "AUC SCORE:  0.7812232971191406\n",
      "Epoch: 00, Loss: 1416.3225\n",
      "Epoch: 01, Loss: 1412.2732\n",
      "Epoch: 02, Loss: 1407.7856\n",
      "Epoch: 03, Loss: 1402.9135\n",
      "Epoch: 04, Loss: 1397.7039\n",
      "AP SCORE：  0.8183365724618126\n",
      "AUC SCORE:  0.7834892272949219\n",
      "######################### 模块循环 ： 14 ##########################\n",
      "Epoch: 00, Loss: 1392.2012\n",
      "Epoch: 01, Loss: 1391.3744\n",
      "Epoch: 02, Loss: 1389.8052\n",
      "Epoch: 03, Loss: 1387.5715\n",
      "Epoch: 04, Loss: 1384.7450\n",
      "AP SCORE：  0.8198389789710773\n",
      "AUC SCORE:  0.7849922180175781\n",
      "Epoch: 00, Loss: 1381.3911\n",
      "Epoch: 01, Loss: 1377.5696\n",
      "Epoch: 02, Loss: 1373.3347\n",
      "Epoch: 03, Loss: 1368.7372\n",
      "Epoch: 04, Loss: 1363.8218\n",
      "AP SCORE：  0.8220714878072193\n",
      "AUC SCORE:  0.7871475219726562\n",
      "######################### 模块循环 ： 15 ##########################\n",
      "Epoch: 00, Loss: 1358.6298\n",
      "Epoch: 01, Loss: 1357.8496\n",
      "Epoch: 02, Loss: 1356.3690\n",
      "Epoch: 03, Loss: 1354.2620\n",
      "Epoch: 04, Loss: 1351.5952\n",
      "AP SCORE：  0.82325344801247\n",
      "AUC SCORE:  0.7882614135742188\n",
      "Epoch: 00, Loss: 1348.4315\n",
      "Epoch: 01, Loss: 1344.8264\n",
      "Epoch: 02, Loss: 1340.8322\n",
      "Epoch: 03, Loss: 1336.4957\n",
      "Epoch: 04, Loss: 1331.8601\n",
      "AP SCORE：  0.8252219569199201\n",
      "AUC SCORE:  0.7902565002441406\n",
      "######################### 模块循环 ： 16 ##########################\n",
      "Epoch: 00, Loss: 1326.9641\n",
      "Epoch: 01, Loss: 1326.2284\n",
      "Epoch: 02, Loss: 1324.8325\n",
      "Epoch: 03, Loss: 1322.8458\n",
      "Epoch: 04, Loss: 1320.3319\n",
      "AP SCORE：  0.8262542620280019\n",
      "AUC SCORE:  0.7912635803222656\n",
      "Epoch: 00, Loss: 1317.3490\n",
      "Epoch: 01, Loss: 1313.9507\n",
      "Epoch: 02, Loss: 1310.1858\n",
      "Epoch: 03, Loss: 1306.0984\n",
      "Epoch: 04, Loss: 1301.7296\n",
      "AP SCORE：  0.8279045797946649\n",
      "AUC SCORE:  0.79302978515625\n",
      "######################### 模块循环 ： 17 ##########################\n",
      "Epoch: 00, Loss: 1297.1160\n",
      "Epoch: 01, Loss: 1296.4229\n",
      "Epoch: 02, Loss: 1295.1077\n",
      "Epoch: 03, Loss: 1293.2358\n",
      "Epoch: 04, Loss: 1290.8676\n",
      "AP SCORE：  0.8288995861762388\n",
      "AUC SCORE:  0.79412841796875\n",
      "Epoch: 00, Loss: 1288.0576\n",
      "Epoch: 01, Loss: 1284.8566\n",
      "Epoch: 02, Loss: 1281.3104\n",
      "Epoch: 03, Loss: 1277.4611\n",
      "Epoch: 04, Loss: 1273.3467\n",
      "AP SCORE：  0.830812710162798\n",
      "AUC SCORE:  0.7959823608398438\n",
      "######################### 模块循环 ： 18 ##########################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Loss: 1269.0023\n",
      "Epoch: 01, Loss: 1268.3499\n",
      "Epoch: 02, Loss: 1267.1115\n",
      "Epoch: 03, Loss: 1265.3496\n",
      "Epoch: 04, Loss: 1263.1199\n",
      "AP SCORE：  0.8315334334460569\n",
      "AUC SCORE:  0.7968215942382812\n",
      "Epoch: 00, Loss: 1260.4751\n",
      "Epoch: 01, Loss: 1257.4619\n",
      "Epoch: 02, Loss: 1254.1241\n",
      "Epoch: 03, Loss: 1250.5015\n",
      "Epoch: 04, Loss: 1246.6299\n",
      "AP SCORE：  0.8328755620457913\n",
      "AUC SCORE:  0.7983932495117188\n",
      "######################### 模块循环 ： 19 ##########################\n",
      "Epoch: 00, Loss: 1242.5420\n",
      "Epoch: 01, Loss: 1241.9280\n",
      "Epoch: 02, Loss: 1240.7632\n",
      "Epoch: 03, Loss: 1239.1053\n",
      "Epoch: 04, Loss: 1237.0079\n",
      "AP SCORE：  0.8336184887004681\n",
      "AUC SCORE:  0.7992439270019531\n",
      "Epoch: 00, Loss: 1234.5198\n",
      "Epoch: 01, Loss: 1231.6854\n",
      "Epoch: 02, Loss: 1228.5461\n",
      "Epoch: 03, Loss: 1225.1388\n",
      "Epoch: 04, Loss: 1221.4974\n",
      "AP SCORE：  0.8347336744652346\n",
      "AUC SCORE:  0.800628662109375\n",
      "######################### 模块循环 ： 20 ##########################\n",
      "Epoch: 00, Loss: 1217.6532\n",
      "Epoch: 01, Loss: 1217.0759\n",
      "Epoch: 02, Loss: 1215.9806\n",
      "Epoch: 03, Loss: 1214.4218\n",
      "Epoch: 04, Loss: 1212.4496\n",
      "AP SCORE：  0.835395653252082\n",
      "AUC SCORE:  0.801422119140625\n",
      "Epoch: 00, Loss: 1210.1101\n",
      "Epoch: 01, Loss: 1207.4451\n",
      "Epoch: 02, Loss: 1204.4934\n",
      "Epoch: 03, Loss: 1201.2902\n",
      "Epoch: 04, Loss: 1197.8669\n",
      "AP SCORE：  0.8364351730576458\n",
      "AUC SCORE:  0.8025856018066406\n",
      "######################### 模块循环 ： 21 ##########################\n",
      "Epoch: 00, Loss: 1194.2528\n",
      "Epoch: 01, Loss: 1193.7101\n",
      "Epoch: 02, Loss: 1192.6803\n",
      "Epoch: 03, Loss: 1191.2148\n",
      "Epoch: 04, Loss: 1189.3610\n",
      "AP SCORE：  0.8370788689686457\n",
      "AUC SCORE:  0.8032913208007812\n",
      "Epoch: 00, Loss: 1187.1615\n",
      "Epoch: 01, Loss: 1184.6565\n",
      "Epoch: 02, Loss: 1181.8818\n",
      "Epoch: 03, Loss: 1178.8705\n",
      "Epoch: 04, Loss: 1175.6526\n",
      "AP SCORE：  0.8382395828149767\n",
      "AUC SCORE:  0.8047065734863281\n",
      "######################### 模块循环 ： 22 ##########################\n",
      "Epoch: 00, Loss: 1172.2552\n",
      "Epoch: 01, Loss: 1171.7449\n",
      "Epoch: 02, Loss: 1170.7769\n",
      "Epoch: 03, Loss: 1169.3992\n",
      "Epoch: 04, Loss: 1167.6560\n",
      "AP SCORE：  0.8388555670634592\n",
      "AUC SCORE:  0.8055038452148438\n",
      "Epoch: 00, Loss: 1165.5884\n",
      "Epoch: 01, Loss: 1163.2333\n",
      "Epoch: 02, Loss: 1160.6245\n",
      "Epoch: 03, Loss: 1157.7933\n",
      "Epoch: 04, Loss: 1154.7678\n",
      "AP SCORE：  0.8396657466570958\n",
      "AUC SCORE:  0.8066940307617188\n",
      "######################### 模块循环 ： 23 ##########################\n",
      "Epoch: 00, Loss: 1151.5734\n",
      "Epoch: 01, Loss: 1151.0936\n",
      "Epoch: 02, Loss: 1150.1831\n",
      "Epoch: 03, Loss: 1148.8876\n",
      "Epoch: 04, Loss: 1147.2483\n",
      "AP SCORE：  0.8402834032397708\n",
      "AUC SCORE:  0.8074073791503906\n",
      "Epoch: 00, Loss: 1145.3036\n",
      "Epoch: 01, Loss: 1143.0886\n",
      "Epoch: 02, Loss: 1140.6350\n",
      "Epoch: 03, Loss: 1137.9719\n",
      "Epoch: 04, Loss: 1135.1260\n",
      "AP SCORE：  0.8413620667486286\n",
      "AUC SCORE:  0.808807373046875\n",
      "######################### 模块循环 ： 24 ##########################\n",
      "Epoch: 00, Loss: 1132.1210\n",
      "Epoch: 01, Loss: 1131.6696\n",
      "Epoch: 02, Loss: 1130.8130\n",
      "Epoch: 03, Loss: 1129.5936\n",
      "Epoch: 04, Loss: 1128.0511\n",
      "AP SCORE：  0.8418742817396666\n",
      "AUC SCORE:  0.8093757629394531\n",
      "Epoch: 00, Loss: 1126.2213\n",
      "Epoch: 01, Loss: 1124.1367\n",
      "Epoch: 02, Loss: 1121.8276\n",
      "Epoch: 03, Loss: 1119.3213\n",
      "Epoch: 04, Loss: 1116.6423\n",
      "AP SCORE：  0.8427249363837415\n",
      "AUC SCORE:  0.8103523254394531\n",
      "######################### 模块循环 ： 25 ##########################\n",
      "Epoch: 00, Loss: 1113.8135\n",
      "Epoch: 01, Loss: 1113.3885\n",
      "Epoch: 02, Loss: 1112.5817\n",
      "Epoch: 03, Loss: 1111.4337\n",
      "Epoch: 04, Loss: 1109.9810\n",
      "AP SCORE：  0.8431927350998731\n",
      "AUC SCORE:  0.8109283447265625\n",
      "Epoch: 00, Loss: 1108.2577\n",
      "Epoch: 01, Loss: 1106.2947\n",
      "Epoch: 02, Loss: 1104.1196\n",
      "Epoch: 03, Loss: 1101.7588\n",
      "Epoch: 04, Loss: 1099.2351\n",
      "AP SCORE：  0.8440171477868494\n",
      "AUC SCORE:  0.8119468688964844\n",
      "######################### 模块循环 ： 26 ##########################\n",
      "Epoch: 00, Loss: 1096.5702\n",
      "Epoch: 01, Loss: 1096.1696\n",
      "Epoch: 02, Loss: 1095.4094\n",
      "Epoch: 03, Loss: 1094.3274\n",
      "Epoch: 04, Loss: 1092.9583\n",
      "AP SCORE：  0.8444555808636605\n",
      "AUC SCORE:  0.8124275207519531\n",
      "Epoch: 00, Loss: 1091.3340\n",
      "Epoch: 01, Loss: 1089.4834\n",
      "Epoch: 02, Loss: 1087.4331\n",
      "Epoch: 03, Loss: 1085.2073\n",
      "Epoch: 04, Loss: 1082.8279\n",
      "AP SCORE：  0.8449980063956583\n",
      "AUC SCORE:  0.8132438659667969\n",
      "######################### 模块循环 ： 27 ##########################\n",
      "Epoch: 00, Loss: 1080.3149\n",
      "Epoch: 01, Loss: 1079.9370\n",
      "Epoch: 02, Loss: 1079.2198\n",
      "Epoch: 03, Loss: 1078.1992\n",
      "Epoch: 04, Loss: 1076.9077\n",
      "AP SCORE：  0.8454558317409084\n",
      "AUC SCORE:  0.8137245178222656\n",
      "Epoch: 00, Loss: 1075.3751\n",
      "Epoch: 01, Loss: 1073.6292\n",
      "Epoch: 02, Loss: 1071.6946\n",
      "Epoch: 03, Loss: 1069.5941\n",
      "Epoch: 04, Loss: 1067.3486\n",
      "AP SCORE：  0.8460504421061783\n",
      "AUC SCORE:  0.8144607543945312\n",
      "######################### 模块循环 ： 28 ##########################\n",
      "Epoch: 00, Loss: 1064.9766\n",
      "Epoch: 01, Loss: 1064.6199\n",
      "Epoch: 02, Loss: 1063.9427\n",
      "Epoch: 03, Loss: 1062.9790\n",
      "Epoch: 04, Loss: 1061.7594\n",
      "AP SCORE：  0.8465063437925842\n",
      "AUC SCORE:  0.8151016235351562\n",
      "Epoch: 00, Loss: 1060.3123\n",
      "Epoch: 01, Loss: 1058.6633\n",
      "Epoch: 02, Loss: 1056.8359\n",
      "Epoch: 03, Loss: 1054.8521\n",
      "Epoch: 04, Loss: 1052.7306\n",
      "AP SCORE：  0.8470227360146942\n",
      "AUC SCORE:  0.8158493041992188\n",
      "######################### 模块循环 ： 29 ##########################\n",
      "Epoch: 00, Loss: 1050.4897\n",
      "Epoch: 01, Loss: 1050.1525\n",
      "Epoch: 02, Loss: 1049.5125\n",
      "Epoch: 03, Loss: 1048.6016\n",
      "Epoch: 04, Loss: 1047.4487\n",
      "AP SCORE：  0.8474469489995801\n",
      "AUC SCORE:  0.816436767578125\n",
      "Epoch: 00, Loss: 1046.0807\n",
      "Epoch: 01, Loss: 1044.5220\n",
      "Epoch: 02, Loss: 1042.7943\n",
      "Epoch: 03, Loss: 1040.9185\n",
      "Epoch: 04, Loss: 1038.9124\n",
      "AP SCORE：  0.848018200771098\n",
      "AUC SCORE:  0.8172607421875\n",
      "######################### 模块循环 ： 30 ##########################\n",
      "Epoch: 00, Loss: 1036.7930\n",
      "Epoch: 01, Loss: 1036.4739\n",
      "Epoch: 02, Loss: 1035.8683\n",
      "Epoch: 03, Loss: 1035.0066\n",
      "Epoch: 04, Loss: 1033.9156\n",
      "AP SCORE：  0.8482774873237023\n",
      "AUC SCORE:  0.8176116943359375\n",
      "Epoch: 00, Loss: 1032.6213\n",
      "Epoch: 01, Loss: 1031.1461\n",
      "Epoch: 02, Loss: 1029.5112\n",
      "Epoch: 03, Loss: 1027.7357\n",
      "Epoch: 04, Loss: 1025.8367\n",
      "AP SCORE：  0.8487284144028948\n",
      "AUC SCORE:  0.8183364868164062\n",
      "######################### 模块循环 ： 31 ##########################\n",
      "Epoch: 00, Loss: 1023.8303\n",
      "Epoch: 01, Loss: 1023.5281\n",
      "Epoch: 02, Loss: 1022.9548\n",
      "Epoch: 03, Loss: 1022.1385\n",
      "Epoch: 04, Loss: 1021.1052\n",
      "AP SCORE：  0.8490095387736004\n",
      "AUC SCORE:  0.8187522888183594\n",
      "Epoch: 00, Loss: 1019.8793\n",
      "Epoch: 01, Loss: 1018.4818\n",
      "Epoch: 02, Loss: 1016.9332\n",
      "Epoch: 03, Loss: 1015.2509\n",
      "Epoch: 04, Loss: 1013.4517\n",
      "AP SCORE：  0.849465139393186\n",
      "AUC SCORE:  0.8194503784179688\n",
      "######################### 模块循环 ： 32 ##########################\n",
      "Epoch: 00, Loss: 1011.5500\n",
      "Epoch: 01, Loss: 1011.2638\n",
      "Epoch: 02, Loss: 1010.7202\n",
      "Epoch: 03, Loss: 1009.9462\n",
      "Epoch: 04, Loss: 1008.9669\n",
      "AP SCORE：  0.8497832099702876\n",
      "AUC SCORE:  0.8199005126953125\n",
      "Epoch: 00, Loss: 1007.8044\n",
      "Epoch: 01, Loss: 1006.4795\n",
      "Epoch: 02, Loss: 1005.0109\n",
      "Epoch: 03, Loss: 1003.4157\n",
      "Epoch: 04, Loss: 1001.7092\n",
      "AP SCORE：  0.8503845770200079\n",
      "AUC SCORE:  0.8206558227539062\n",
      "######################### 模块循环 ： 33 ##########################\n",
      "Epoch: 00, Loss: 999.9056\n",
      "Epoch: 01, Loss: 999.6339\n",
      "Epoch: 02, Loss: 999.1182\n",
      "Epoch: 03, Loss: 998.3839\n",
      "Epoch: 04, Loss: 997.4545\n",
      "AP SCORE：  0.8505959287191518\n",
      "AUC SCORE:  0.8209877014160156\n",
      "Epoch: 00, Loss: 996.3516\n",
      "Epoch: 01, Loss: 995.0942\n",
      "Epoch: 02, Loss: 993.7004\n",
      "Epoch: 03, Loss: 992.1864\n",
      "Epoch: 04, Loss: 990.5666\n",
      "AP SCORE：  0.8510590258534688\n",
      "AUC SCORE:  0.8217048645019531\n",
      "######################### 模块循环 ： 34 ##########################\n",
      "Epoch: 00, Loss: 988.8547\n",
      "Epoch: 01, Loss: 988.5967\n",
      "Epoch: 02, Loss: 988.1069\n",
      "Epoch: 03, Loss: 987.4100\n",
      "Epoch: 04, Loss: 986.5275\n",
      "AP SCORE：  0.8512407915087044\n",
      "AUC SCORE:  0.82208251953125\n",
      "Epoch: 00, Loss: 985.4800\n",
      "Epoch: 01, Loss: 984.2860\n",
      "Epoch: 02, Loss: 982.9625\n",
      "Epoch: 03, Loss: 981.5244\n",
      "Epoch: 04, Loss: 979.9861\n",
      "AP SCORE：  0.851365906850497\n",
      "AUC SCORE:  0.8224334716796875\n",
      "######################### 模块循环 ： 35 ##########################\n",
      "Epoch: 00, Loss: 978.3602\n",
      "Epoch: 01, Loss: 978.1149\n",
      "Epoch: 02, Loss: 977.6497\n",
      "Epoch: 03, Loss: 976.9875\n",
      "Epoch: 04, Loss: 976.1492\n",
      "AP SCORE：  0.8515434949348951\n",
      "AUC SCORE:  0.82275390625\n",
      "Epoch: 00, Loss: 975.1541\n",
      "Epoch: 01, Loss: 974.0197\n",
      "Epoch: 02, Loss: 972.7621\n",
      "Epoch: 03, Loss: 971.3957\n",
      "Epoch: 04, Loss: 969.9340\n",
      "AP SCORE：  0.8518952368862421\n",
      "AUC SCORE:  0.8233222961425781\n",
      "######################### 模块循环 ： 36 ##########################\n",
      "Epoch: 00, Loss: 968.3889\n",
      "Epoch: 01, Loss: 968.1559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Loss: 967.7139\n",
      "Epoch: 03, Loss: 967.0844\n",
      "Epoch: 04, Loss: 966.2876\n",
      "AP SCORE：  0.8520609077753885\n",
      "AUC SCORE:  0.8236312866210938\n",
      "Epoch: 00, Loss: 965.3418\n",
      "Epoch: 01, Loss: 964.2637\n",
      "Epoch: 02, Loss: 963.0682\n",
      "Epoch: 03, Loss: 961.7696\n",
      "Epoch: 04, Loss: 960.3802\n",
      "AP SCORE：  0.8524087086108008\n",
      "AUC SCORE:  0.8242034912109375\n",
      "######################### 模块循环 ： 37 ##########################\n",
      "Epoch: 00, Loss: 958.9115\n",
      "Epoch: 01, Loss: 958.6899\n",
      "Epoch: 02, Loss: 958.2695\n",
      "Epoch: 03, Loss: 957.6711\n",
      "Epoch: 04, Loss: 956.9135\n",
      "AP SCORE：  0.8525037467040943\n",
      "AUC SCORE:  0.8244132995605469\n",
      "Epoch: 00, Loss: 956.0141\n",
      "Epoch: 01, Loss: 954.9889\n",
      "Epoch: 02, Loss: 953.8523\n",
      "Epoch: 03, Loss: 952.6172\n",
      "Epoch: 04, Loss: 951.2959\n",
      "AP SCORE：  0.8527601180420041\n",
      "AUC SCORE:  0.8248062133789062\n",
      "######################### 模块循环 ： 38 ##########################\n",
      "Epoch: 00, Loss: 949.8989\n",
      "Epoch: 01, Loss: 949.6882\n",
      "Epoch: 02, Loss: 949.2883\n",
      "Epoch: 03, Loss: 948.7188\n",
      "Epoch: 04, Loss: 947.9980\n",
      "AP SCORE：  0.8528461185001344\n",
      "AUC SCORE:  0.8250236511230469\n",
      "Epoch: 00, Loss: 947.1425\n",
      "Epoch: 01, Loss: 946.1667\n",
      "Epoch: 02, Loss: 945.0851\n",
      "Epoch: 03, Loss: 943.9099\n",
      "Epoch: 04, Loss: 942.6523\n",
      "AP SCORE：  0.852982468269101\n",
      "AUC SCORE:  0.8254356384277344\n",
      "######################### 模块循环 ： 39 ##########################\n",
      "Epoch: 00, Loss: 941.3225\n",
      "Epoch: 01, Loss: 941.1217\n",
      "Epoch: 02, Loss: 940.7409\n",
      "Epoch: 03, Loss: 940.1987\n",
      "Epoch: 04, Loss: 939.5123\n",
      "AP SCORE：  0.8530705778992609\n",
      "AUC SCORE:  0.8256149291992188\n",
      "Epoch: 00, Loss: 938.6971\n",
      "Epoch: 01, Loss: 937.7681\n",
      "Epoch: 02, Loss: 936.7377\n",
      "Epoch: 03, Loss: 935.6182\n",
      "Epoch: 04, Loss: 934.4199\n",
      "AP SCORE：  0.8532579443805455\n",
      "AUC SCORE:  0.8260307312011719\n",
      "######################### 模块循环 ： 40 ##########################\n",
      "Epoch: 00, Loss: 933.1528\n",
      "Epoch: 01, Loss: 932.9614\n",
      "Epoch: 02, Loss: 932.5984\n",
      "Epoch: 03, Loss: 932.0815\n",
      "Epoch: 04, Loss: 931.4270\n",
      "AP SCORE：  0.8534717846819513\n",
      "AUC SCORE:  0.82635498046875\n",
      "Epoch: 00, Loss: 930.6499\n",
      "Epoch: 01, Loss: 929.7640\n",
      "Epoch: 02, Loss: 928.7814\n",
      "Epoch: 03, Loss: 927.7134\n",
      "Epoch: 04, Loss: 926.5704\n",
      "AP SCORE：  0.85370437506029\n",
      "AUC SCORE:  0.82672119140625\n",
      "######################### 模块循环 ： 41 ##########################\n",
      "Epoch: 00, Loss: 925.3616\n",
      "Epoch: 01, Loss: 925.1791\n",
      "Epoch: 02, Loss: 924.8325\n",
      "Epoch: 03, Loss: 924.3392\n",
      "Epoch: 04, Loss: 923.7145\n",
      "AP SCORE：  0.8538644698249798\n",
      "AUC SCORE:  0.8268966674804688\n",
      "Epoch: 00, Loss: 922.9727\n",
      "Epoch: 01, Loss: 922.1270\n",
      "Epoch: 02, Loss: 921.1887\n",
      "Epoch: 03, Loss: 920.1688\n",
      "Epoch: 04, Loss: 919.0775\n",
      "AP SCORE：  0.8541598448779785\n",
      "AUC SCORE:  0.8272857666015625\n",
      "######################### 模块循环 ： 42 ##########################\n",
      "Epoch: 00, Loss: 917.9227\n",
      "Epoch: 01, Loss: 917.7482\n",
      "Epoch: 02, Loss: 917.4172\n",
      "Epoch: 03, Loss: 916.9457\n",
      "Epoch: 04, Loss: 916.3487\n",
      "AP SCORE：  0.854189671779054\n",
      "AUC SCORE:  0.8274459838867188\n",
      "Epoch: 00, Loss: 915.6398\n",
      "Epoch: 01, Loss: 914.8312\n",
      "Epoch: 02, Loss: 913.9346\n",
      "Epoch: 03, Loss: 912.9597\n",
      "Epoch: 04, Loss: 911.9160\n",
      "AP SCORE：  0.8542225375601015\n",
      "AUC SCORE:  0.8277626037597656\n",
      "######################### 模块循环 ： 43 ##########################\n",
      "Epoch: 00, Loss: 910.8119\n",
      "Epoch: 01, Loss: 910.6451\n",
      "Epoch: 02, Loss: 910.3284\n",
      "Epoch: 03, Loss: 909.8773\n",
      "Epoch: 04, Loss: 909.3062\n",
      "AP SCORE：  0.8543437818891453\n",
      "AUC SCORE:  0.8279190063476562\n",
      "Epoch: 00, Loss: 908.6278\n",
      "Epoch: 01, Loss: 907.8542\n",
      "Epoch: 02, Loss: 906.9961\n",
      "Epoch: 03, Loss: 906.0630\n",
      "Epoch: 04, Loss: 905.0640\n",
      "AP SCORE：  0.854524699331956\n",
      "AUC SCORE:  0.8283157348632812\n",
      "######################### 模块循环 ： 44 ##########################\n",
      "Epoch: 00, Loss: 904.0071\n",
      "Epoch: 01, Loss: 903.8473\n",
      "Epoch: 02, Loss: 903.5440\n",
      "Epoch: 03, Loss: 903.1119\n",
      "Epoch: 04, Loss: 902.5648\n",
      "AP SCORE：  0.854485404726115\n",
      "AUC SCORE:  0.8283920288085938\n",
      "Epoch: 00, Loss: 901.9152\n",
      "Epoch: 01, Loss: 901.1741\n",
      "Epoch: 02, Loss: 900.3519\n",
      "Epoch: 03, Loss: 899.4581\n",
      "Epoch: 04, Loss: 898.5009\n",
      "AP SCORE：  0.8546925461645829\n",
      "AUC SCORE:  0.8286552429199219\n",
      "######################### 模块循环 ： 45 ##########################\n",
      "Epoch: 00, Loss: 897.4880\n",
      "Epoch: 01, Loss: 897.3349\n",
      "Epoch: 02, Loss: 897.0441\n",
      "Epoch: 03, Loss: 896.6296\n",
      "Epoch: 04, Loss: 896.1052\n",
      "AP SCORE：  0.8547255709339636\n",
      "AUC SCORE:  0.8287620544433594\n",
      "Epoch: 00, Loss: 895.4823\n",
      "Epoch: 01, Loss: 894.7718\n",
      "Epoch: 02, Loss: 893.9833\n",
      "Epoch: 03, Loss: 893.1261\n",
      "Epoch: 04, Loss: 892.2079\n",
      "AP SCORE：  0.8547850130400825\n",
      "AUC SCORE:  0.8289070129394531\n",
      "######################### 模块循环 ： 46 ##########################\n",
      "Epoch: 00, Loss: 891.2363\n",
      "Epoch: 01, Loss: 891.0892\n",
      "Epoch: 02, Loss: 890.8102\n",
      "Epoch: 03, Loss: 890.4126\n",
      "Epoch: 04, Loss: 889.9094\n",
      "AP SCORE：  0.8548591462419637\n",
      "AUC SCORE:  0.82904052734375\n",
      "Epoch: 00, Loss: 889.3114\n",
      "Epoch: 01, Loss: 888.6294\n",
      "Epoch: 02, Loss: 887.8725\n",
      "Epoch: 03, Loss: 887.0495\n",
      "Epoch: 04, Loss: 886.1680\n",
      "AP SCORE：  0.854781590183884\n",
      "AUC SCORE:  0.8291244506835938\n",
      "######################### 模块循环 ： 47 ##########################\n",
      "Epoch: 00, Loss: 885.2350\n",
      "Epoch: 01, Loss: 885.0939\n",
      "Epoch: 02, Loss: 884.8257\n",
      "Epoch: 03, Loss: 884.4440\n",
      "Epoch: 04, Loss: 883.9604\n",
      "AP SCORE：  0.8547821566778298\n",
      "AUC SCORE:  0.8292274475097656\n",
      "Epoch: 00, Loss: 883.3861\n",
      "Epoch: 01, Loss: 882.7309\n",
      "Epoch: 02, Loss: 882.0038\n",
      "Epoch: 03, Loss: 881.2130\n",
      "Epoch: 04, Loss: 880.3660\n",
      "AP SCORE：  0.8548262813411116\n",
      "AUC SCORE:  0.8293838500976562\n",
      "######################### 模块循环 ： 48 ##########################\n",
      "Epoch: 00, Loss: 879.4694\n",
      "Epoch: 01, Loss: 879.3336\n",
      "Epoch: 02, Loss: 879.0759\n",
      "Epoch: 03, Loss: 878.7089\n",
      "Epoch: 04, Loss: 878.2440\n",
      "AP SCORE：  0.8547994783352035\n",
      "AUC SCORE:  0.8294639587402344\n",
      "Epoch: 00, Loss: 877.6918\n",
      "Epoch: 01, Loss: 877.0618\n",
      "Epoch: 02, Loss: 876.3627\n",
      "Epoch: 03, Loss: 875.6023\n",
      "Epoch: 04, Loss: 874.7876\n",
      "AP SCORE：  0.8548341828741929\n",
      "AUC SCORE:  0.8295936584472656\n",
      "######################### 模块循环 ： 49 ##########################\n",
      "Epoch: 00, Loss: 873.9254\n",
      "Epoch: 01, Loss: 873.7947\n",
      "Epoch: 02, Loss: 873.5469\n",
      "Epoch: 03, Loss: 873.1937\n",
      "Epoch: 04, Loss: 872.7465\n",
      "AP SCORE：  0.8548884306811317\n",
      "AUC SCORE:  0.8297080993652344\n",
      "Epoch: 00, Loss: 872.2152\n",
      "Epoch: 01, Loss: 871.6090\n",
      "Epoch: 02, Loss: 870.9362\n",
      "Epoch: 03, Loss: 870.2044\n",
      "Epoch: 04, Loss: 869.4205\n",
      "AP SCORE：  0.855046470679022\n",
      "AUC SCORE:  0.8299789428710938\n",
      "######################### 模块循环 ： 50 ##########################\n",
      "Epoch: 00, Loss: 868.5904\n",
      "Epoch: 01, Loss: 868.4647\n",
      "Epoch: 02, Loss: 868.2261\n",
      "Epoch: 03, Loss: 867.8862\n",
      "Epoch: 04, Loss: 867.4556\n",
      "AP SCORE：  0.8550249486457421\n",
      "AUC SCORE:  0.8300247192382812\n",
      "Epoch: 00, Loss: 866.9438\n",
      "Epoch: 01, Loss: 866.3602\n",
      "Epoch: 02, Loss: 865.7123\n",
      "Epoch: 03, Loss: 865.0076\n",
      "Epoch: 04, Loss: 864.2526\n",
      "AP SCORE：  0.8549675059858202\n",
      "AUC SCORE:  0.8301506042480469\n",
      "######################### 模块循环 ： 51 ##########################\n",
      "Epoch: 00, Loss: 863.4531\n",
      "Epoch: 01, Loss: 863.3320\n",
      "Epoch: 02, Loss: 863.1021\n",
      "Epoch: 03, Loss: 862.7745\n",
      "Epoch: 04, Loss: 862.3596\n",
      "AP SCORE：  0.8550537600793874\n",
      "AUC SCORE:  0.8302688598632812\n",
      "Epoch: 00, Loss: 861.8667\n",
      "Epoch: 01, Loss: 861.3043\n",
      "Epoch: 02, Loss: 860.6801\n",
      "Epoch: 03, Loss: 860.0008\n",
      "Epoch: 04, Loss: 859.2732\n",
      "AP SCORE：  0.8550487278431429\n",
      "AUC SCORE:  0.8303909301757812\n",
      "######################### 模块循环 ： 52 ##########################\n",
      "Epoch: 00, Loss: 858.5027\n",
      "Epoch: 01, Loss: 858.3859\n",
      "Epoch: 02, Loss: 858.1642\n",
      "Epoch: 03, Loss: 857.8484\n",
      "Epoch: 04, Loss: 857.4485\n",
      "AP SCORE：  0.8550532407435768\n",
      "AUC SCORE:  0.8304214477539062\n",
      "Epoch: 00, Loss: 856.9732\n",
      "Epoch: 01, Loss: 856.4308\n",
      "Epoch: 02, Loss: 855.8290\n",
      "Epoch: 03, Loss: 855.1742\n",
      "Epoch: 04, Loss: 854.4722\n",
      "AP SCORE：  0.8550047703084285\n",
      "AUC SCORE:  0.8305130004882812\n",
      "######################### 模块循环 ： 53 ##########################\n",
      "Epoch: 00, Loss: 853.7293\n",
      "Epoch: 01, Loss: 853.6168\n",
      "Epoch: 02, Loss: 853.4027\n",
      "Epoch: 03, Loss: 853.0982\n",
      "Epoch: 04, Loss: 852.7123\n",
      "AP SCORE：  0.8550265950288807\n",
      "AUC SCORE:  0.8306159973144531\n",
      "Epoch: 00, Loss: 852.2537\n",
      "Epoch: 01, Loss: 851.7305\n",
      "Epoch: 02, Loss: 851.1497\n",
      "Epoch: 03, Loss: 850.5177\n",
      "Epoch: 04, Loss: 849.8407\n",
      "AP SCORE：  0.8550635496940936\n",
      "AUC SCORE:  0.8307304382324219\n",
      "######################### 模块循环 ： 54 ##########################\n",
      "Epoch: 00, Loss: 849.1236\n",
      "Epoch: 01, Loss: 849.0148\n",
      "Epoch: 02, Loss: 848.8085\n",
      "Epoch: 03, Loss: 848.5143\n",
      "Epoch: 04, Loss: 848.1418\n",
      "AP SCORE：  0.8550227483632298\n",
      "AUC SCORE:  0.8307647705078125\n",
      "Epoch: 00, Loss: 847.6991\n",
      "Epoch: 01, Loss: 847.1940\n",
      "Epoch: 02, Loss: 846.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Loss: 846.0232\n",
      "Epoch: 04, Loss: 845.3693\n",
      "AP SCORE：  0.8551078749688762\n",
      "AUC SCORE:  0.8308944702148438\n",
      "######################### 模块循环 ： 55 ##########################\n",
      "Epoch: 00, Loss: 844.6769\n",
      "Epoch: 01, Loss: 844.5719\n",
      "Epoch: 02, Loss: 844.3724\n",
      "Epoch: 03, Loss: 844.0884\n",
      "Epoch: 04, Loss: 843.7286\n",
      "AP SCORE：  0.8550699566171647\n",
      "AUC SCORE:  0.8309745788574219\n",
      "Epoch: 00, Loss: 843.3011\n",
      "Epoch: 01, Loss: 842.8132\n",
      "Epoch: 02, Loss: 842.2714\n",
      "Epoch: 03, Loss: 841.6821\n",
      "Epoch: 04, Loss: 841.0504\n",
      "AP SCORE：  0.8551702161409731\n",
      "AUC SCORE:  0.8311309814453125\n",
      "######################### 模块循环 ： 56 ##########################\n",
      "Epoch: 00, Loss: 840.3813\n",
      "Epoch: 01, Loss: 840.2797\n",
      "Epoch: 02, Loss: 840.0870\n",
      "Epoch: 03, Loss: 839.8126\n",
      "Epoch: 04, Loss: 839.4649\n",
      "AP SCORE：  0.85516418749633\n",
      "AUC SCORE:  0.8311958312988281\n",
      "Epoch: 00, Loss: 839.0516\n",
      "Epoch: 01, Loss: 838.5800\n",
      "Epoch: 02, Loss: 838.0564\n",
      "Epoch: 03, Loss: 837.4866\n",
      "Epoch: 04, Loss: 836.8759\n",
      "AP SCORE：  0.8551490536247648\n",
      "AUC SCORE:  0.8312644958496094\n",
      "######################### 模块循环 ： 57 ##########################\n",
      "Epoch: 00, Loss: 836.2290\n",
      "Epoch: 01, Loss: 836.1310\n",
      "Epoch: 02, Loss: 835.9446\n",
      "Epoch: 03, Loss: 835.6792\n",
      "Epoch: 04, Loss: 835.3428\n",
      "AP SCORE：  0.8550674203817759\n",
      "AUC SCORE:  0.8312568664550781\n",
      "Epoch: 00, Loss: 834.9434\n",
      "Epoch: 01, Loss: 834.4872\n",
      "Epoch: 02, Loss: 833.9807\n",
      "Epoch: 03, Loss: 833.4296\n",
      "Epoch: 04, Loss: 832.8389\n",
      "AP SCORE：  0.8549957839766475\n",
      "AUC SCORE:  0.8312950134277344\n",
      "######################### 模块循环 ： 58 ##########################\n",
      "Epoch: 00, Loss: 832.2132\n",
      "Epoch: 01, Loss: 832.1183\n",
      "Epoch: 02, Loss: 831.9381\n",
      "Epoch: 03, Loss: 831.6812\n",
      "Epoch: 04, Loss: 831.3558\n",
      "AP SCORE：  0.8549477114388047\n",
      "AUC SCORE:  0.8313179016113281\n",
      "Epoch: 00, Loss: 830.9692\n",
      "Epoch: 01, Loss: 830.5278\n",
      "Epoch: 02, Loss: 830.0378\n",
      "Epoch: 03, Loss: 829.5044\n",
      "Epoch: 04, Loss: 828.9328\n",
      "AP SCORE：  0.8549518896941735\n",
      "AUC SCORE:  0.83135986328125\n",
      "######################### 模块循环 ： 59 ##########################\n",
      "Epoch: 00, Loss: 828.3273\n",
      "Epoch: 01, Loss: 828.2354\n",
      "Epoch: 02, Loss: 828.0609\n",
      "Epoch: 03, Loss: 827.8123\n",
      "Epoch: 04, Loss: 827.4972\n",
      "AP SCORE：  0.8549153989343998\n",
      "AUC SCORE:  0.8313713073730469\n",
      "Epoch: 00, Loss: 827.1229\n",
      "Epoch: 01, Loss: 826.6957\n",
      "Epoch: 02, Loss: 826.2212\n",
      "Epoch: 03, Loss: 825.7047\n",
      "Epoch: 04, Loss: 825.1512\n",
      "AP SCORE：  0.8549076342617901\n",
      "AUC SCORE:  0.8314208984375\n",
      "######################### 模块循环 ： 60 ##########################\n",
      "Epoch: 00, Loss: 824.5648\n",
      "Epoch: 01, Loss: 824.4758\n",
      "Epoch: 02, Loss: 824.3068\n",
      "Epoch: 03, Loss: 824.0660\n",
      "Epoch: 04, Loss: 823.7609\n",
      "AP SCORE：  0.8548825505636906\n",
      "AUC SCORE:  0.8313980102539062\n",
      "Epoch: 00, Loss: 823.3984\n",
      "Epoch: 01, Loss: 822.9845\n",
      "Epoch: 02, Loss: 822.5248\n",
      "Epoch: 03, Loss: 822.0247\n",
      "Epoch: 04, Loss: 821.4884\n",
      "AP SCORE：  0.8548149536365768\n",
      "AUC SCORE:  0.8314094543457031\n",
      "######################### 模块循环 ： 61 ##########################\n",
      "Epoch: 00, Loss: 820.9202\n",
      "Epoch: 01, Loss: 820.8340\n",
      "Epoch: 02, Loss: 820.6702\n",
      "Epoch: 03, Loss: 820.4370\n",
      "Epoch: 04, Loss: 820.1412\n",
      "AP SCORE：  0.8548280724586539\n",
      "AUC SCORE:  0.8314552307128906\n",
      "Epoch: 00, Loss: 819.7898\n",
      "Epoch: 01, Loss: 819.3887\n",
      "Epoch: 02, Loss: 818.9433\n",
      "Epoch: 03, Loss: 818.4585\n",
      "Epoch: 04, Loss: 817.9388\n",
      "AP SCORE：  0.8549282564889402\n",
      "AUC SCORE:  0.8315849304199219\n",
      "######################### 模块循环 ： 62 ##########################\n",
      "Epoch: 00, Loss: 817.3880\n",
      "Epoch: 01, Loss: 817.3046\n",
      "Epoch: 02, Loss: 817.1458\n",
      "Epoch: 03, Loss: 816.9195\n",
      "Epoch: 04, Loss: 816.6328\n",
      "AP SCORE：  0.85492075278748\n",
      "AUC SCORE:  0.83160400390625\n",
      "Epoch: 00, Loss: 816.2921\n",
      "Epoch: 01, Loss: 815.9032\n",
      "Epoch: 02, Loss: 815.4713\n",
      "Epoch: 03, Loss: 815.0013\n",
      "Epoch: 04, Loss: 814.4973\n",
      "AP SCORE：  0.8550455396890444\n",
      "AUC SCORE:  0.8317375183105469\n",
      "######################### 模块循环 ： 63 ##########################\n",
      "Epoch: 00, Loss: 813.9633\n",
      "Epoch: 01, Loss: 813.8820\n",
      "Epoch: 02, Loss: 813.7281\n",
      "Epoch: 03, Loss: 813.5086\n",
      "Epoch: 04, Loss: 813.2305\n",
      "AP SCORE：  0.8550058307378301\n",
      "AUC SCORE:  0.8317642211914062\n",
      "Epoch: 00, Loss: 812.9001\n",
      "Epoch: 01, Loss: 812.5229\n",
      "Epoch: 02, Loss: 812.1039\n",
      "Epoch: 03, Loss: 811.6479\n",
      "Epoch: 04, Loss: 811.1589\n",
      "AP SCORE：  0.8549725893079865\n",
      "AUC SCORE:  0.8318061828613281\n",
      "######################### 模块循环 ： 64 ##########################\n",
      "Epoch: 00, Loss: 810.6408\n",
      "Epoch: 01, Loss: 810.5622\n",
      "Epoch: 02, Loss: 810.4127\n",
      "Epoch: 03, Loss: 810.1997\n",
      "Epoch: 04, Loss: 809.9299\n",
      "AP SCORE：  0.8549095058528722\n",
      "AUC SCORE:  0.8318328857421875\n",
      "Epoch: 00, Loss: 809.6093\n",
      "Epoch: 01, Loss: 809.2432\n",
      "Epoch: 02, Loss: 808.8364\n",
      "Epoch: 03, Loss: 808.3939\n",
      "Epoch: 04, Loss: 807.9193\n",
      "AP SCORE：  0.8548272424791918\n",
      "AUC SCORE:  0.8318328857421875\n",
      "######################### 模块循环 ： 65 ##########################\n",
      "Epoch: 00, Loss: 807.4164\n",
      "Epoch: 01, Loss: 807.3400\n",
      "Epoch: 02, Loss: 807.1949\n",
      "Epoch: 03, Loss: 806.9882\n",
      "Epoch: 04, Loss: 806.7261\n",
      "AP SCORE：  0.8547419769614544\n",
      "AUC SCORE:  0.8317756652832031\n",
      "Epoch: 00, Loss: 806.4150\n",
      "Epoch: 01, Loss: 806.0593\n",
      "Epoch: 02, Loss: 805.6645\n",
      "Epoch: 03, Loss: 805.2347\n",
      "Epoch: 04, Loss: 804.7740\n",
      "AP SCORE：  0.8548211756691748\n",
      "AUC SCORE:  0.8319473266601562\n",
      "######################### 模块循环 ： 66 ##########################\n",
      "Epoch: 00, Loss: 804.2856\n",
      "Epoch: 01, Loss: 804.2114\n",
      "Epoch: 02, Loss: 804.0705\n",
      "Epoch: 03, Loss: 803.8698\n",
      "Epoch: 04, Loss: 803.6154\n",
      "AP SCORE：  0.854858513769454\n",
      "AUC SCORE:  0.8320083618164062\n",
      "Epoch: 00, Loss: 803.3129\n",
      "Epoch: 01, Loss: 802.9675\n",
      "Epoch: 02, Loss: 802.5842\n",
      "Epoch: 03, Loss: 802.1666\n",
      "Epoch: 04, Loss: 801.7191\n",
      "AP SCORE：  0.854899194869119\n",
      "AUC SCORE:  0.8321113586425781\n",
      "######################### 模块循环 ： 67 ##########################\n",
      "Epoch: 00, Loss: 801.2444\n",
      "Epoch: 01, Loss: 801.1724\n",
      "Epoch: 02, Loss: 801.0355\n",
      "Epoch: 03, Loss: 800.8403\n",
      "Epoch: 04, Loss: 800.5931\n",
      "AP SCORE：  0.8548926128466942\n",
      "AUC SCORE:  0.8321151733398438\n",
      "Epoch: 00, Loss: 800.2993\n",
      "Epoch: 01, Loss: 799.9637\n",
      "Epoch: 02, Loss: 799.5911\n",
      "Epoch: 03, Loss: 799.1854\n",
      "Epoch: 04, Loss: 798.7503\n",
      "AP SCORE：  0.854860440694519\n",
      "AUC SCORE:  0.8321380615234375\n",
      "######################### 模块循环 ： 68 ##########################\n",
      "Epoch: 00, Loss: 798.2892\n",
      "Epoch: 01, Loss: 798.2191\n",
      "Epoch: 02, Loss: 798.0859\n",
      "Epoch: 03, Loss: 797.8964\n",
      "Epoch: 04, Loss: 797.6561\n",
      "AP SCORE：  0.8548652072753897\n",
      "AUC SCORE:  0.8321723937988281\n",
      "Epoch: 00, Loss: 797.3703\n",
      "Epoch: 01, Loss: 797.0442\n",
      "Epoch: 02, Loss: 796.6818\n",
      "Epoch: 03, Loss: 796.2874\n",
      "Epoch: 04, Loss: 795.8644\n",
      "AP SCORE：  0.8548122205280574\n",
      "AUC SCORE:  0.8322219848632812\n",
      "######################### 模块循环 ： 69 ##########################\n",
      "Epoch: 00, Loss: 795.4160\n",
      "Epoch: 01, Loss: 795.3479\n",
      "Epoch: 02, Loss: 795.2184\n",
      "Epoch: 03, Loss: 795.0340\n",
      "Epoch: 04, Loss: 794.8002\n",
      "AP SCORE：  0.854795161025258\n",
      "AUC SCORE:  0.8322067260742188\n",
      "Epoch: 00, Loss: 794.5225\n",
      "Epoch: 01, Loss: 794.2052\n",
      "Epoch: 02, Loss: 793.8528\n",
      "Epoch: 03, Loss: 793.4692\n",
      "Epoch: 04, Loss: 793.0577\n",
      "AP SCORE：  0.8548088078069328\n",
      "AUC SCORE:  0.8322868347167969\n",
      "######################### 模块循环 ： 70 ##########################\n",
      "Epoch: 00, Loss: 792.6216\n",
      "Epoch: 01, Loss: 792.5552\n",
      "Epoch: 02, Loss: 792.4293\n",
      "Epoch: 03, Loss: 792.2499\n",
      "Epoch: 04, Loss: 792.0226\n",
      "AP SCORE：  0.854806449174107\n",
      "AUC SCORE:  0.832275390625\n",
      "Epoch: 00, Loss: 791.7523\n",
      "Epoch: 01, Loss: 791.4437\n",
      "Epoch: 02, Loss: 791.1008\n",
      "Epoch: 03, Loss: 790.7274\n",
      "Epoch: 04, Loss: 790.3271\n",
      "AP SCORE：  0.8547226808122019\n",
      "AUC SCORE:  0.832244873046875\n",
      "######################### 模块循环 ： 71 ##########################\n",
      "Epoch: 00, Loss: 789.9027\n",
      "Epoch: 01, Loss: 789.8382\n",
      "Epoch: 02, Loss: 789.7155\n",
      "Epoch: 03, Loss: 789.5410\n",
      "Epoch: 04, Loss: 789.3196\n",
      "AP SCORE：  0.8547743401946872\n",
      "AUC SCORE:  0.8322792053222656\n",
      "Epoch: 00, Loss: 789.0565\n",
      "Epoch: 01, Loss: 788.7561\n",
      "Epoch: 02, Loss: 788.4223\n",
      "Epoch: 03, Loss: 788.0590\n",
      "Epoch: 04, Loss: 787.6691\n",
      "AP SCORE：  0.854793460554004\n",
      "AUC SCORE:  0.832305908203125\n",
      "######################### 模块循环 ： 72 ##########################\n",
      "Epoch: 00, Loss: 787.2560\n",
      "Epoch: 01, Loss: 787.1932\n",
      "Epoch: 02, Loss: 787.0739\n",
      "Epoch: 03, Loss: 786.9038\n",
      "Epoch: 04, Loss: 786.6884\n",
      "AP SCORE：  0.8548274602582856\n",
      "AUC SCORE:  0.8323326110839844\n",
      "Epoch: 00, Loss: 786.4322\n",
      "Epoch: 01, Loss: 786.1395\n",
      "Epoch: 02, Loss: 785.8146\n",
      "Epoch: 03, Loss: 785.4608\n",
      "Epoch: 04, Loss: 785.0812\n",
      "AP SCORE：  0.8547711861063291\n",
      "AUC SCORE:  0.8323822021484375\n",
      "######################### 模块循环 ： 73 ##########################\n",
      "Epoch: 00, Loss: 784.6788\n",
      "Epoch: 01, Loss: 784.6176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Loss: 784.5013\n",
      "Epoch: 03, Loss: 784.3358\n",
      "Epoch: 04, Loss: 784.1259\n",
      "AP SCORE：  0.8547883097954772\n",
      "AUC SCORE:  0.8324089050292969\n",
      "Epoch: 00, Loss: 783.8763\n",
      "Epoch: 01, Loss: 783.5913\n",
      "Epoch: 02, Loss: 783.2747\n",
      "Epoch: 03, Loss: 782.9299\n",
      "Epoch: 04, Loss: 782.5602\n",
      "AP SCORE：  0.8547193574184402\n",
      "AUC SCORE:  0.8323631286621094\n",
      "######################### 模块循环 ： 74 ##########################\n",
      "Epoch: 00, Loss: 782.1681\n",
      "Epoch: 01, Loss: 782.1086\n",
      "Epoch: 02, Loss: 781.9952\n",
      "Epoch: 03, Loss: 781.8338\n",
      "Epoch: 04, Loss: 781.6293\n",
      "AP SCORE：  0.8546999705602405\n",
      "AUC SCORE:  0.832366943359375\n",
      "Epoch: 00, Loss: 781.3860\n",
      "Epoch: 01, Loss: 781.1083\n",
      "Epoch: 02, Loss: 780.7997\n",
      "Epoch: 03, Loss: 780.4637\n",
      "Epoch: 04, Loss: 780.1033\n",
      "AP SCORE：  0.8546223315134249\n",
      "AUC SCORE:  0.8323478698730469\n",
      "######################### 模块循环 ： 75 ##########################\n",
      "Epoch: 00, Loss: 779.7211\n",
      "Epoch: 01, Loss: 779.6629\n",
      "Epoch: 02, Loss: 779.5524\n",
      "Epoch: 03, Loss: 779.3951\n",
      "Epoch: 04, Loss: 779.1957\n",
      "AP SCORE：  0.8546193996520648\n",
      "AUC SCORE:  0.8324165344238281\n",
      "Epoch: 00, Loss: 778.9586\n",
      "Epoch: 01, Loss: 778.6877\n",
      "Epoch: 02, Loss: 778.3869\n",
      "Epoch: 03, Loss: 778.0591\n",
      "Epoch: 04, Loss: 777.7078\n",
      "AP SCORE：  0.854598748638586\n",
      "AUC SCORE:  0.8324203491210938\n",
      "######################### 模块循环 ： 76 ##########################\n",
      "Epoch: 00, Loss: 777.3351\n",
      "Epoch: 01, Loss: 777.2784\n",
      "Epoch: 02, Loss: 777.1706\n",
      "Epoch: 03, Loss: 777.0172\n",
      "Epoch: 04, Loss: 776.8226\n",
      "AP SCORE：  0.8546268032232207\n",
      "AUC SCORE:  0.8324165344238281\n",
      "Epoch: 00, Loss: 776.5913\n",
      "Epoch: 01, Loss: 776.3271\n",
      "Epoch: 02, Loss: 776.0336\n",
      "Epoch: 03, Loss: 775.7140\n",
      "Epoch: 04, Loss: 775.3710\n",
      "AP SCORE：  0.8546346497622166\n",
      "AUC SCORE:  0.8324089050292969\n",
      "######################### 模块循环 ： 77 ##########################\n",
      "Epoch: 00, Loss: 775.0074\n",
      "Epoch: 01, Loss: 774.9520\n",
      "Epoch: 02, Loss: 774.8469\n",
      "Epoch: 03, Loss: 774.6970\n",
      "Epoch: 04, Loss: 774.5072\n",
      "AP SCORE：  0.8546313624645129\n",
      "AUC SCORE:  0.8324203491210938\n",
      "Epoch: 00, Loss: 774.2815\n",
      "Epoch: 01, Loss: 774.0236\n",
      "Epoch: 02, Loss: 773.7371\n",
      "Epoch: 03, Loss: 773.4251\n",
      "Epoch: 04, Loss: 773.0903\n",
      "AP SCORE：  0.8545447966061596\n",
      "AUC SCORE:  0.8323287963867188\n",
      "######################### 模块循环 ： 78 ##########################\n",
      "Epoch: 00, Loss: 772.7354\n",
      "Epoch: 01, Loss: 772.6813\n",
      "Epoch: 02, Loss: 772.5787\n",
      "Epoch: 03, Loss: 772.4324\n",
      "Epoch: 04, Loss: 772.2470\n",
      "AP SCORE：  0.854519989998754\n",
      "AUC SCORE:  0.8323211669921875\n",
      "Epoch: 00, Loss: 772.0265\n",
      "Epoch: 01, Loss: 771.7748\n",
      "Epoch: 02, Loss: 771.4951\n",
      "Epoch: 03, Loss: 771.1903\n",
      "Epoch: 04, Loss: 770.8634\n",
      "AP SCORE：  0.8544409735455958\n",
      "AUC SCORE:  0.832305908203125\n",
      "######################### 模块循环 ： 79 ##########################\n",
      "Epoch: 00, Loss: 770.5166\n",
      "Epoch: 01, Loss: 770.4639\n",
      "Epoch: 02, Loss: 770.3635\n",
      "Epoch: 03, Loss: 770.2206\n",
      "Epoch: 04, Loss: 770.0396\n",
      "AP SCORE：  0.8544580517539828\n",
      "AUC SCORE:  0.8323593139648438\n",
      "Epoch: 00, Loss: 769.8242\n",
      "Epoch: 01, Loss: 769.5781\n",
      "Epoch: 02, Loss: 769.3048\n",
      "Epoch: 03, Loss: 769.0070\n",
      "Epoch: 04, Loss: 768.6875\n",
      "AP SCORE：  0.8543600468634894\n",
      "AUC SCORE:  0.8322982788085938\n",
      "######################### 模块循环 ： 80 ##########################\n",
      "Epoch: 00, Loss: 768.3486\n",
      "Epoch: 01, Loss: 768.2971\n",
      "Epoch: 02, Loss: 768.1990\n",
      "Epoch: 03, Loss: 768.0594\n",
      "Epoch: 04, Loss: 767.8823\n",
      "AP SCORE：  0.854307146758242\n",
      "AUC SCORE:  0.8323020935058594\n",
      "Epoch: 00, Loss: 767.6717\n",
      "Epoch: 01, Loss: 767.4312\n",
      "Epoch: 02, Loss: 767.1639\n",
      "Epoch: 03, Loss: 766.8727\n",
      "Epoch: 04, Loss: 766.5604\n",
      "AP SCORE：  0.8542951541944881\n",
      "AUC SCORE:  0.8322792053222656\n",
      "######################### 模块循环 ： 81 ##########################\n",
      "Epoch: 00, Loss: 766.2292\n",
      "Epoch: 01, Loss: 766.1788\n",
      "Epoch: 02, Loss: 766.0829\n",
      "Epoch: 03, Loss: 765.9462\n",
      "Epoch: 04, Loss: 765.7731\n",
      "AP SCORE：  0.8543332133445862\n",
      "AUC SCORE:  0.832305908203125\n",
      "Epoch: 00, Loss: 765.5671\n",
      "Epoch: 01, Loss: 765.3319\n",
      "Epoch: 02, Loss: 765.0706\n",
      "Epoch: 03, Loss: 764.7858\n",
      "Epoch: 04, Loss: 764.4802\n",
      "AP SCORE：  0.8543140617196271\n",
      "AUC SCORE:  0.8323287963867188\n",
      "######################### 模块循环 ： 82 ##########################\n",
      "Epoch: 00, Loss: 764.1561\n",
      "Epoch: 01, Loss: 764.1067\n",
      "Epoch: 02, Loss: 764.0129\n",
      "Epoch: 03, Loss: 763.8792\n",
      "Epoch: 04, Loss: 763.7097\n",
      "AP SCORE：  0.8542897464560071\n",
      "AUC SCORE:  0.8323135375976562\n",
      "Epoch: 00, Loss: 763.5082\n",
      "Epoch: 01, Loss: 763.2781\n",
      "Epoch: 02, Loss: 763.0222\n",
      "Epoch: 03, Loss: 762.7434\n",
      "Epoch: 04, Loss: 762.4445\n",
      "AP SCORE：  0.8542048723226001\n",
      "AUC SCORE:  0.8322715759277344\n",
      "######################### 模块循环 ： 83 ##########################\n",
      "Epoch: 00, Loss: 762.1271\n",
      "Epoch: 01, Loss: 762.0788\n",
      "Epoch: 02, Loss: 761.9870\n",
      "Epoch: 03, Loss: 761.8562\n",
      "Epoch: 04, Loss: 761.6902\n",
      "AP SCORE：  0.854111942453683\n",
      "AUC SCORE:  0.8322105407714844\n",
      "Epoch: 00, Loss: 761.4929\n",
      "Epoch: 01, Loss: 761.2676\n",
      "Epoch: 02, Loss: 761.0171\n",
      "Epoch: 03, Loss: 760.7443\n",
      "Epoch: 04, Loss: 760.4514\n",
      "AP SCORE：  0.8541448169668069\n",
      "AUC SCORE:  0.8322715759277344\n",
      "######################### 模块循环 ： 84 ##########################\n",
      "Epoch: 00, Loss: 760.1408\n",
      "Epoch: 01, Loss: 760.0934\n",
      "Epoch: 02, Loss: 760.0035\n",
      "Epoch: 03, Loss: 759.8753\n",
      "Epoch: 04, Loss: 759.7128\n",
      "AP SCORE：  0.854167371576005\n",
      "AUC SCORE:  0.8322563171386719\n",
      "Epoch: 00, Loss: 759.5195\n",
      "Epoch: 01, Loss: 759.2988\n",
      "Epoch: 02, Loss: 759.0535\n",
      "Epoch: 03, Loss: 758.7861\n",
      "Epoch: 04, Loss: 758.4992\n",
      "AP SCORE：  0.854064901700115\n",
      "AUC SCORE:  0.8322181701660156\n",
      "######################### 模块循环 ： 85 ##########################\n",
      "Epoch: 00, Loss: 758.1949\n",
      "Epoch: 01, Loss: 758.1485\n",
      "Epoch: 02, Loss: 758.0604\n",
      "Epoch: 03, Loss: 757.9347\n",
      "Epoch: 04, Loss: 757.7756\n",
      "AP SCORE：  0.8540459099580994\n",
      "AUC SCORE:  0.8322067260742188\n",
      "Epoch: 00, Loss: 757.5862\n",
      "Epoch: 01, Loss: 757.3699\n",
      "Epoch: 02, Loss: 757.1295\n",
      "Epoch: 03, Loss: 756.8676\n",
      "Epoch: 04, Loss: 756.5863\n",
      "AP SCORE：  0.854062567951865\n",
      "AUC SCORE:  0.832183837890625\n",
      "######################### 模块循环 ： 86 ##########################\n",
      "Epoch: 00, Loss: 756.2882\n",
      "Epoch: 01, Loss: 756.2427\n",
      "Epoch: 02, Loss: 756.1563\n",
      "Epoch: 03, Loss: 756.0332\n",
      "Epoch: 04, Loss: 755.8772\n",
      "AP SCORE：  0.8540038853301416\n",
      "AUC SCORE:  0.8321418762207031\n",
      "Epoch: 00, Loss: 755.6916\n",
      "Epoch: 01, Loss: 755.4795\n",
      "Epoch: 02, Loss: 755.2438\n",
      "Epoch: 03, Loss: 754.9870\n",
      "Epoch: 04, Loss: 754.7114\n",
      "AP SCORE：  0.8540298485705483\n",
      "AUC SCORE:  0.8321876525878906\n",
      "######################### 模块循环 ： 87 ##########################\n",
      "Epoch: 00, Loss: 754.4191\n",
      "Epoch: 01, Loss: 754.3745\n",
      "Epoch: 02, Loss: 754.2898\n",
      "Epoch: 03, Loss: 754.1690\n",
      "Epoch: 04, Loss: 754.0161\n",
      "AP SCORE：  0.8539324875803596\n",
      "AUC SCORE:  0.8321304321289062\n",
      "Epoch: 00, Loss: 753.8342\n",
      "Epoch: 01, Loss: 753.6262\n",
      "Epoch: 02, Loss: 753.3951\n",
      "Epoch: 03, Loss: 753.1434\n",
      "Epoch: 04, Loss: 752.8732\n",
      "AP SCORE：  0.8539226568429946\n",
      "AUC SCORE:  0.8321075439453125\n",
      "######################### 模块循环 ： 88 ##########################\n",
      "Epoch: 00, Loss: 752.5863\n",
      "Epoch: 01, Loss: 752.5425\n",
      "Epoch: 02, Loss: 752.4595\n",
      "Epoch: 03, Loss: 752.3412\n",
      "Epoch: 04, Loss: 752.1910\n",
      "AP SCORE：  0.8538882093167824\n",
      "AUC SCORE:  0.8320999145507812\n",
      "Epoch: 00, Loss: 752.0126\n",
      "Epoch: 01, Loss: 751.8088\n",
      "Epoch: 02, Loss: 751.5822\n",
      "Epoch: 03, Loss: 751.3352\n",
      "Epoch: 04, Loss: 751.0701\n",
      "AP SCORE：  0.8538623933172106\n",
      "AUC SCORE:  0.8321075439453125\n",
      "######################### 模块循环 ： 89 ##########################\n",
      "Epoch: 00, Loss: 750.7889\n",
      "Epoch: 01, Loss: 750.7460\n",
      "Epoch: 02, Loss: 750.6644\n",
      "Epoch: 03, Loss: 750.5483\n",
      "Epoch: 04, Loss: 750.4011\n",
      "AP SCORE：  0.8538846554193231\n",
      "AUC SCORE:  0.8321342468261719\n",
      "Epoch: 00, Loss: 750.2261\n",
      "Epoch: 01, Loss: 750.0261\n",
      "Epoch: 02, Loss: 749.8037\n",
      "Epoch: 03, Loss: 749.5615\n",
      "Epoch: 04, Loss: 749.3015\n",
      "AP SCORE：  0.8539258893074134\n",
      "AUC SCORE:  0.8321723937988281\n",
      "######################### 模块循环 ： 90 ##########################\n",
      "Epoch: 00, Loss: 749.0255\n",
      "Epoch: 01, Loss: 748.9834\n",
      "Epoch: 02, Loss: 748.9035\n",
      "Epoch: 03, Loss: 748.7896\n",
      "Epoch: 04, Loss: 748.6451\n",
      "AP SCORE：  0.8539320749437389\n",
      "AUC SCORE:  0.8321876525878906\n",
      "Epoch: 00, Loss: 748.4736\n",
      "Epoch: 01, Loss: 748.2772\n",
      "Epoch: 02, Loss: 748.0591\n",
      "Epoch: 03, Loss: 747.8214\n",
      "Epoch: 04, Loss: 747.5663\n",
      "AP SCORE：  0.8539466638404825\n",
      "AUC SCORE:  0.8322029113769531\n",
      "######################### 模块循环 ： 91 ##########################\n",
      "Epoch: 00, Loss: 747.2956\n",
      "Epoch: 01, Loss: 747.2544\n",
      "Epoch: 02, Loss: 747.1760\n",
      "Epoch: 03, Loss: 747.0641\n",
      "Epoch: 04, Loss: 746.9225\n",
      "AP SCORE：  0.8539291378102545\n",
      "AUC SCORE:  0.8322105407714844\n",
      "Epoch: 00, Loss: 746.7538\n",
      "Epoch: 01, Loss: 746.5614\n",
      "Epoch: 02, Loss: 746.3474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Loss: 746.1143\n",
      "Epoch: 04, Loss: 745.8638\n",
      "AP SCORE：  0.8539590024174221\n",
      "AUC SCORE:  0.832244873046875\n",
      "######################### 模块循环 ： 92 ##########################\n",
      "Epoch: 00, Loss: 745.5982\n",
      "Epoch: 01, Loss: 745.5577\n",
      "Epoch: 02, Loss: 745.4808\n",
      "Epoch: 03, Loss: 745.3711\n",
      "Epoch: 04, Loss: 745.2321\n",
      "AP SCORE：  0.8539553831366442\n",
      "AUC SCORE:  0.8322525024414062\n",
      "Epoch: 00, Loss: 745.0667\n",
      "Epoch: 01, Loss: 744.8779\n",
      "Epoch: 02, Loss: 744.6678\n",
      "Epoch: 03, Loss: 744.4389\n",
      "Epoch: 04, Loss: 744.1934\n",
      "AP SCORE：  0.8539362195532935\n",
      "AUC SCORE:  0.8322296142578125\n",
      "######################### 模块循环 ： 93 ##########################\n",
      "Epoch: 00, Loss: 743.9327\n",
      "Epoch: 01, Loss: 743.8931\n",
      "Epoch: 02, Loss: 743.8176\n",
      "Epoch: 03, Loss: 743.7100\n",
      "Epoch: 04, Loss: 743.5735\n",
      "AP SCORE：  0.8539181285283118\n",
      "AUC SCORE:  0.8322067260742188\n",
      "Epoch: 00, Loss: 743.4112\n",
      "Epoch: 01, Loss: 743.2259\n",
      "Epoch: 02, Loss: 743.0198\n",
      "Epoch: 03, Loss: 742.7953\n",
      "Epoch: 04, Loss: 742.5542\n",
      "AP SCORE：  0.8539077567558336\n",
      "AUC SCORE:  0.8322410583496094\n",
      "######################### 模块循环 ： 94 ##########################\n",
      "Epoch: 00, Loss: 742.2986\n",
      "Epoch: 01, Loss: 742.2595\n",
      "Epoch: 02, Loss: 742.1855\n",
      "Epoch: 03, Loss: 742.0799\n",
      "Epoch: 04, Loss: 741.9459\n",
      "AP SCORE：  0.8538302984441463\n",
      "AUC SCORE:  0.8321990966796875\n",
      "Epoch: 00, Loss: 741.7867\n",
      "Epoch: 01, Loss: 741.6049\n",
      "Epoch: 02, Loss: 741.4026\n",
      "Epoch: 03, Loss: 741.1824\n",
      "Epoch: 04, Loss: 740.9457\n",
      "AP SCORE：  0.8537948613640249\n",
      "AUC SCORE:  0.8321533203125\n",
      "######################### 模块循环 ： 95 ##########################\n",
      "Epoch: 00, Loss: 740.6949\n",
      "Epoch: 01, Loss: 740.6566\n",
      "Epoch: 02, Loss: 740.5839\n",
      "Epoch: 03, Loss: 740.4803\n",
      "Epoch: 04, Loss: 740.3489\n",
      "AP SCORE：  0.8537932583626087\n",
      "AUC SCORE:  0.8321647644042969\n",
      "Epoch: 00, Loss: 740.1926\n",
      "Epoch: 01, Loss: 740.0141\n",
      "Epoch: 02, Loss: 739.8157\n",
      "Epoch: 03, Loss: 739.5994\n",
      "Epoch: 04, Loss: 739.3674\n",
      "AP SCORE：  0.8537595702456988\n",
      "AUC SCORE:  0.8321456909179688\n",
      "######################### 模块循环 ： 96 ##########################\n",
      "Epoch: 00, Loss: 739.1210\n",
      "Epoch: 01, Loss: 739.0835\n",
      "Epoch: 02, Loss: 739.0122\n",
      "Epoch: 03, Loss: 738.9104\n",
      "Epoch: 04, Loss: 738.7815\n",
      "AP SCORE：  0.8537658169415873\n",
      "AUC SCORE:  0.8321723937988281\n",
      "Epoch: 00, Loss: 738.6282\n",
      "Epoch: 01, Loss: 738.4530\n",
      "Epoch: 02, Loss: 738.2582\n",
      "Epoch: 03, Loss: 738.0460\n",
      "Epoch: 04, Loss: 737.8182\n",
      "AP SCORE：  0.8537788339050053\n",
      "AUC SCORE:  0.8321762084960938\n",
      "######################### 模块循环 ： 97 ##########################\n",
      "Epoch: 00, Loss: 737.5765\n",
      "Epoch: 01, Loss: 737.5396\n",
      "Epoch: 02, Loss: 737.4695\n",
      "Epoch: 03, Loss: 737.3698\n",
      "Epoch: 04, Loss: 737.2432\n",
      "AP SCORE：  0.8537534984971349\n",
      "AUC SCORE:  0.8321685791015625\n",
      "Epoch: 00, Loss: 737.0927\n",
      "Epoch: 01, Loss: 736.9207\n",
      "Epoch: 02, Loss: 736.7295\n",
      "Epoch: 03, Loss: 736.5211\n",
      "Epoch: 04, Loss: 736.2975\n",
      "AP SCORE：  0.8537301359428452\n",
      "AUC SCORE:  0.8321533203125\n",
      "######################### 模块循环 ： 98 ##########################\n",
      "Epoch: 00, Loss: 736.0602\n",
      "Epoch: 01, Loss: 736.0240\n",
      "Epoch: 02, Loss: 735.9553\n",
      "Epoch: 03, Loss: 735.8572\n",
      "Epoch: 04, Loss: 735.7330\n",
      "AP SCORE：  0.853779942234464\n",
      "AUC SCORE:  0.832183837890625\n",
      "Epoch: 00, Loss: 735.5851\n",
      "Epoch: 01, Loss: 735.4164\n",
      "Epoch: 02, Loss: 735.2286\n",
      "Epoch: 03, Loss: 735.0240\n",
      "Epoch: 04, Loss: 734.8046\n",
      "AP SCORE：  0.8537524221778408\n",
      "AUC SCORE:  0.8322029113769531\n",
      "######################### 模块循环 ： 99 ##########################\n",
      "Epoch: 00, Loss: 734.5715\n",
      "Epoch: 01, Loss: 734.5360\n",
      "Epoch: 02, Loss: 734.4684\n",
      "Epoch: 03, Loss: 734.3722\n",
      "Epoch: 04, Loss: 734.2502\n",
      "AP SCORE：  0.8537166080319385\n",
      "AUC SCORE:  0.8321914672851562\n",
      "Epoch: 00, Loss: 734.1052\n",
      "Epoch: 01, Loss: 733.9392\n",
      "Epoch: 02, Loss: 733.7549\n",
      "Epoch: 03, Loss: 733.5539\n",
      "Epoch: 04, Loss: 733.3383\n",
      "AP SCORE：  0.8535612265555665\n",
      "AUC SCORE:  0.8320808410644531\n"
     ]
    }
   ],
   "source": [
    "train_edge, test_edge, train_mask, test_mask, nodes_number = get_graph(DATASET=dataset, task=2)\n",
    "context_embedding = Embedding(nodes_number, context_embedding_dim, sparse=True)      # 时刻为0时给定随机的嵌入\n",
    "nodes_context_embeddings = context_embedding.weight.detach()\n",
    "\n",
    "importance_embedding = Embedding(importance_embedding_dim, context_embedding_dim, sparse=True)      # 时刻为0时给定随机的嵌入\n",
    "nodes_importance_embeddings = importance_embedding.weight.detach()\n",
    "    \n",
    "auc_first_best_auc = 0\n",
    "auc_first_best_ap = 0\n",
    "ap_first_best_auc = 0\n",
    "ap_first_best_ap = 0\n",
    "\n",
    "for module_epoch in range(100):\n",
    "    print(\"######################### 模块循环 ： %d ##########################\"%module_epoch)\n",
    "    update_nodes_module = update_nodes_embedding(nodes_context_embeddings)\n",
    "    nodes_context_embeddings, ap, auc = update_nodes_module(train_edge, test_edge, train_mask, test_mask, nodes_importance_embeddings)\n",
    "    if auc > auc_first_best_auc:\n",
    "        auc_first_best_auc = auc\n",
    "        auc_first_best_ap = ap\n",
    "    if ap > ap_first_best_ap:\n",
    "        ap_first_best_auc = auc\n",
    "        ap_first_best_ap = ap\n",
    "    update_nodes_importance_module = update_nodes_embedding_importance(nodes_importance_embeddings)\n",
    "    nodes_importance_embeddings, ap, auc = update_nodes_module(train_edge, test_edge, train_mask, test_mask, nodes_context_embeddings)\n",
    "    if auc > auc_first_best_auc:\n",
    "        auc_first_best_auc = auc\n",
    "        auc_first_best_ap = ap\n",
    "    if ap > ap_first_best_ap:\n",
    "        ap_first_best_auc = auc\n",
    "        ap_first_best_ap = ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "601daf9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-16T06:02:53.883292Z",
     "start_time": "2022-10-16T06:02:53.866429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC FIRST BEST AUC:  0.8324203491210938\n",
      "AUC FIRST BEST AP:  0.854598748638586\n",
      "AP FIRST BEST AUC:  0.8311309814453125\n",
      "AP FIRST BEST AP:  0.8551702161409731\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC FIRST BEST AUC: \", auc_first_best_auc)\n",
    "print(\"AUC FIRST BEST AP: \", auc_first_best_ap)\n",
    "print(\"AP FIRST BEST AUC: \", ap_first_best_auc)\n",
    "print(\"AP FIRST BEST AP: \", ap_first_best_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dfe1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
